[[["ec98efa2-add3-474b-8ef8-294529f406a7",{"pageContent":"{/* Resposta */}\n      {response && (\n        <Card>\n          <CardBody>\n            <div className=\"flex justify-between items-start mb-4\">\n              <Typography variant=\"h5\">Resposta</Typography>\n              <div className=\"flex items-center gap-2\">\n                {response.cached && (\n                  <Chip\n                    value=\"Cache\"\n                    color=\"green\"\n                    size=\"sm\"\n                    icon={<CheckCircleIcon className=\"h-4 w-4\" />}\n                  />\n                )}\n                {response.responseTime && (\n                  <Chip\n                    value={`${response.responseTime.toFixed(1)}s`}\n                    color=\"blue\"\n                    size=\"sm\"\n                    icon={<ClockIcon className=\"h-4 w-4\" />}\n                  />\n                )}\n                {response.isStreaming && (\n                  <div className=\"flex items-center gap-2\">\n                    <div className=\"h-2 w-2 bg-blue-500 rounded-full animate-pulse\" />\n                    <Typography variant=\"small\" color=\"blue\">\n                      Processando...\n                    </Typography>\n                  </div>\n                )}\n              </div>\n            </div>\n            \n            <div className=\"prose prose-lg max-w-none\">\n              <Typography className=\"whitespace-pre-wrap leading-relaxed\">\n                {response.answer}\n              </Typography>\n            </div>","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":39,"totalChunks":43,"timestamp":1749642230530}}],["03aca64d-3c5f-4c3f-8dde-e1f70e03f585",{"pageContent":"export const useOpenAI = (apiKey) => {\n  const [isLoading, setIsLoading] = useState(false);\n  const [isTranscribing, setIsTranscribing] = useState(false);\n  const [error, setError] = useState(null);\n\n  // Memoize service instance\n  const openAIService = useMemo(() => {\n    return apiKey ? createOpenAIService(apiKey) : null;\n  }, [apiKey]);\n\n  /**\n   * Send chat message with streaming\n   * @param {string} prompt - User prompt\n   * @param {string} context - PDF context\n   * @param {function} onChunk - Callback for response chunks\n   * @returns {Promise<string>} Complete response\n   */\n  const sendMessage = useCallback(async (prompt, context = '', onChunk) => {\n    if (!openAIService) {\n      throw new Error('OpenAI service not initialized');\n    }\n\n    setIsLoading(true);\n    setError(null);\n\n    try {\n      const response = await openAIService.sendChatMessage(prompt, context, onChunk);\n      return response;\n    } catch (err) {\n      setError(err.message);\n      throw err;\n    } finally {\n      setIsLoading(false);\n    }\n  }, [openAIService]);\n\n  /**\n   * Transcribe audio to text\n   * @param {Blob} audioBlob - Audio data\n   * @param {string} language - Language code\n   * @returns {Promise<string>} Transcribed text\n   */\n  const transcribeAudio = useCallback(async (audioBlob, language = 'pt') => {\n    if (!openAIService) {\n      throw new Error('OpenAI service not initialized');\n    }\n\n    setIsTranscribing(true);\n    setError(null);\n\n    try {\n      const transcription = await openAIService.transcribeAudio(audioBlob, language);\n      return transcription;\n    } catch (err) {\n      setError(err.message);\n      throw err;\n    } finally {\n      setIsTranscribing(false);\n    }\n  }, [openAIService]);\n\n  /**\n   * Clear error state\n   */\n  const clearError = useCallback(() => {\n    setError(null);\n  }, []);\n\n  return {\n    sendMessage,\n    transcribeAudio,\n    clearError,\n    isLoading,\n    isTranscribing,\n    error,\n    isReady: !!openAIService,\n  };\n};","metadata":{"source":"src/hooks/useOpenAI.js","section":"","chunkIndex":1,"totalChunks":2,"timestamp":1749642230530}}],["1ddc96d9-5992-41de-8795-4b5105b3efff",{"pageContent":"/**\n * @fileoverview Application constants\n */\n\n/**\n * OpenAI API configuration\n */\nexport const OPENAI_CONFIG = {\n  CHAT_MODEL: 'gpt-4.1',\n  WHISPER_MODEL: 'whisper-1',\n  TEMPERATURE: 0,\n  MAX_TOKENS: 4000,\n};\n\n/**\n * API endpoints\n */\nexport const API_ENDPOINTS = {\n  OPENAI_CHAT: 'https://api.openai.com/v1/chat/completions',\n  OPENAI_TRANSCRIPTIONS: 'https://api.openai.com/v1/audio/transcriptions',\n};\n\n/**\n * PDF processing configuration\n */\nexport const PDF_CONFIG = {\n  MAX_FILE_SIZE: 10 * 1024 * 1024, // 10MB\n  ACCEPTED_TYPES: ['application/pdf'],\n  WORKER_SRC: 'https://cdn.jsdelivr.net/npm/pdfjs-dist@5.3.31/build/pdf.worker.min.mjs',\n  MAX_TEXT_PREVIEW: 1000,\n  MAX_CONTEXT_LENGTH: 3000,\n};\n\n/**\n * Audio recording configuration\n */\nexport const AUDIO_CONFIG = {\n  AUDIO_TYPE: 'audio/webm',\n  CONSTRAINTS: {\n    audio: {\n      channelCount: 1,\n      sampleRate: 16000,\n    },\n  },\n  MAX_RECORDING_TIME: 5 * 60 * 1000, // 5 minutes\n};\n\n/**\n * UI constants\n */\nexport const UI_CONFIG = {\n  MAX_RESPONSE_HEIGHT: 'max-h-80',\n  SPINNER_SIZE: 'h-8 w-8',\n  ANIMATION_DURATION: 300,\n};\n\n/**\n * Error messages\n */\nexport const ERROR_MESSAGES = {\n  PDF_PROCESSING: 'Erro ao processar PDF. Verifique se o arquivo é válido.',\n  MICROPHONE_ACCESS: 'Erro ao acessar o microfone. Verifique as permissões.',\n  TRANSCRIPTION_FAILED: 'Erro ao transcrever o áudio. Tente novamente.',\n  CHAT_REQUEST_FAILED: 'Erro ao processar sua solicitação. Tente novamente.',\n  FILE_TOO_LARGE: 'Arquivo muito grande. Tamanho máximo permitido: 10MB.',\n  INVALID_FILE_TYPE: 'Tipo de arquivo não suportado. Apenas PDFs são aceitos.',\n};\n\n/**\n * Success messages\n */\nexport const SUCCESS_MESSAGES = {\n  PDF_UPLOADED: 'PDF carregado com sucesso!',\n  TRANSCRIPTION_COMPLETED: 'Transcrição concluída com sucesso!',\n};","metadata":{"source":"src/constants/index.js","section":"","chunkIndex":0,"totalChunks":1,"timestamp":1749642230530}}],["445d6b54-5d7b-435c-8c0c-3e0d80805d51",{"pageContent":"### Abordagem mobile-first\n```javascript\nimport { Typography, Card } from \"@material-tailwind/react\";\n\nexport default function ResponsiveCard() {\n  return (\n    <Card className=\"w-full max-w-sm mx-auto sm:max-w-md md:max-w-lg lg:max-w-xl\">\n      <Typography \n        variant=\"h4\" \n        className=\"text-center text-base sm:text-lg md:text-xl lg:text-2xl\"\n      >\n        Responsive Typography\n      </Typography>\n    </Card>\n  );\n}\n```\n\n## 7. Diferenças entre versões gratuitas e Pro\n\n| Recurso | Versão Gratuita | Versão Pro |\n|---------|-----------------|------------|\n| **Componentes** | 40+ componentes básicos | 300+ componentes premium |\n| **Blocks e Seções** | Seções pré-construídas limitadas | 100+ blocks prontos para uso |\n| **Templates** | Sem templates completos | 20+ templates de websites completos |\n| **Arquivos Figma** | Não incluídos | Sistema de design Figma completo |\n| **Componentes Avançados** | Exibição básica de dados | Tabelas avançadas, gráficos, calendários |\n| **Elementos Premium** | Apenas componentes padrão | Formulários complexos, dashboards, e-commerce |\n| **Suporte** | Apenas suporte da comunidade | Suporte prioritário por email |\n| **Atualizações** | Ciclo de lançamento padrão | Acesso antecipado a novos recursos |\n| **Licença Comercial** | Licença MIT (uso comercial gratuito) | Licença comercial estendida |\n| **Preço** | Gratuito (Licença MIT) | Pagamento único: $299 individual, $799 equipe |\n| **Ferramentas IA** | Não disponível | Geração de componentes com IA (V3 Pro) |\n| **Exportação de Código** | Copiar e colar manual | Ferramentas de exportação direta de código |","metadata":{"source":"docs/Material-Tailwind-Guia-Completo.md","section":"","chunkIndex":8,"totalChunks":15,"timestamp":1749642230530}}],["758483d2-0baa-4101-8014-7ddc6f643644",{"pageContent":"{/* Progresso */}\n      {progress && (\n        <Card>\n          <CardBody>\n            <div className=\"space-y-3\">\n              <div className=\"flex justify-between items-center\">\n                <Typography className=\"font-medium\">\n                  {progress.message}\n                </Typography>\n                <Typography className=\"font-bold text-blue-600\">\n                  {Math.round(progress.percentage)}%\n                </Typography>\n              </div>\n              <Progress \n                value={progress.percentage} \n                color=\"blue\" \n                className=\"h-3\"\n              />\n              {progress.current && (\n                <Typography variant=\"small\" color=\"gray\" className=\"text-center\">\n                  {progress.current} de {progress.total} processados\n                </Typography>\n              )}\n            </div>\n          </CardBody>\n        </Card>\n      )}","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":37,"totalChunks":43,"timestamp":1749642230530}}],["548fa954-bb9c-4bb4-a250-c882952b8276",{"pageContent":"{/* Dialogs */}\n      <StatsDialog />\n      <HistoryDialog />\n    </div>\n  );\n}\n```\n\n## 6. App Principal com Roteamento\n\n```javascript\n// src/App.jsx\nimport React, { useState } from 'react';\nimport { ThemeProvider } from '@material-tailwind/react';\nimport { ApiKeySetup } from './components/ApiKeySetup';\nimport { HighQualityRAG } from './components/HighQualityRAG';\nimport { ConfigService } from './services/config.service';\n\nfunction App() {\n  const [hasApiKey, setHasApiKey] = useState(ConfigService.hasApiKey());\n\n  const handleApiKeySetup = () => {\n    setHasApiKey(true);\n  };\n\n  return (\n    <ThemeProvider>\n      <div className=\"min-h-screen bg-gray-50\">\n        {!hasApiKey ? (\n          <ApiKeySetup onComplete={handleApiKeySetup} />\n        ) : (\n          <HighQualityRAG />\n        )}\n      </div>\n    </ThemeProvider>\n  );\n}\n\nexport default App;\n```\n\n## 7. Configuração Vite Otimizada\n\n```javascript\n// vite.config.js\nimport { defineConfig } from 'vite'\nimport react from '@vitejs/plugin-react'\n\nexport default defineConfig({\n  plugins: [react()],\n  optimizeDeps: {\n    include: ['openai', '@orama/orama', 'pdfjs-dist', 'langchain']\n  },\n  build: {\n    rollupOptions: {\n      output: {\n        manualChunks: {\n          'openai': ['openai'],\n          'pdf': ['pdfjs-dist'],\n          'search': ['@orama/orama'],\n          'ui': ['@material-tailwind/react'],\n          'langchain': ['langchain']\n        }\n      }\n    },\n    chunkSizeWarningLimit: 1000\n  },\n  worker: {\n    format: 'es'\n  }\n})\n```\n\n## 8. Package.json Atualizado","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":41,"totalChunks":43,"timestamp":1749642230530}}],["68058528-3efb-43a4-87d0-4fcd1b81d9f0",{"pageContent":"{/* Exportar */}\n            {uploadedFile && (\n              <Button\n                onClick={handleExport}\n                variant=\"outlined\"\n                disabled={isProcessing}\n                className=\"flex items-center justify-center gap-2\"\n              >\n                <ArrowDownTrayIcon className=\"h-5 w-5\" />\n                Exportar\n              </Button>\n            )}\n\n            {/* Estatísticas */}\n            {stats && (\n              <Button\n                onClick={() => setShowStats(true)}\n                variant=\"outlined\"\n                color=\"blue-gray\"\n                className=\"flex items-center justify-center gap-2\"\n              >\n                <ChartBarIcon className=\"h-5 w-5\" />\n                Estatísticas\n              </Button>\n            )}\n          </div>","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":35,"totalChunks":43,"timestamp":1749642230530}}],["5bfefeb9-274c-467f-8a82-dbf1115d404f",{"pageContent":"/**\n * @fileoverview Audio recording service\n */\n\nimport { AUDIO_CONFIG, ERROR_MESSAGES } from '../constants';\n\n/**\n * Audio recording service class\n */","metadata":{"source":"src/services/audio.service.js","section":"","chunkIndex":0,"totalChunks":5,"timestamp":1749642230530}}],["136c873d-9a74-4254-ab58-ca53f8bd8d3d",{"pageContent":"const endTime = Date.now();\n      const responseTime = (endTime - startTime) / 1000;\n\n      setResponse(prev => ({\n        ...prev,\n        isStreaming: false,\n        responseTime: responseTime,\n        cached: result.cached || false\n      }));\n\n      // Adicionar ao histórico\n      const historyItem = {\n        query: query,\n        answer: fullResponse.substring(0, 100) + '...',\n        timestamp: new Date().toISOString(),\n        sources: result.sources.length\n      };\n      \n      const newHistory = [historyItem, ...queryHistory].slice(0, 20);\n      setQueryHistory(newHistory);\n      localStorage.setItem('query_history', JSON.stringify(newHistory));\n\n    } catch (err) {\n      setError(err.message);\n    } finally {\n      setIsProcessing(false);\n      setIsStreaming(false);\n    }\n  }, [query, ragService, queryHistory]);\n\n  // Exportar índice\n  const handleExport = useCallback(async () => {\n    try {\n      const blob = await ragService.exportIndex();\n      const url = URL.createObjectURL(blob);\n      const a = document.createElement('a');\n      a.href = url;\n      a.download = `rag-index-${uploadedFile?.name || 'export'}-${new Date().toISOString().split('T')[0]}.json`;\n      a.click();\n      URL.revokeObjectURL(url);\n      \n      // Notificar sucesso\n      alert('✅ Índice exportado com sucesso!');\n    } catch (err) {\n      setError(err.message);\n    }\n  }, [ragService, uploadedFile]);\n\n  // Importar índice\n  const handleImport = useCallback(async (event) => {\n    const file = event.target.files[0];\n    if (!file) return;\n\n    setIsProcessing(true);\n    setError(null);","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":23,"totalChunks":43,"timestamp":1749642230530}}],["74859e58-c497-48dc-a09b-69c095640b80",{"pageContent":"## 6. Melhores práticas de uso\n\n### Otimização de performance\n\n**Tree Shaking e Purging**\n```javascript\nmodule.exports = withMT({\n  content: [\n    \"./src/**/*.{js,jsx,ts,tsx}\",\n    \"./node_modules/@material-tailwind/react/components/**/*.{js,ts,jsx,tsx}\",\n    \"./node_modules/@material-tailwind/react/theme/components/**/*.{js,ts,jsx,tsx}\",\n  ],\n});\n```\n\n**Importação otimizada de componentes**\n```javascript\n// ✅ Bom - Importações individuais\nimport { Button, Card, Typography } from \"@material-tailwind/react\";\n\n// ❌ Evitar - Importar toda a biblioteca\nimport * as MaterialTailwind from \"@material-tailwind/react\";\n```\n\n### Padrões de composição de componentes\n```javascript\nimport { Card, CardHeader, CardBody, CardFooter, Typography, Button } from \"@material-tailwind/react\";\n\nexport default function ProductCard({ product }) {\n  return (\n    <Card className=\"mt-6 w-96\">\n      <CardHeader color=\"blue-gray\" className=\"relative h-56\">\n        <img src={product.image} alt={product.name} />\n      </CardHeader>\n      <CardBody>\n        <Typography variant=\"h5\" color=\"blue-gray\" className=\"mb-2\">\n          {product.name}\n        </Typography>\n        <Typography>\n          {product.description}\n        </Typography>\n      </CardBody>\n      <CardFooter className=\"pt-0\">\n        <Button>Add to Cart</Button>\n      </CardFooter>\n    </Card>\n  );\n}\n```\n\n### Considerações de acessibilidade\n```javascript\nimport { Button, IconButton } from \"@material-tailwind/react\";\n\nexport default function AccessibleButton() {\n  return (\n    <>\n      <Button \n        aria-label=\"Submit form\"\n        className=\"w-full\"\n      >\n        Submit\n      </Button>\n      \n      <IconButton \n        aria-label=\"Close dialog\"\n        variant=\"text\"\n      >\n        <XMarkIcon className=\"h-5 w-5\" />\n      </IconButton>\n    </>\n  );\n}\n```\n\n### Abordagem mobile-first\n```javascript\nimport { Typography, Card } from \"@material-tailwind/react\";","metadata":{"source":"docs/Material-Tailwind-Guia-Completo.md","section":"","chunkIndex":7,"totalChunks":15,"timestamp":1749642230530}}],["6a8e313e-9c3e-42ee-8423-c8a0d5d33eff",{"pageContent":"// Verificar cache de respostas\n    const cacheKey = `${query}_${relevantDocs.map(d => d.metadata.hash).join('_')}`;\n    const cachedResponse = this.getResponseCache(cacheKey);\n    if (cachedResponse) {\n      return { ...cachedResponse, cached: true };\n    }\n\n    // Construir contexto otimizado\n    const context = this.buildOptimizedContext(relevantDocs, maxContextTokens);\n\n    // Preparar mensagens\n    const messages = [\n      {\n        role: 'system',\n        content: systemPrompt\n      },\n      {\n        role: 'user',\n        content: `Contexto do documento:\\n\\n${context}\\n\\nPergunta: ${query}\\n\\nPor favor, forneça uma resposta detalhada e precisa baseada no contexto acima.`\n      }\n    ];\n\n    try {\n      if (streamResponse) {\n        const stream = await this.openai.chat.completions.create({\n          model: this.config.chatModel,\n          messages: messages,\n          temperature: this.config.temperature,\n          max_tokens: this.config.maxTokens,\n          stream: true\n        });\n\n        return {\n          stream: stream,\n          sources: relevantDocs.map(doc => doc.metadata),\n          cached: false\n        };\n      } else {\n        const response = await this.openai.chat.completions.create({\n          model: this.config.chatModel,\n          messages: messages,\n          temperature: this.config.temperature,\n          max_tokens: this.config.maxTokens\n        });\n\n        const result = {\n          answer: response.choices[0].message.content,\n          sources: relevantDocs.map(doc => doc.metadata),\n          usage: response.usage,\n          cached: false\n        };\n\n        // Cachear resposta\n        this.setResponseCache(cacheKey, result);\n\n        return result;\n      }\n    } catch (error) {\n      console.error('Erro ao gerar resposta:', error);\n      throw new Error('Falha ao gerar resposta: ' + error.message);\n    }\n  }","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":11,"totalChunks":43,"timestamp":1749642230530}}],["d638c7f4-1616-4322-8df3-d25e4849a2f9",{"pageContent":"{/* Interface de Busca */}\n      {uploadedFile && !progress && (\n        <Card>\n          <CardBody>\n            <Typography variant=\"h5\" className=\"mb-4\">\n              Fazer Pergunta\n            </Typography>\n            \n            <div className=\"space-y-4\">\n              <div className=\"relative\">\n                <Textarea\n                  value={query}\n                  onChange={(e) => setQuery(e.target.value)}\n                  placeholder=\"Digite sua pergunta sobre o documento...\"\n                  rows={3}\n                  disabled={isProcessing}\n                  onKeyDown={(e) => {\n                    if (e.key === 'Enter' && e.ctrlKey) {\n                      handleQuery();\n                    }\n                  }}\n                />\n                <Typography variant=\"small\" color=\"gray\" className=\"absolute bottom-2 right-2\">\n                  Ctrl+Enter para enviar\n                </Typography>\n              </div>\n              \n              <Button\n                onClick={handleQuery}\n                disabled={isProcessing || !query.trim() || isStreaming}\n                color=\"green\"\n                size=\"lg\"\n                className=\"w-full flex items-center justify-center gap-2\"\n              >\n                <MagnifyingGlassIcon className=\"h-5 w-5\" />\n                {isStreaming ? 'Gerando resposta...' : 'Buscar e Responder'}\n              </Button>\n            </div>\n          </CardBody>\n        </Card>\n      )}","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":38,"totalChunks":43,"timestamp":1749642230530}}],["f23fb33b-8426-49fa-b0de-ad3716970cfd",{"pageContent":"<Button\n          variant=\"text\"\n          color=\"red\"\n          onClick={() => {\n            if (confirm('Deseja limpar todo o histórico?')) {\n              setQueryHistory([]);\n              localStorage.removeItem('query_history');\n            }\n          }}\n          className=\"mr-auto\"\n        >\n          Limpar Histórico\n        </Button>\n        <Button variant=\"text\" onClick={() => setShowSavedIndexes(false)}>\n          Fechar\n        </Button>\n      </DialogFooter>\n    </Dialog>\n  );","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":32,"totalChunks":43,"timestamp":1749642230530}}],["ecd1d5f0-408a-44c2-906f-8a989300da16",{"pageContent":"// Reranking com GPT\n    if (useReranking && relevantDocs.length > 0) {\n      relevantDocs = await this.rerankDocuments(query, relevantDocs, limit);\n    }\n\n    // Incluir contexto adjacente se solicitado\n    if (includeContext) {\n      relevantDocs = await this.expandWithContext(relevantDocs);\n    }\n\n    return relevantDocs.slice(0, limit);\n  }\n\n  // Expandir com chunks adjacentes para mais contexto\n  async expandWithContext(documents) {\n    const expanded = [];\n    \n    for (const doc of documents) {\n      expanded.push(doc);\n      \n      // Buscar chunks adjacentes\n      const prevChunkId = `${doc.metadata.source}_p${doc.metadata.pageNumber}_c${doc.metadata.chunkIndex - 1}`;\n      const nextChunkId = `${doc.metadata.source}_p${doc.metadata.pageNumber}_c${doc.metadata.chunkIndex + 1}`;\n      \n      // Adicionar contexto anterior/posterior se existir\n      // (implementação simplificada - em produção, fazer query no DB)\n    }\n    \n    return expanded;\n  }\n\n  // Gerar resposta com streaming\n  async generateResponse(query, options = {}) {\n    const {\n      systemPrompt = `Você é um assistente especializado que fornece respostas precisas e detalhadas baseadas no contexto fornecido. \n      Sempre cite as páginas relevantes quando possível e seja específico nas suas respostas.\n      Se não encontrar informação suficiente no contexto, diga claramente.`,\n      includePageNumbers = true,\n      streamResponse = true,\n      maxContextTokens = 12000\n    } = options;\n\n    // Buscar documentos relevantes\n    const relevantDocs = await this.searchSemantic(query, {\n      useReranking: true,\n      includeContext: true\n    });\n    \n    if (relevantDocs.length === 0) {\n      return {\n        answer: 'Desculpe, não encontrei informações relevantes no documento para responder sua pergunta.',\n        sources: [],\n        cached: false\n      };\n    }","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":10,"totalChunks":43,"timestamp":1749642230530}}],["d772aed8-9127-499f-9230-8cf15bfbe9db",{"pageContent":"return relevantDocs.slice(0, limit);\n    } catch (error) {\n      console.error('Search failed:', error);\n      throw new Error(`Erro na busca: ${error.message}`);\n    }\n  }\n\n  // Expandir com chunks adjacentes para mais contexto\n  async expandWithContext(documents) {\n    const expanded = [];\n    \n    for (const doc of documents) {\n      expanded.push(doc);\n      \n      // Buscar chunks adjacentes\n      const prevChunkId = `${doc.metadata.source}_p${doc.metadata.pageNumber}_c${doc.metadata.chunkIndex - 1}`;\n      const nextChunkId = `${doc.metadata.source}_p${doc.metadata.pageNumber}_c${doc.metadata.chunkIndex + 1}`;\n      \n      // Adicionar contexto anterior/posterior se existir\n      // (implementação simplificada - em produção, fazer query no DB)\n    }\n    \n    return expanded;\n  }\n\n  // Gerar resposta com streaming\n  async generateResponse(query, options = {}) {\n    const {\n      systemPrompt = `Você é um assistente especializado que fornece respostas precisas e detalhadas baseadas no contexto fornecido. \n      Sempre cite as páginas relevantes quando possível e seja específico nas suas respostas.\n      Se não encontrar informação suficiente no contexto, diga claramente.`,\n      includePageNumbers = true,\n      streamResponse = true,\n      maxContextTokens = 12000\n    } = options;\n\n    // Buscar documentos relevantes\n    const relevantDocs = await this.searchSemantic(query, {\n      useReranking: true,\n      includeContext: true\n    });\n    \n    if (relevantDocs.length === 0) {\n      return {\n        answer: 'Desculpe, não encontrei informações relevantes no documento para responder sua pergunta.',\n        sources: [],\n        cached: false\n      };\n    }\n\n    // Verificar cache de respostas\n    const cacheKey = `${query}_${relevantDocs.map(d => d.metadata.hash).join('_')}`;\n    const cachedResponse = this.getResponseCache(cacheKey);\n    if (cachedResponse) {\n      return { ...cachedResponse, cached: true };\n    }","metadata":{"source":"src/services/highQualityRAG.service.js","section":"","chunkIndex":10,"totalChunks":17,"timestamp":1749642230530}}],["469af271-9223-4b43-870c-4503595efc05",{"pageContent":"3. **Component Organization**:\n   - `components/features/` - Feature-specific components\n   - `components/ui/` - Reusable UI components\n   - Each component manages its own state\n\n### OpenAI Integration Details\n\n- **Chat Model**: GPT-4.1 (Note: Update to valid model like `gpt-4-turbo-preview`)\n- **Whisper Model**: whisper-1 for transcription\n- **Streaming**: Real-time responses via LangChain\n- **Context**: PDF text passed as system message (max 3000 chars)\n- **Temperature**: 0 (deterministic responses)\n\n### Important Configuration Notes\n\n1. **PDF Worker Required**: Ensure `pdf.worker.min.mjs` exists in `/public` folder\n\n2. **Implementation Status**:\n   - ✅ PDF text extraction with progress\n   - ✅ Streaming chat with context\n   - ✅ Audio recording and transcription\n   - ❌ Text-to-speech (not implemented)\n   - ❌ Vector search (hnswlib installed but unused)\n\n### Code Style Conventions\n\n- **Indentation**: 2 spaces\n- **Quotes**: Single quotes for strings\n- **Semicolons**: Required\n- **Components**: PascalCase (`ChatInterface.jsx`)\n- **Hooks**: usePrefix (`useOpenAI`)\n- **Services**: camelCase (`openai.service.js`)\n- **Constants**: UPPER_SNAKE_CASE\n- **Documentation**: JSDoc with @fileoverview, @param, @returns","metadata":{"source":"CLAUDE.md","section":"","chunkIndex":1,"totalChunks":2,"timestamp":1749642230530}}],["40237ae6-e1b5-496d-a1de-07a521668129",{"pageContent":"{response.sources && response.sources.length > 0 && (\n              <div className=\"mt-6 pt-4 border-t\">\n                <Typography variant=\"h6\" className=\"mb-3\">\n                  Fontes Utilizadas ({response.sources.length})\n                </Typography>\n                <div className=\"grid grid-cols-1 md:grid-cols-2 gap-3\">\n                  {response.sources.map((source, idx) => (\n                    <Card key={idx} className=\"bg-gray-50\">\n                      <CardBody className=\"p-3\">\n                        <div className=\"flex items-center justify-between mb-1\">\n                          <Chip\n                            value={`Página ${source.pageNumber}`}\n                            size=\"sm\"\n                            color=\"blue\"\n                          />\n                          <Typography variant=\"small\" color=\"gray\">\n                            Relevância: {((source.importance || 1) * 100).toFixed(0)}%\n                          </Typography>\n                        </div>\n                        <Typography variant=\"small\" color=\"gray\">\n                          Chunk #{source.chunkIndex + 1} • {source.totalTokens} tokens\n                        </Typography>\n                      </CardBody>\n                    </Card>\n                  ))}\n                </div>\n              </div>\n            )}\n          </CardBody>\n        </Card>\n      )}\n\n      {/* Erros */}\n      {error && (\n        <Alert\n          color=\"red\"\n          onClose={() => setError(null)}\n          className=\"flex items-center\"\n        >\n          <ExclamationCircleIcon className=\"h-5 w-5 mr-2\" />\n          <div className=\"flex-1\">\n            <Typography className=\"font-medium\">Erro</Typography>\n            <Typography variant=\"small\">{error}</Typography>\n          </div>\n        </Alert>\n      )}\n\n      {/* Dialogs */}\n      <StatsDialog />\n      <HistoryDialog />\n    </div>\n  );\n}\n```\n\n## 6. App Principal com Roteamento","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":40,"totalChunks":43,"timestamp":1749642230530}}],["e241573a-e2ca-4f66-a943-303144f7a351",{"pageContent":"{/* Estimativa de custos detalhada */}\n            <Card className=\"bg-blue-gray-50\">\n              <CardBody>\n                <Typography variant=\"h6\" className=\"mb-3 flex items-center gap-2\">\n                  <CurrencyDollarIcon className=\"h-5 w-5\" />\n                  Estimativa de Custos\n                </Typography>\n                {(() => {\n                  const costs = ragService.estimateCost(stats.totalChunks);\n                  return (\n                    <div className=\"space-y-3\">\n                      <div className=\"p-3 bg-white rounded\">\n                        <Typography variant=\"small\" className=\"font-medium\">\n                          Embeddings ({ragService.config.embeddingModel})\n                        </Typography>\n                        <div className=\"flex justify-between mt-1\">\n                          <Typography variant=\"small\" color=\"gray\">\n                            {costs.embedding.tokens.toLocaleString()} tokens\n                          </Typography>\n                          <Typography variant=\"small\" className=\"font-medium text-green-600\">\n                            ${costs.embedding.cost.toFixed(4)}\n                          </Typography>\n                        </div>\n                      </div>\n                      \n                      <div className=\"p-3 bg-white rounded\">\n                        <Typography variant=\"small\" className=\"font-medium\">\n                          Uso Estimado de Chat (10 queries)\n                        </Typography>\n                        <div className=\"flex justify-between mt-1\">\n                          <Typography variant=\"small\" color=\"gray\">\n                            ~20,000 tokens\n                          </Typography>\n                          <Typography variant=\"small\" className=\"font-medium text-green-600\">\n                            $0.60\n                          </Typography>\n                        </div>\n                      </div>","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":28,"totalChunks":43,"timestamp":1749642230530}}],["b23cadb0-7136-4a6a-acea-4f9ed36e3f2f",{"pageContent":"return result;\n      }\n    } catch (error) {\n      console.error('Erro ao gerar resposta:', error);\n      throw new Error('Falha ao gerar resposta: ' + error.message);\n    }\n  }\n\n  // Sistema de cache de respostas\n  responseCache = new Map();\n  \n  getResponseCache(key) {\n    const cached = this.responseCache.get(key);\n    if (cached && Date.now() - cached.timestamp < 3600000) { // 1 hora\n      return cached.data;\n    }\n    return null;\n  }\n  \n  setResponseCache(key, data) {\n    this.responseCache.set(key, {\n      data: data,\n      timestamp: Date.now()\n    });\n    \n    // Limpar cache antigo\n    if (this.responseCache.size > 100) {\n      const oldestKey = this.responseCache.keys().next().value;\n      this.responseCache.delete(oldestKey);\n    }\n  }\n\n  // Reranking melhorado\n  async rerankDocuments(query, documents, topK) {\n    const prompt = `Task: Rank these text passages by relevance to the query.\n    \nQuery: \"${query}\"\n    \nPassages:\n${documents.map((doc, i) => `[${i + 1}] ${doc.text.substring(0, 300)}...`).join('\\n\\n')}\n    \nReturn ONLY the passage numbers in order of relevance (most to least relevant), separated by commas.\nExample: 3,1,5,2,4`;\n\n    try {\n      const response = await this.openai.chat.completions.create({\n        model: 'gpt-3.5-turbo',\n        messages: [{ role: 'user', content: prompt }],\n        temperature: 0,\n        max_tokens: 50\n      });\n\n      const content = response.choices[0].message.content.trim();\n      const ranking = content.split(',')\n        .map(n => parseInt(n.trim()) - 1)\n        .filter(n => !isNaN(n) && n >= 0 && n < documents.length);\n\n      if (ranking.length === 0) {\n        return documents;\n      }\n\n      return ranking.map(index => documents[index]);\n    } catch (error) {\n      console.warn('Reranking falhou:', error);\n      return documents;\n    }\n  }\n\n  // Construir contexto otimizado com metadados\n  buildOptimizedContext(documents, maxTokens) {\n    let context = '';\n    let currentTokens = 0;","metadata":{"source":"src/services/highQualityRAG.service.js","section":"","chunkIndex":12,"totalChunks":17,"timestamp":1749642230530}}],["30e8cfa7-4c9f-4da9-9482-dcaa65975e16",{"pageContent":"return result;\n      }\n    } catch (error) {\n      console.error('Erro ao gerar resposta:', error);\n      throw new Error('Falha ao gerar resposta: ' + error.message);\n    }\n  }\n\n  // Sistema de cache de respostas\n  responseCache = new Map();\n  \n  getResponseCache(key) {\n    const cached = this.responseCache.get(key);\n    if (cached && Date.now() - cached.timestamp < 3600000) { // 1 hora\n      return cached.data;\n    }\n    return null;\n  }\n  \n  setResponseCache(key, data) {\n    this.responseCache.set(key, {\n      data: data,\n      timestamp: Date.now()\n    });\n    \n    // Limpar cache antigo\n    if (this.responseCache.size > 100) {\n      const oldestKey = this.responseCache.keys().next().value;\n      this.responseCache.delete(oldestKey);\n    }\n  }\n\n  // Reranking melhorado\n  async rerankDocuments(query, documents, topK) {\n    const prompt = `Task: Rank these text passages by relevance to the query.\n    \nQuery: \"${query}\"\n    \nPassages:\n${documents.map((doc, i) => `[${i + 1}] ${doc.text.substring(0, 300)}...`).join('\\n\\n')}\n    \nReturn ONLY the passage numbers in order of relevance (most to least relevant), separated by commas.\nExample: 3,1,5,2,4`;\n\n    try {\n      const response = await this.openai.chat.completions.create({\n        model: 'gpt-3.5-turbo',\n        messages: [{ role: 'user', content: prompt }],\n        temperature: 0,\n        max_tokens: 50\n      });\n\n      const content = response.choices[0].message.content.trim();\n      const ranking = content.split(',')\n        .map(n => parseInt(n.trim()) - 1)\n        .filter(n => !isNaN(n) && n >= 0 && n < documents.length);\n\n      if (ranking.length === 0) {\n        return documents;\n      }\n\n      return ranking.map(index => documents[index]);\n    } catch (error) {\n      console.warn('Reranking falhou:', error);\n      return documents;\n    }\n  }\n\n  // Construir contexto otimizado com metadados\n  buildOptimizedContext(documents, maxTokens) {\n    let context = '';\n    let currentTokens = 0;","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":12,"totalChunks":43,"timestamp":1749642230530}}],["bc82d40c-92d3-4689-b37c-cc8f9be02415",{"pageContent":"/**\n   * Clear error state\n   */\n  const clearError = useCallback(() => {\n    setError(null);\n  }, []);\n\n  return {\n    extractText,\n    getMetadata,\n    validateFile,\n    clearText,\n    clearError,\n    extractedText,\n    isProcessing,\n    progress,\n    error,\n  };\n};","metadata":{"source":"src/hooks/usePDF.js","section":"","chunkIndex":2,"totalChunks":3,"timestamp":1749642230530}}],["5f225529-5bf1-4069-81c6-7211b4019ded",{"pageContent":"if (!ConfigService.hasApiKey()) {\n    return null;\n  }\n\n  return (\n    <div className=\"max-w-7xl mx-auto p-4 space-y-4\">\n      {/* Header */}\n      <Card>\n        <CardBody className=\"flex justify-between items-center\">\n          <div>\n            <Typography variant=\"h3\" color=\"blue-gray\" className=\"flex items-center gap-2\">\n              <SparklesIcon className=\"h-8 w-8 text-blue-500\" />\n              Sistema RAG de Alta Qualidade\n            </Typography>\n            <Typography color=\"gray\" className=\"mt-1\">\n              {ragService.config.embeddingModel} • {ragService.config.chatModel}\n            </Typography>\n          </div>\n          <div className=\"flex gap-2\">\n            <Tooltip content=\"Histórico\">\n              <IconButton\n                variant=\"text\"\n                onClick={() => setShowSavedIndexes(true)}\n              >\n                <ClockIcon className=\"h-5 w-5\" />\n              </IconButton>\n            </Tooltip>\n            <Tooltip content=\"Configurações\">\n              <IconButton\n                variant=\"text\"\n                onClick={handleReset}\n              >\n                <Cog6ToothIcon className=\"h-5 w-5\" />\n              </IconButton>\n            </Tooltip>\n          </div>\n        </CardBody>\n      </Card>","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":33,"totalChunks":43,"timestamp":1749642230530}}],["7ea566b7-e49c-48fc-bc3e-4b54bfc325ed",{"pageContent":"// Construir contexto otimizado\n    const context = this.buildOptimizedContext(relevantDocs, maxContextTokens);\n\n    // Preparar mensagens\n    const messages = [\n      {\n        role: 'system',\n        content: systemPrompt\n      },\n      {\n        role: 'user',\n        content: `Contexto do documento:\\n\\n${context}\\n\\nPergunta: ${query}\\n\\nPor favor, forneça uma resposta detalhada e precisa baseada no contexto acima.`\n      }\n    ];\n\n    try {\n      if (streamResponse) {\n        const stream = await this.openai.chat.completions.create({\n          model: this.config.chatModel,\n          messages: messages,\n          temperature: this.config.temperature,\n          max_tokens: this.config.maxTokens,\n          stream: true\n        });\n\n        return {\n          stream: stream,\n          sources: relevantDocs.map(doc => doc.metadata),\n          cached: false\n        };\n      } else {\n        const response = await this.openai.chat.completions.create({\n          model: this.config.chatModel,\n          messages: messages,\n          temperature: this.config.temperature,\n          max_tokens: this.config.maxTokens\n        });\n\n        const result = {\n          answer: response.choices[0].message.content,\n          sources: relevantDocs.map(doc => doc.metadata),\n          usage: response.usage,\n          cached: false\n        };\n\n        // Cachear resposta\n        this.setResponseCache(cacheKey, result);\n\n        return result;\n      }\n    } catch (error) {\n      console.error('Erro ao gerar resposta:', error);\n      throw new Error('Falha ao gerar resposta: ' + error.message);\n    }\n  }","metadata":{"source":"src/services/highQualityRAG.service.js","section":"","chunkIndex":11,"totalChunks":17,"timestamp":1749642230530}}],["f0bf5977-e4fc-4820-a8ff-815e3e98fca9",{"pageContent":"calculateImportance(text, pageNum, totalPages) {\n    let score = 1.0;\n    \n    // Primeiras páginas (resumo, introdução)\n    if (pageNum <= 3) score *= 1.3;\n    \n    // Últimas páginas (conclusão)\n    if (pageNum >= totalPages - 2) score *= 1.2;\n    \n    // Títulos e subtítulos (heurística)\n    if (text.match(/^[A-Z\\s\\d\\.]{3,50}$/m)) score *= 1.4;\n    \n    // Parágrafos com números e dados\n    const numbers = text.match(/\\d+\\.?\\d*/g) || [];\n    if (numbers.length > 5) score *= 1.2;\n    \n    // Listas e enumerações\n    if (text.match(/^\\s*[\\d\\-\\*•]\\s+/m)) score *= 1.1;\n    \n    // Chunks mais longos (mais contexto)\n    if (text.length > 600) score *= 1.1;\n    \n    return Math.min(score, 2.0);\n  }\n\n  calculatePercentiles(values) {\n    if (!values.length) return {};\n    \n    const sorted = values.sort((a, b) => a - b);\n    const percentiles = {};\n    \n    [25, 50, 75, 90, 95].forEach(p => {\n      const index = Math.floor((p / 100) * sorted.length);\n      percentiles[`p${p}`] = sorted[index];\n    });\n    \n    return percentiles;\n  }\n\n  estimateCost(totalChunks) {\n    const tokensPerChunk = this.config.chunkSize;\n    const totalTokens = totalChunks * tokensPerChunk;\n    \n    return {\n      embedding: {\n        model: this.config.embeddingModel,\n        tokens: totalTokens,\n        cost: (totalTokens / 1000) * 0.00013 // $0.00013 per 1K tokens\n      },\n      total: (totalTokens / 1000) * 0.00013\n    };\n  }\n\n  // Limpar recursos\n  cleanup() {\n    if (this.pdfWorker) {\n      this.pdfWorker.terminate();\n      this.pdfWorker = null;\n    }\n    this.embeddingCache.clear();\n    this.responseCache.clear();\n  }\n}\n```\n\n## 4. Componente de Setup Inicial Melhorado","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":15,"totalChunks":43,"timestamp":1749642230530}}],["46281bb3-c620-43bf-ba2e-6f77e9e6700f",{"pageContent":"npm install\n```\n\n**Resolução de módulo em tsconfig.json**\n```json\n{\n  \"compilerOptions\": {\n    \"moduleResolution\": \"node\"\n  }\n}\n```\n\n### Problema 2: Conflitos com Tailwind CSS\n\n**Solução para cores que param de funcionar após usar withMT()**\n```javascript\nconst withMT = require('@material-tailwind/react/utils/withMT');\n\nmodule.exports = withMT({\n  content: [\n    './index.html',\n    './src/**/*.{vue,js,ts,jsx,tsx}',\n    'path-to-your-node_modules/@material-tailwind/react/components/**/*.{js,ts,jsx,tsx}',\n    'path-to-your-node_modules/@material-tailwind/react/theme/components/**/*.{js,ts,jsx,tsx}',\n  ],\n  theme: {\n    extend: {}, // Não sobrescrever o tema padrão completamente\n  },\n  plugins: [],\n});\n```\n\n### Problema 3: Erros de build com Vite\n\n**Soluções comuns**\n\n**Limpar cache npm e reinstalar**\n```bash\nnpm cache clean --force\nrm -rf node_modules package-lock.json\nnpm install\n```\n\n**Configuração Vite com PostCSS explícito**\n```javascript\n// vite.config.js\nimport { defineConfig } from 'vite'\nimport react from '@vitejs/plugin-react'\nimport tailwindcss from 'tailwindcss'\n\nexport default defineConfig({\n  plugins: [react()],\n  css: {\n    postcss: {\n      plugins: [tailwindcss()],\n    },\n  }\n})\n```\n\n### Problema 4: Problemas de resolução de módulo\n\n**Downgrade de versão do pacote**\n```bash\nnpm install @material-tailwind/react@2.0.5  # Versão estável conhecida\n```\n\n**Verificar versões corretas no package.json**\n```json\n{\n  \"dependencies\": {\n    \"@material-tailwind/react\": \"^2.1.10\"\n  },\n  \"devDependencies\": {\n    \"@types/react\": \"18.2.42\",\n    \"tailwindcss\": \"^3.3.0\"\n  }\n}\n```\n\n### Problema 5: Componentes interativos não funcionando\n\n**Adicionar script ripple para versão HTML**\n```html\n<!-- Para versão HTML -->\n<script async src=\"node_modules/@material-tailwind/html/scripts/ripple.js\"></script>\n<!-- ou CDN -->\n<script async src=\"https://unpkg.com/@material-tailwind/html@latest/scripts/ripple.js\"></script>\n```\n\n### Problema 6: Ícones Material não exibindo","metadata":{"source":"docs/Material-Tailwind-Guia-Completo.md","section":"","chunkIndex":13,"totalChunks":15,"timestamp":1749642230530}}],["5eb18e84-c5c2-44c7-b5e7-a6a3cd2a9d59",{"pageContent":"{/* Informações */}\n        <Card className=\"bg-blue-50\">\n          <CardBody>\n            <Typography variant=\"h6\" className=\"mb-2\">\n              ℹ️ Informações Importantes\n            </Typography>\n            <ul className=\"space-y-1\">\n              <li>\n                <Typography variant=\"small\">\n                  • Este sistema usa os modelos mais avançados da OpenAI\n                </Typography>\n              </li>\n              <li>\n                <Typography variant=\"small\">\n                  • Custo estimado: ~$0.13 por 1M tokens de embedding\n                </Typography>\n              </li>\n              <li>\n                <Typography variant=\"small\">\n                  • Seus documentos são processados localmente no navegador\n                </Typography>\n              </li>\n              <li>\n                <Typography variant=\"small\">\n                  • Índices podem ser salvos para uso futuro sem API key\n                </Typography>\n              </li>\n            </ul>\n          </CardBody>\n        </Card>\n      </div>\n    </div>\n  );\n}\n```\n\n## 5. Interface Principal Completa com Todas as Funcionalidades\n\n```javascript\n// src/components/HighQualityRAG.jsx\nimport React, { useState, useEffect, useCallback, useRef } from 'react';\nimport {\n  Card,\n  CardBody,\n  Typography,\n  Button,\n  Textarea,\n  Progress,\n  Alert,\n  Chip,\n  IconButton,\n  Dialog,\n  DialogHeader,\n  DialogBody,\n  DialogFooter,\n  List,\n  ListItem,\n  Menu,\n  MenuHandler,\n  MenuList,\n  MenuItem,\n  Tooltip,\n} from '@material-tailwind/react';\nimport {\n  DocumentIcon,\n  MagnifyingGlassIcon,\n  ArrowDownTrayIcon,\n  ArrowUpTrayIcon,\n  ChartBarIcon,\n  CurrencyDollarIcon,\n  Cog6ToothIcon,\n  XMarkIcon,\n  ClockIcon,\n  CheckCircleIcon,\n  ExclamationCircleIcon,\n  SparklesIcon,\n  FolderIcon,\n  TrashIcon,\n} from '@heroicons/react/24/outline';\nimport { HighQualityRAGService } from '../services/highQualityRAG.service';\nimport { ConfigService } from '../services/config.service';","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":20,"totalChunks":43,"timestamp":1749642230530}}],["e7bb3eb9-42f7-49ef-add3-36b67641ccbf",{"pageContent":"{\n  \"name\": \"podcast-poc\",\n  \"private\": true,\n  \"version\": \"0.0.0\",\n  \"type\": \"module\",\n  \"scripts\": {\n    \"dev\": \"vite\",\n    \"build\": \"vite build\",\n    \"lint\": \"eslint .\",\n    \"preview\": \"vite preview\"\n  },\n  \"dependencies\": {\n    \"@heroicons/react\": \"^2.2.0\",\n    \"@material-tailwind/react\": \"^2.1.10\",\n    \"@orama/orama\": \"^3.1.7\",\n    \"audiobuffer-to-wav\": \"^1.0.0\",\n    \"file-saver\": \"^2.0.5\",\n    \"hnswlib-node\": \"^3.0.0\",\n    \"openai\": \"^5.3.0\",\n    \"pdfjs-dist\": \"^5.3.31\",\n    \"react\": \"^19.1.0\",\n    \"react-dom\": \"^19.1.0\",\n    \"uuid\": \"^11.1.0\",\n    \"wavesurfer.js\": \"^7.9.5\"\n  },\n  \"devDependencies\": {\n    \"@eslint/js\": \"^9.25.0\",\n    \"@radix-ui/react-slot\": \"^1.2.3\",\n    \"@types/react\": \"^19.1.2\",\n    \"@types/react-dom\": \"^19.1.2\",\n    \"@vitejs/plugin-react\": \"^4.4.1\",\n    \"autoprefixer\": \"^10.4.21\",\n    \"class-variance-authority\": \"^0.7.1\",\n    \"clsx\": \"^2.1.1\",\n    \"eslint\": \"^9.25.0\",\n    \"eslint-plugin-react-hooks\": \"^5.2.0\",\n    \"eslint-plugin-react-refresh\": \"^0.4.19\",\n    \"globals\": \"^16.0.0\",\n    \"postcss\": \"^8.5.4\",\n    \"tailwind-merge\": \"^3.3.1\",\n    \"tailwindcss\": \"^3.4.17\",\n    \"vite\": \"^6.3.5\"\n  }\n}","metadata":{"source":"package.json","section":"","chunkIndex":0,"totalChunks":1,"timestamp":1749642230530}}],["4aa1691d-76e7-4afc-a471-0bf7f4c90bfd",{"pageContent":"{/* Informações do documento */}\n          {stats && !progress && (\n            <div className=\"mt-4 p-3 bg-gray-50 rounded-lg\">\n              <div className=\"grid grid-cols-2 md:grid-cols-4 gap-4 text-center\">\n                <div>\n                  <Typography variant=\"small\" color=\"gray\">Páginas</Typography>\n                  <Typography className=\"font-bold\">{stats.pagesProcessed}</Typography>\n                </div>\n                <div>\n                  <Typography variant=\"small\" color=\"gray\">Chunks</Typography>\n                  <Typography className=\"font-bold\">{stats.totalChunks}</Typography>\n                </div>\n                <div>\n                  <Typography variant=\"small\" color=\"gray\">Tokens</Typography>\n                  <Typography className=\"font-bold\">{(stats.totalTokens / 1000).toFixed(1)}k</Typography>\n                </div>\n                <div>\n                  <Typography variant=\"small\" color=\"gray\">Custo</Typography>\n                  <Typography className=\"font-bold text-green-600\">\n                    ${ragService.estimateCost(stats.totalChunks).total.toFixed(3)}\n                  </Typography>\n                </div>\n              </div>\n            </div>\n          )}\n        </CardBody>\n      </Card>","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":36,"totalChunks":43,"timestamp":1749642230530}}],["e305fbfd-3e30-42c9-9877-619a6c3b5115",{"pageContent":"{/* Informações adicionais */}\n            {stats.duplicateChunks > 0 && (\n              <Alert color=\"amber\" className=\"flex items-center\">\n                <ExclamationCircleIcon className=\"h-5 w-5 mr-2\" />\n                {stats.duplicateChunks} chunks duplicados foram detectados e otimizados\n              </Alert>\n            )}\n          </div>\n        )}\n      </DialogBody>\n      <DialogFooter>\n        <Button variant=\"text\" onClick={() => setShowStats(false)}>\n          Fechar\n        </Button>\n      </DialogFooter>\n    </Dialog>\n  );","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":30,"totalChunks":43,"timestamp":1749642230530}}],["5fadf2b2-201b-46e2-9e13-f94af618d7fd",{"pageContent":"$0.60\n                          </Typography>\n                        </div>\n                      </div>\n                      \n                      <div className=\"border-t pt-3 flex justify-between\">\n                        <Typography className=\"font-bold\">Total Estimado:</Typography>\n                        <Typography className=\"font-bold text-green-600 text-lg\">\n                          ${(costs.total + 0.60).toFixed(2)}\n                        </Typography>\n                      </div>\n                    </div>\n                  );\n                })()}\n              </CardBody>\n            </Card>","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":29,"totalChunks":43,"timestamp":1749642230531}}],["5088fc3c-2cc7-4884-856c-fdcb8b244fa6",{"pageContent":"const root = ReactDOM.createRoot(document.getElementById(\"root\"));\nroot.render(\n  <React.StrictMode>\n    <ThemeProvider>\n      <App />\n    </ThemeProvider>\n  </React.StrictMode>\n);\n```\n\n## 2. Lista completa de componentes disponíveis\n\n### Componentes de navegação\n- **Navbar**: Barras de navegação responsivas com suporte a dropdown\n- **Breadcrumbs**: Navegação hierárquica com separadores personalizáveis\n- **Sidebar**: Navegação lateral colapsável com menus multinível\n- **Menu**: Menus dropdown com posicionamento e aninhamento\n- **Mega Menu**: Menus grandes para estruturas complexas\n- **Pagination**: Navegação de páginas com botões personalizáveis\n- **Tabs**: Sistemas de abas horizontais e verticais\n\n### Componentes de formulário\n- **Input**: Campos de texto com variantes (outlined, filled, standard)\n- **Input Number**: Campos numéricos com controles de incremento\n- **Input Phone**: Entrada de telefone com seleção de código de país\n- **Textarea**: Entrada de texto multilinha com redimensionamento automático\n- **Select**: Seleção dropdown com busca e multi-seleção\n- **Checkbox**: Caixas de seleção simples e agrupadas\n- **Radio Button**: Grupos de botões de rádio\n- **Switch**: Interruptores de alternância\n- **Form**: Layouts completos de formulário com validação\n\n### Componentes de exibição de dados\n- **Table**: Tabelas avançadas com ordenação, paginação e busca\n- **Card**: Componentes de cartão versáteis com cabeçalhos e rodapés\n- **List**: Listas simples e complexas com seleção\n- **Avatar**: Avatares de usuário com indicadores de status\n- **Badge**: Badges de notificação com contadores\n- **Chip**: Elementos compactos para tags e filtros\n- **Typography**: Componentes de texto com hierarquia Material Design\n- **Timeline**: Linhas do tempo verticais","metadata":{"source":"docs/Material-Tailwind-Guia-Completo.md","section":"","chunkIndex":1,"totalChunks":15,"timestamp":1749642230531}}],["e8528a19-f391-4a73-939e-f118555d9b7c",{"pageContent":"## 8. Package.json Atualizado\n\n```json\n{\n  \"name\": \"rag-openai-frontend\",\n  \"version\": \"2.0.0\",\n  \"type\": \"module\",\n  \"scripts\": {\n    \"dev\": \"vite\",\n    \"build\": \"vite build\",\n    \"preview\": \"vite preview\"\n  },\n  \"dependencies\": {\n    \"react\": \"^18.2.0\",\n    \"react-dom\": \"^18.2.0\",\n    \"@material-tailwind/react\": \"^2.1.10\",\n    \"@heroicons/react\": \"^2.0.18\",\n    \"openai\": \"^4.38.0\",\n    \"@orama/orama\": \"^2.0.0\",\n    \"langchain\": \"^0.1.36\",\n    \"pdfjs-dist\": \"^3.11.174\"\n  },\n  \"devDependencies\": {\n    \"@vitejs/plugin-react\": \"^4.2.1\",\n    \"vite\": \"^5.2.0\",\n    \"tailwindcss\": \"^3.4.0\",\n    \"autoprefixer\": \"^10.4.18\",\n    \"postcss\": \"^8.4.35\"\n  }\n}\n```\n\n## Resumo das Funcionalidades Implementadas\n\n### 1. **Processamento Avançado**\n- ✅ Web Worker para processar PDFs sem travar a UI\n- ✅ Chunking inteligente com análise de importância\n- ✅ Progress tracking detalhado em duas fases\n- ✅ Cache de embeddings para evitar reprocessamento\n\n### 2. **Busca e Respostas**\n- ✅ Busca semântica com threshold configurável\n- ✅ Reranking opcional com GPT-3.5\n- ✅ Streaming de respostas em tempo real\n- ✅ Cache de respostas para queries idênticas\n\n### 3. **Gestão de Dados**\n- ✅ Export/Import de índices completos\n- ✅ Histórico de consultas persistente\n- ✅ Estatísticas detalhadas do documento\n- ✅ Estimativa de custos em tempo real\n\n### 4. **UX Profissional**\n- ✅ Interface responsiva e moderna\n- ✅ Feedback visual rico durante processamento\n- ✅ Tratamento robusto de erros\n- ✅ Atalhos de teclado (Ctrl+Enter)\n\n### 5. **Performance**\n- ✅ Rate limiting automático\n- ✅ Retry automático em falhas\n- ✅ Gerenciamento inteligente de memória\n- ✅ Bundle splitting para carregamento rápido\n\nEste sistema está pronto para produção e oferece a mais alta qualidade disponível com os modelos da OpenAI!","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":42,"totalChunks":43,"timestamp":1749642230531}}],["a3c7ce2f-9126-4e5e-9c7d-29b01ba1585f",{"pageContent":"## 4. Componente de Setup Inicial Melhorado\n\n```javascript\n// src/components/ApiKeySetup.jsx\nimport React, { useState, useEffect } from 'react';\nimport {\n  Card,\n  CardBody,\n  Typography,\n  Input,\n  Button,\n  Alert,\n  List,\n  ListItem,\n  Chip,\n} from '@material-tailwind/react';\nimport { \n  KeyIcon, \n  DocumentIcon, \n  CheckCircleIcon,\n  ExclamationTriangleIcon \n} from '@heroicons/react/24/outline';\nimport { ConfigService } from '../services/config.service';\n\nexport function ApiKeySetup({ onComplete }) {\n  const [apiKey, setApiKey] = useState('');\n  const [error, setError] = useState('');\n  const [isValidating, setIsValidating] = useState(false);\n  const [availableIndexes, setAvailableIndexes] = useState([]);\n  const [showIndexes, setShowIndexes] = useState(false);\n\n  useEffect(() => {\n    // Verificar se há índices salvos\n    const indexes = ConfigService.getAvailableIndexes();\n    setAvailableIndexes(indexes);\n    setShowIndexes(indexes.length > 0);\n  }, []);\n\n  const validateAndSaveKey = async () => {\n    if (!ConfigService.validateApiKey(apiKey)) {\n      setError('Formato de API key inválido. Deve começar com \"sk-\"');\n      return;\n    }\n\n    setIsValidating(true);\n    setError('');\n\n    try {\n      // Testar a API key\n      const response = await fetch('https://api.openai.com/v1/models', {\n        headers: {\n          'Authorization': `Bearer ${apiKey}`\n        }\n      });\n\n      if (!response.ok) {\n        if (response.status === 401) {\n          throw new Error('API key inválida ou expirada');\n        } else if (response.status === 429) {\n          throw new Error('Limite de requisições excedido. Tente novamente em alguns segundos.');\n        } else {\n          throw new Error('Erro ao validar API key');\n        }\n      }","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":16,"totalChunks":43,"timestamp":1749642230531}}],["d199d339-50ee-4553-b13b-8ebad3d934d1",{"pageContent":"export const useAudioRecording = () => {\n  const [isRecording, setIsRecording] = useState(false);\n  const [isSupported, setIsSupported] = useState(false);\n  const [hasPermission, setHasPermission] = useState(false);\n  const [duration, setDuration] = useState(0);\n  const [error, setError] = useState(null);\n\n  const audioServiceRef = useRef(null);\n  const durationIntervalRef = useRef(null);\n\n  // Initialize audio service\n  useEffect(() => {\n    audioServiceRef.current = createAudioService();\n    setIsSupported(audioServiceRef.current.isSupported());\n\n    return () => {\n      // Cleanup on unmount\n      if (audioServiceRef.current) {\n        audioServiceRef.current.cleanup?.();\n      }\n      if (durationIntervalRef.current) {\n        clearInterval(durationIntervalRef.current);\n      }\n    };\n  }, []);\n\n  /**\n   * Request microphone permission\n   * @returns {Promise<boolean>} Whether permission was granted\n   */\n  const requestPermission = useCallback(async () => {\n    if (!audioServiceRef.current) return false;\n\n    try {\n      const granted = await audioServiceRef.current.requestPermission();\n      setHasPermission(granted);\n      setError(null);\n      return granted;\n    } catch (err) {\n      setError(err.message);\n      return false;\n    }\n  }, []);\n\n  /**\n   * Start recording audio\n   * @param {Object} options - Recording options\n   * @param {function} options.onComplete - Callback when recording completes\n   * @param {function} options.onError - Callback for errors\n   * @returns {Promise<void>}\n   */\n  const startRecording = useCallback(async ({ onComplete, onError } = {}) => {\n    if (!audioServiceRef.current || !isSupported) {\n      const errorMsg = 'Audio recording is not supported';\n      setError(errorMsg);\n      if (onError) onError(new Error(errorMsg));\n      return;\n    }","metadata":{"source":"src/hooks/useAudioRecording.js","section":"","chunkIndex":1,"totalChunks":4,"timestamp":1749642230531}}],["34e50e4b-8c89-4bc4-92b4-3191f08fc012",{"pageContent":"export const createAudioService = () => {\n  return new AudioService();\n};","metadata":{"source":"src/services/audio.service.js","section":"","chunkIndex":4,"totalChunks":5,"timestamp":1749642230531}}],["ded20539-ebad-4c9b-832a-fcc0c7672ddc",{"pageContent":"// Busca vetorial\n      let results;\n      try {\n        results = await search(this.db, {\n          mode: 'vector',\n          vector: {\n            value: queryEmbedding,\n            property: 'embedding'\n          },\n          limit: limit * 2,\n          threshold: threshold,\n          includeVectors: false\n        });\n      } catch (searchError) {\n        console.warn('Vector search failed, falling back to text search:', searchError);\n        // Fallback to simple text search\n        results = await search(this.db, {\n          term: query,\n          limit: limit\n        });\n      }\n\n      if (!results || !results.hits || results.hits.length === 0) {\n        return [];\n      }\n\n      let relevantDocs = results.hits.map(hit => ({\n        text: hit.document.text,\n        score: hit.score || 0.5,\n        metadata: {\n          pageNumber: hit.document.pageNumber,\n          source: hit.document.source,\n          chunkIndex: hit.document.chunkIndex,\n          totalTokens: hit.document.totalTokens,\n          importance: hit.document.importance,\n          hash: hit.document.hash\n        }\n      }));\n\n      // Reranking com GPT (with error handling)\n      if (useReranking && relevantDocs.length > 0) {\n        try {\n          relevantDocs = await this.rerankDocuments(query, relevantDocs, limit);\n        } catch (rerankError) {\n          console.warn('Reranking failed, using original order:', rerankError);\n        }\n      }\n\n      // Incluir contexto adjacente se solicitado\n      if (includeContext) {\n        try {\n          relevantDocs = await this.expandWithContext(relevantDocs);\n        } catch (contextError) {\n          console.warn('Context expansion failed:', contextError);\n        }\n      }\n\n      return relevantDocs.slice(0, limit);\n    } catch (error) {\n      console.error('Search failed:', error);\n      throw new Error(`Erro na busca: ${error.message}`);\n    }\n  }","metadata":{"source":"src/services/highQualityRAG.service.js","section":"","chunkIndex":9,"totalChunks":17,"timestamp":1749642230531}}],["7ed72a65-bf9c-4caf-9885-57b99e9c21c2",{"pageContent":"## 3. Exemplos de código para cada componente\n\n### Implementação básica de Button\n```jsx\nimport { Button } from \"@material-tailwind/react\";\n\nexport function ButtonExample() {\n  return (\n    <div className=\"flex gap-4\">\n      <Button>Default</Button>\n      <Button variant=\"gradient\">Gradient</Button>\n      <Button variant=\"outlined\">Outlined</Button>\n      <Button variant=\"text\">Text</Button>\n    </div>\n  );\n}\n```\n\n### Card avançado com múltiplas seções\n```jsx\nimport {\n  Card,\n  CardHeader,\n  CardBody,\n  CardFooter,\n  Typography,\n  Button,\n} from \"@material-tailwind/react\";\n\nexport function CardExample() {\n  return (\n    <Card className=\"mt-6 w-96\">\n      <CardHeader color=\"blue-gray\" className=\"relative h-56\">\n        <img\n          src=\"https://images.unsplash.com/photo-1540553016722-983e48a2cd10\"\n          alt=\"card-image\"\n        />\n      </CardHeader>\n      <CardBody>\n        <Typography variant=\"h5\" color=\"blue-gray\" className=\"mb-2\">\n          UI/UX Review Check\n        </Typography>\n        <Typography>\n          The place is close to Barceloneta Beach and bus stop just 2 min by walk.\n        </Typography>\n      </CardBody>\n      <CardFooter className=\"pt-0\">\n        <Button>Read More</Button>\n      </CardFooter>\n    </Card>\n  );\n}\n```\n\n### Formulário com validação\n```jsx\nimport { Input, Button, Typography, Card } from \"@material-tailwind/react\";","metadata":{"source":"docs/Material-Tailwind-Guia-Completo.md","section":"","chunkIndex":3,"totalChunks":15,"timestamp":1749642230531}}],["11461a2f-c714-4126-8a7a-f56b18ed2700",{"pageContent":"export class OpenAIService {\n  /**\n   * @param {string} apiKey - OpenAI API key\n   */\n  constructor(apiKey) {\n    this.apiKey = apiKey;\n    this.chatModel = null;\n  }\n\n  /**\n   * Initialize the chat model\n   * @private\n   */\n  _initChatModel() {\n    if (!this.chatModel) {\n      this.chatModel = new ChatOpenAI({\n        openAIApiKey: this.apiKey,\n        modelName: OPENAI_CONFIG.CHAT_MODEL,\n        temperature: OPENAI_CONFIG.TEMPERATURE,\n        streaming: true,\n      });\n    }\n    return this.chatModel;\n  }\n\n  /**\n   * Send a chat message with streaming response\n   * @param {string} prompt - User prompt\n   * @param {string} context - PDF context text\n   * @param {function} onChunk - Callback for each response chunk\n   * @returns {Promise<string>} Complete response text\n   * @throws {Error} When chat request fails\n   */\n  async sendChatMessage(prompt, context = '', onChunk) {\n    try {\n      const model = this._initChatModel();\n      \n      const messages = [\n        new SystemMessage(\n          context \n            ? `Você é um assistente útil. Aqui está o contexto do documento PDF extraído:\\n\\n${context.substring(0, OPENAI_CONFIG.MAX_CONTEXT_LENGTH)}...`\n            : 'Você é um assistente útil.'\n        ),\n        new HumanMessage(prompt)\n      ];\n\n      const stream = await model.stream(messages);\n      let fullResponse = '';\n      \n      for await (const chunk of stream) {\n        const content = chunk.content;\n        if (typeof content === 'string') {\n          fullResponse += content;\n          if (onChunk) {\n            onChunk(fullResponse);\n          }\n        }\n      }\n      \n      return fullResponse;\n    } catch (error) {\n      console.error('Chat request failed:', error);\n      throw new Error(ERROR_MESSAGES.CHAT_REQUEST_FAILED);\n    }\n  }","metadata":{"source":"src/services/openai.service.js","section":"","chunkIndex":1,"totalChunks":4,"timestamp":1749642230531}}],["1e901cdc-f5eb-43f5-84f5-6ea6ada5244b",{"pageContent":"export function HighQualityRAG() {\n  const [ragService] = useState(() => new HighQualityRAGService());\n  const [isInitialized, setIsInitialized] = useState(false);\n  const [isProcessing, setIsProcessing] = useState(false);\n  const [uploadedFile, setUploadedFile] = useState(null);\n  const [progress, setProgress] = useState(null);\n  const [query, setQuery] = useState('');\n  const [response, setResponse] = useState(null);\n  const [error, setError] = useState(null);\n  const [stats, setStats] = useState(null);\n  const [showStats, setShowStats] = useState(false);\n  const [isStreaming, setIsStreaming] = useState(false);\n  const [savedIndexes, setSavedIndexes] = useState([]);\n  const [showSavedIndexes, setShowSavedIndexes] = useState(false);\n  const [queryHistory, setQueryHistory] = useState([]);\n  const fileInputRef = useRef(null);\n  const indexInputRef = useRef(null);\n\n  // Inicializar serviço\n  useEffect(() => {\n    const init = async () => {\n      try {\n        await ragService.initialize();\n        setIsInitialized(true);\n        \n        // Carregar histórico de queries\n        const history = JSON.parse(localStorage.getItem('query_history') || '[]');\n        setQueryHistory(history);\n      } catch (err) {\n        setError(err.message);\n      }\n    };\n    \n    if (ConfigService.hasApiKey()) {\n      init();\n    }\n  }, [ragService]);\n\n  // Cleanup ao desmontar\n  useEffect(() => {\n    return () => {\n      ragService.cleanup();\n    };\n  }, [ragService]);\n\n  // Processar PDF\n  const handleFileUpload = useCallback(async (event) => {\n    const file = event.target.files[0];\n    if (!file) return;\n\n    if (file.type !== 'application/pdf') {\n      setError('Por favor, selecione um arquivo PDF');\n      return;\n    }\n\n    if (file.size > 100 * 1024 * 1024) {\n      setError('Arquivo muito grande. Máximo: 100MB');\n      return;\n    }\n\n    setUploadedFile(file);\n    setIsProcessing(true);\n    setError(null);\n    setProgress(null);\n    setResponse(null);","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":21,"totalChunks":43,"timestamp":1749642230531}}],["365d470d-82ee-492a-b05d-3140306d2454",{"pageContent":"<CardBody className=\"text-center\">\n                  <Typography variant=\"h6\" color=\"purple\">Média/Chunk</Typography>\n                  <Typography variant=\"h3\" color=\"blue-gray\">\n                    {stats.averageChunkSize}\n                  </Typography>\n                </CardBody>\n              </Card>\n            </div>","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":26,"totalChunks":43,"timestamp":1749642230531}}],["f36ae44c-ad3b-4ae0-a580-d3981c049c13",{"pageContent":"### Recursos exclusivos da versão Pro\n- **Componentes avançados de dashboard**: Widgets de análise, cartões KPI, gráficos avançados\n- **Templates de e-commerce**: Catálogos de produtos, carrinhos de compras, fluxos de checkout\n- **Páginas de autenticação**: Login, signup, redefinição de senha com múltiplas variantes\n- **Templates de landing page**: Páginas de marketing, landing pages SaaS, portfólios\n- **Blocks premium**: Seções hero, depoimentos, tabelas de preços, seções de equipe\n\n## 8. Compatibilidade com Tailwind CSS v3\n\n### Status atual de compatibilidade\n- **Versão Tailwind suportada**: v3.0+ (até v3.4.x)\n- **Versão mínima requerida**: Tailwind CSS v3.0\n- **Modo JIT**: Totalmente suportado e recomendado\n\n### Suporte ao modo JIT\n```javascript\n// tailwind.config.js\nmodule.exports = withMT({\n  mode: 'jit', // Habilitado por padrão em v3+\n  content: [\n    './src/**/*.{js,jsx,ts,tsx}',\n  ],\n  theme: {\n    extend: {},\n  },\n  plugins: [],\n});\n```\n\n### Integração com novos recursos do Tailwind v3\n\n**Suporte a valores arbitrários**\n```javascript\nimport { Button } from \"@material-tailwind/react\";\n\nexport default function ArbitraryValues() {\n  return (\n    <Button className=\"bg-[#1da1f2] text-[14px] p-[10px] rounded-[8px]\">\n      Custom Values\n    </Button>\n  );\n}\n```\n\n**Paleta de cores aprimorada**\nMaterial Tailwind suporta automaticamente a paleta expandida do Tailwind v3, incluindo cores como cyan, rose, fuchsia e lime por padrão.\n\n**Container Queries (v3.2+)**\n```javascript\n<Card className=\"@container\">\n  <div className=\"@sm:flex @md:grid-cols-2\">\n    {/* Responsivo ao tamanho do container */}\n  </div>\n</Card>\n```\n\n### Considerações de migração\n\n**De Tailwind v2 para v3**\n```bash\nnpm install -D tailwindcss@latest postcss@latest autoprefixer@latest\nnpm install @material-tailwind/react@latest\n```","metadata":{"source":"docs/Material-Tailwind-Guia-Completo.md","section":"","chunkIndex":9,"totalChunks":15,"timestamp":1749642230531}}],["de6873dd-7acb-46f9-8a37-f41905e6553b",{"pageContent":"# React + Vite\n\nThis template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.\n\nCurrently, two official plugins are available:\n\n- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react) uses [Babel](https://babeljs.io/) for Fast Refresh\n- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh\n\n## Expanding the ESLint configuration\n\nIf you are developing a production application, we recommend using TypeScript with type-aware lint rules enabled. Check out the [TS template](https://github.com/vitejs/vite/tree/main/packages/create-vite/template-react-ts) for information on how to integrate TypeScript and [`typescript-eslint`](https://typescript-eslint.io) in your project.","metadata":{"source":"README.md","section":"","chunkIndex":0,"totalChunks":1,"timestamp":1749642230531}}],["e97779d3-a669-4186-bb04-f7c77a1a1a4a",{"pageContent":"# Sistema RAG Frontend com OpenAI - Implementação Completa de Alta Qualidade\n\n## 📋 Descrição Detalhada do Projeto para Claude Code\n\n### Visão Geral\nEste projeto implementa um sistema RAG (Retrieval-Augmented Generation) completo que roda inteiramente no navegador (frontend-only), projetado para processar documentos PDF de até 100MB e fornecer respostas contextualizadas usando os modelos mais avançados da OpenAI.\n\n### Arquitetura e Fluxo de Dados\n```\n1. Upload PDF → 2. Extração de Texto → 3. Chunking Inteligente → 4. Geração de Embeddings\n                                                                             ↓\n8. Resposta Contextualizada ← 7. Geração GPT-4 ← 6. Busca Semântica ← 5. Armazenamento Vetorial\n```\n\n### Características Técnicas Principais\n- **Stack**: React + Vite + Material Tailwind + OpenAI API + Orama (vector DB)\n- **Modelos**: text-embedding-3-large (3072 dims) + GPT-4 Turbo\n- **Processamento**: 100% no navegador com Web Workers\n- **Persistência**: Export/Import de índices vetoriais completos\n- **Segurança**: API key fornecida pelo usuário, armazenada apenas em sessionStorage\n\n### Funcionalidades Implementadas\n1. **Setup Inicial**: Interface para usuário inserir sua API key OpenAI\n2. **Processamento de PDF**: \n   - Extração de texto página por página\n   - Chunking semântico com overlap\n   - Progress tracking detalhado\n   - Análise de importância dos chunks\n3. **Sistema de Embeddings**:\n   - Geração com modelo de alta qualidade\n   - Processamento em batches com rate limiting\n   - Cache e reutilização de embeddings\n4. **Busca e Resposta**:\n   - Busca vetorial com threshold de similaridade\n   - Reranking opcional com GPT-3.5\n   - Streaming de respostas do GPT-4\n5. **Gestão de Dados**:\n   - Export de índice completo (embeddings + metadados)\n   - Import de índices salvos\n   - Estatísticas e análise de custos","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":0,"totalChunks":43,"timestamp":1749642230531}}],["1b84ef0f-0724-4cb2-8e66-48fb13ec7849",{"pageContent":"### Considerações de migração\n\n**De Tailwind v2 para v3**\n```bash\nnpm install -D tailwindcss@latest postcss@latest autoprefixer@latest\nnpm install @material-tailwind/react@latest\n```\n\n**Atualizações de configuração**\n```javascript\n// Não usar mais 'purge', usar 'content' em vez disso\nmodule.exports = withMT({\n  content: ['./src/**/*.{js,jsx,ts,tsx}'], // era 'purge' em v2\n  theme: {\n    extend: {},\n  },\n  plugins: [],\n});\n```\n\n## 9. Exemplos de layouts completos\n\n### Layout de Dashboard\n```jsx\nimport {\n  Card,\n  Typography,\n  List,\n  ListItem,\n  ListItemPrefix,\n  Accordion,\n  AccordionHeader,\n  AccordionBody,\n} from \"@material-tailwind/react\";\n\nexport function DashboardLayout() {\n  return (\n    <div className=\"flex\">\n      {/* Sidebar */}\n      <Card className=\"h-[calc(100vh-2rem)] w-full max-w-[20rem] p-4 shadow-xl shadow-blue-gray-900/5\">\n        <div className=\"mb-2 p-4\">\n          <Typography variant=\"h5\" color=\"blue-gray\">\n            Sidebar\n          </Typography>\n        </div>\n        <List>\n          <Accordion open={open === 1}>\n            <ListItem className=\"p-0\" selected={open === 1}>\n              <AccordionHeader onClick={() => handleOpen(1)} className=\"border-b-0 p-3\">\n                <ListItemPrefix>\n                  <PresentationChartBarIcon className=\"h-5 w-5\" />\n                </ListItemPrefix>\n                <Typography color=\"blue-gray\" className=\"mr-auto font-normal\">\n                  Dashboard\n                </Typography>\n              </AccordionHeader>\n            </ListItem>\n          </Accordion>\n        </List>\n      </Card>\n      \n      {/* Main Content */}\n      <div className=\"flex-1 p-4\">\n        <Typography variant=\"h4\" color=\"blue-gray\" className=\"mb-4\">\n          Dashboard\n        </Typography>\n        {/* Dashboard content */}\n      </div>\n    </div>\n  );\n}\n```","metadata":{"source":"docs/Material-Tailwind-Guia-Completo.md","section":"","chunkIndex":10,"totalChunks":15,"timestamp":1749642230531}}],["bcfde8c6-6110-4207-b63c-15d3761472b7",{"pageContent":"---\n\n## 1. Serviço de Configuração e Gerenciamento de API Key\n\n```javascript\n// src/services/config.service.js\nexport class ConfigService {\n  static API_KEY_STORAGE = 'openai_api_key';\n  static INDEX_METADATA_STORAGE = 'rag_index_metadata';\n  \n  // API Key Management\n  static saveApiKey(apiKey) {\n    sessionStorage.setItem(this.API_KEY_STORAGE, apiKey);\n  }\n  \n  static getApiKey() {\n    return sessionStorage.getItem(this.API_KEY_STORAGE);\n  }\n  \n  static hasApiKey() {\n    return !!this.getApiKey();\n  }\n  \n  static clearApiKey() {\n    sessionStorage.removeItem(this.API_KEY_STORAGE);\n  }\n  \n  static validateApiKey(apiKey) {\n    return apiKey && apiKey.startsWith('sk-') && apiKey.length > 20;\n  }\n  \n  // Index Metadata Management\n  static saveIndexMetadata(metadata) {\n    localStorage.setItem(this.INDEX_METADATA_STORAGE, JSON.stringify(metadata));\n  }\n  \n  static getIndexMetadata() {\n    const data = localStorage.getItem(this.INDEX_METADATA_STORAGE);\n    return data ? JSON.parse(data) : null;\n  }\n  \n  static clearIndexMetadata() {\n    localStorage.removeItem(this.INDEX_METADATA_STORAGE);\n  }\n  \n  // Available Indexes\n  static getAvailableIndexes() {\n    const keys = Object.keys(localStorage).filter(key => key.startsWith('rag_index_'));\n    return keys.map(key => {\n      const data = localStorage.getItem(key);\n      try {\n        const parsed = JSON.parse(data);\n        return parsed.metadata;\n      } catch {\n        return null;\n      }\n    }).filter(Boolean);\n  }\n}\n```\n\n## 2. Web Worker para Processamento de PDF\n\n```javascript\n// src/workers/pdf.worker.js\nimport * as pdfjsLib from 'pdfjs-dist';\n\n// Configurar worker do PDF.js\npdfjsLib.GlobalWorkerOptions.workerSrc = `//cdnjs.cloudflare.com/ajax/libs/pdf.js/${pdfjsLib.version}/pdf.worker.min.js`;","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":2,"totalChunks":43,"timestamp":1749642230531}}],["821064f2-4e31-49af-86d5-21a71bf8186e",{"pageContent":"// Request permission if not already granted\n    if (!hasPermission) {\n      const granted = await requestPermission();\n      if (!granted) {\n        const errorMsg = 'Microphone permission required';\n        setError(errorMsg);\n        if (onError) onError(new Error(errorMsg));\n        return;\n      }\n    }\n\n    try {\n      setError(null);\n      setDuration(0);\n      setIsRecording(true);\n\n      // Start duration counter\n      durationIntervalRef.current = setInterval(() => {\n        setDuration(prev => prev + 1);\n      }, 1000);\n\n      await audioServiceRef.current.startRecording({\n        onStop: (audioBlob) => {\n          setIsRecording(false);\n          if (durationIntervalRef.current) {\n            clearInterval(durationIntervalRef.current);\n          }\n          if (onComplete) {\n            onComplete(audioBlob);\n          }\n        },\n        onError: (err) => {\n          setIsRecording(false);\n          setError(err.message);\n          if (durationIntervalRef.current) {\n            clearInterval(durationIntervalRef.current);\n          }\n          if (onError) {\n            onError(err);\n          }\n        }\n      });\n    } catch (err) {\n      setIsRecording(false);\n      setError(err.message);\n      if (durationIntervalRef.current) {\n        clearInterval(durationIntervalRef.current);\n      }\n      if (onError) {\n        onError(err);\n      }\n    }\n  }, [isSupported, hasPermission, requestPermission]);\n\n  /**\n   * Stop recording audio\n   */\n  const stopRecording = useCallback(() => {\n    if (audioServiceRef.current && isRecording) {\n      audioServiceRef.current.stopRecording();\n    }\n  }, [isRecording]);\n\n  /**\n   * Clear error state\n   */\n  const clearError = useCallback(() => {\n    setError(null);\n  }, []);","metadata":{"source":"src/hooks/useAudioRecording.js","section":"","chunkIndex":2,"totalChunks":4,"timestamp":1749642230531}}],["19e0bf5a-4b8d-4c2d-936a-baff62463b30",{"pageContent":"{/* Card de Índices Salvos */}\n        {showIndexes && (\n          <Card>\n            <CardBody>\n              <Typography variant=\"h6\" className=\"mb-3 flex items-center gap-2\">\n                <DocumentIcon className=\"h-5 w-5\" />\n                Índices Salvos Encontrados\n              </Typography>\n              \n              <Typography variant=\"small\" color=\"gray\" className=\"mb-3\">\n                Você pode usar índices salvos anteriormente sem precisar de API key\n              </Typography>\n\n              <List>\n                {availableIndexes.map((index, idx) => (\n                  <ListItem key={idx} className=\"p-2\">\n                    <div className=\"flex items-center justify-between w-full\">\n                      <div>\n                        <Typography variant=\"small\" className=\"font-medium\">\n                          {index.stats?.documentName || 'Documento'}\n                        </Typography>\n                        <Typography variant=\"small\" color=\"gray\">\n                          {index.stats?.totalChunks} chunks • {new Date(index.created).toLocaleDateString()}\n                        </Typography>\n                      </div>\n                      <Chip\n                        value={`${index.stats?.pagesProcessed} páginas`}\n                        size=\"sm\"\n                        color=\"blue\"\n                      />\n                    </div>\n                  </ListItem>\n                ))}\n              </List>\n\n              <Button\n                onClick={loadExistingIndex}\n                variant=\"outlined\"\n                className=\"w-full mt-3\"\n                color=\"green\"\n              >\n                <CheckCircleIcon className=\"h-4 w-4 mr-2\" />\n                Usar Apenas Índices Salvos\n              </Button>\n            </CardBody>\n          </Card>\n        )}","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":19,"totalChunks":43,"timestamp":1749642230531}}],["405a51d9-30f3-41f2-b135-f0db3516c55a",{"pageContent":"import OpenAI from 'openai';\nimport { create, insert, search, save, load } from '@orama/orama';\nimport { SimpleTextSplitter } from '../utils/textSplitter.js';\nimport { ConfigService } from './config.service';","metadata":{"source":"src/services/highQualityRAG.service.js","section":"","chunkIndex":0,"totalChunks":17,"timestamp":1749642230531}}],["9bdbc880-3e2b-4542-81e8-45bceb9ffeaf",{"pageContent":"### Layout de E-commerce\n```jsx\nexport function EcommerceLayout() {\n  return (\n    <div className=\"min-h-screen bg-gray-50\">\n      {/* Header */}\n      <Navbar className=\"sticky top-0 z-10 h-max max-w-full rounded-none px-4 py-2 lg:px-8 lg:py-4\">\n        <div className=\"flex items-center justify-between text-blue-gray-900\">\n          <Typography as=\"a\" href=\"#\" className=\"mr-4 cursor-pointer py-1.5 font-medium\">\n            E-Shop\n          </Typography>\n          <div className=\"flex items-center gap-4\">\n            <Input type=\"search\" placeholder=\"Search...\" />\n            <IconButton variant=\"text\">\n              <ShoppingCartIcon className=\"h-5 w-5\" />\n            </IconButton>\n          </div>\n        </div>\n      </Navbar>\n\n      {/* Product Grid */}\n      <div className=\"container mx-auto px-4 py-8\">\n        <div className=\"grid grid-cols-1 gap-6 sm:grid-cols-2 lg:grid-cols-4\">\n          {/* Product cards */}\n        </div>\n      </div>\n    </div>\n  );\n}\n```","metadata":{"source":"docs/Material-Tailwind-Guia-Completo.md","section":"","chunkIndex":11,"totalChunks":15,"timestamp":1749642230531}}],["f93faad6-e83a-4259-b1ef-42b5cbdda4a6",{"pageContent":"export const usePDF = () => {\n  const [extractedText, setExtractedText] = useState(null);\n  const [isProcessing, setIsProcessing] = useState(false);\n  const [progress, setProgress] = useState(0);\n  const [error, setError] = useState(null);\n\n  // Memoize service instance\n  const pdfService = useMemo(() => createPDFService(), []);\n\n  /**\n   * Extract text from PDF file\n   * @param {File} file - PDF file to process\n   * @returns {Promise<Object>} Extracted text data\n   */\n  const extractText = useCallback(async (file) => {\n    setIsProcessing(true);\n    setProgress(0);\n    setError(null);\n\n    try {\n      const result = await pdfService.extractText(file, (progressData) => {\n        setProgress(progressData.progress);\n      });\n\n      setExtractedText(result);\n      return result;\n    } catch (err) {\n      setError(err.message);\n      throw err;\n    } finally {\n      setIsProcessing(false);\n      setProgress(0);\n    }\n  }, [pdfService]);\n\n  /**\n   * Get PDF metadata\n   * @param {File} file - PDF file\n   * @returns {Promise<Object>} PDF metadata\n   */\n  const getMetadata = useCallback(async (file) => {\n    try {\n      return await pdfService.getMetadata(file);\n    } catch (err) {\n      setError(err.message);\n      throw err;\n    }\n  }, [pdfService]);\n\n  /**\n   * Validate PDF file\n   * @param {File} file - PDF file to validate\n   * @returns {boolean} Whether file is valid\n   */\n  const validateFile = useCallback((file) => {\n    try {\n      pdfService.validateFile(file);\n      return true;\n    } catch (err) {\n      setError(err.message);\n      return false;\n    }\n  }, [pdfService]);\n\n  /**\n   * Clear extracted text and reset state\n   */\n  const clearText = useCallback(() => {\n    setExtractedText(null);\n    setProgress(0);\n    setError(null);\n  }, []);\n\n  /**\n   * Clear error state\n   */\n  const clearError = useCallback(() => {\n    setError(null);\n  }, []);","metadata":{"source":"src/hooks/usePDF.js","section":"","chunkIndex":1,"totalChunks":3,"timestamp":1749642230531}}],["b437a186-bfee-4ceb-96c3-171ab6dceb74",{"pageContent":"function reconstructPageText(textContent) {\n  const lines = {};\n  \n  textContent.items.forEach(item => {\n    const y = Math.round(item.transform[5]);\n    if (!lines[y]) lines[y] = [];\n    lines[y].push(item);\n  });\n  \n  return Object.keys(lines)\n    .sort((a, b) => b - a)\n    .map(y => {\n      return lines[y]\n        .sort((a, b) => a.transform[4] - b.transform[4])\n        .map(item => item.str)\n        .join(' ')\n        .trim();\n    })\n    .filter(line => line.length > 0)\n    .join('\\n');\n}\n```\n\n## 3. Serviço RAG Principal com Processamento Otimizado\n\n```javascript\n// src/services/highQualityRAG.service.js\nimport OpenAI from 'openai';\nimport { create, insert, search, save, load } from '@orama/orama';\nimport { RecursiveCharacterTextSplitter } from 'langchain/text_splitter';\nimport { ConfigService } from './config.service';\n\nexport class HighQualityRAGService {\n  constructor() {\n    this.openai = null;\n    this.db = null;\n    this.initialized = false;\n    this.pdfWorker = null;\n    \n    // Configurações otimizadas para qualidade máxima\n    this.config = {\n      embeddingModel: 'text-embedding-3-large',\n      embeddingDimensions: 3072,\n      chatModel: 'gpt-4-turbo-preview',\n      chunkSize: 800,\n      chunkOverlap: 200,\n      temperature: 0.2,\n      maxTokens: 4000,\n      topK: 10,\n      similarityThreshold: 0.7,\n      batchSize: 5,\n      maxRetries: 3,\n      retryDelay: 1000\n    };\n\n    this.splitter = new RecursiveCharacterTextSplitter({\n      chunkSize: this.config.chunkSize,\n      chunkOverlap: this.config.chunkOverlap,\n      separators: [\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \"; \", \": \", \" \", \"\"],\n      lengthFunction: (text) => this.estimateTokens(text)\n    });\n    \n    // Cache de embeddings para evitar reprocessamento\n    this.embeddingCache = new Map();\n  }\n\n  async initialize() {\n    const apiKey = ConfigService.getApiKey();\n    if (!apiKey) {\n      throw new Error('API key não configurada');\n    }","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":4,"totalChunks":43,"timestamp":1749642230531}}],["fe7c9885-b579-4920-ad8c-d7ce830a763c",{"pageContent":"### Configuração para monorepo\n```javascript\nconst withMT = require(\"@material-tailwind/react/utils/withMT\");\n\nmodule.exports = withMT({\n  content: [\n    \"./index.html\",\n    \"./src/**/*.{js,ts,jsx,tsx}\",\n    \"path-to-your-node_modules/@material-tailwind/react/components/**/*.{js,ts,jsx,tsx}\",\n    \"path-to-your-node_modules/@material-tailwind/react/theme/components/**/*.{js,ts,jsx,tsx}\",\n  ],\n  theme: {\n    extend: {},\n  },\n  plugins: [],\n});\n```\n\n## 5. Customização de temas e cores\n\n### Paletas de cores personalizadas\n```javascript\n// tailwind.config.js\nconst withMT = require(\"@material-tailwind/react/utils/withMT\");\n\nmodule.exports = withMT({\n  theme: {\n    colors: {\n      // Substituir cores padrão completamente\n      white: '#ffffff',\n      purple: '#3f3cbb',\n      midnight: '#121063',\n      tahiti: '#3ab7bf',\n      bermuda: '#78dcca',\n    },\n    extend: {\n      colors: {\n        // Adicionar cores personalizadas à paleta existente\n        'custom-blue': '#3252df',\n        sky: {\n          50: \"#f0f9ff\",\n          100: \"#e0f2fe\",\n          200: \"#bae6fd\",\n          300: \"#7dd3fc\",\n          400: \"#38bdf8\",\n          500: \"#0ea5e9\",\n          600: \"#0284c7\",\n          700: \"#0369a1\",\n          800: \"#075985\",\n          900: \"#0c4a6e\",\n        },\n      },\n    },\n  },\n  plugins: [],\n});\n```\n\n### Customização através do ThemeProvider\n```javascript\nimport { ThemeProvider } from \"@material-tailwind/react\";","metadata":{"source":"docs/Material-Tailwind-Guia-Completo.md","section":"","chunkIndex":5,"totalChunks":15,"timestamp":1749642230531}}],["1fd3996c-7ad6-4882-8967-69c4302457b6",{"pageContent":"// Importar índice\n  const handleImport = useCallback(async (event) => {\n    const file = event.target.files[0];\n    if (!file) return;\n\n    setIsProcessing(true);\n    setError(null);\n\n    try {\n      const metadata = await ragService.importIndex(file);\n      setStats(metadata.stats);\n      setUploadedFile({ name: metadata.stats?.documentName || 'Documento importado' });\n      \n      alert(`✅ Índice importado com sucesso!\\n\\n` +\n        `📄 Documento: ${metadata.stats?.documentName || 'Desconhecido'}\\n` +\n        `📦 ${metadata.stats?.totalChunks || 0} chunks\\n` +\n        `📅 Criado em: ${new Date(metadata.created).toLocaleDateString()}`);\n    } catch (err) {\n      setError(err.message);\n    } finally {\n      setIsProcessing(false);\n    }\n  }, [ragService]);\n\n  // Carregar query do histórico\n  const loadFromHistory = (item) => {\n    setQuery(item.query);\n  };\n\n  // Limpar tudo\n  const handleReset = () => {\n    if (confirm('Deseja limpar todos os dados e começar novamente?')) {\n      ragService.cleanup();\n      setUploadedFile(null);\n      setStats(null);\n      setResponse(null);\n      setQuery('');\n      setError(null);\n      window.location.reload();\n    }\n  };","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":24,"totalChunks":43,"timestamp":1749642230531}}],["88d52e74-b556-49c1-9342-f2e602c4661e",{"pageContent":"### Componentes de feedback\n- **Alert**: Alertas de notificação com opções de descarte\n- **Progress Bar**: Indicadores de progresso lineares\n- **Spinner**: Spinners de carregamento em vários tamanhos\n- **Skeleton**: Placeholders de conteúdo para estados de carregamento\n- **Toast**: Mensagens de notificação temporárias\n- **Tooltip**: Informações ao passar o mouse\n\n### Componentes overlay e modal\n- **Dialog**: Diálogos modais com backdrop\n- **Drawer**: Painéis deslizantes de qualquer direção\n- **Popover**: Overlays de conteúdo posicionados\n- **Modal**: Implementações modais avançadas\n\n### Elementos interativos\n- **Button**: Botões primários, secundários, texto e ícone\n- **Button Group**: Coleções de botões agrupados\n- **Icon Button**: Botões circulares apenas com ícone\n- **Slider**: Sliders de intervalo com alças simples/duplas\n- **Rating Bar**: Componentes de classificação por estrelas\n- **Speed Dial**: Botão de ação flutuante com opções expansíveis\n\n### Componentes de layout\n- **Collapse**: Seções de conteúdo colapsáveis\n- **Accordion**: Painéis de conteúdo expansíveis\n- **Carousel**: Sliders de imagem/conteúdo\n- **Gallery**: Galerias de imagens com lightbox\n- **Stepper**: Indicadores de progresso passo a passo\n- **Footer**: Rodapés de site com várias opções de layout\n\n### Componentes Web 3.0\n- **Crypto Login**: Interfaces de conexão de carteira blockchain\n- **Crypto Card**: Cartões de exibição de criptomoedas\n- **Crypto Chart**: Visualização de dados de criptomoedas\n- **Crypto Modal**: Diálogos modais específicos para Web3\n- **Crypto Table**: Tabelas de transações blockchain\n\n## 3. Exemplos de código para cada componente\n\n### Implementação básica de Button\n```jsx\nimport { Button } from \"@material-tailwind/react\";","metadata":{"source":"docs/Material-Tailwind-Guia-Completo.md","section":"","chunkIndex":2,"totalChunks":15,"timestamp":1749642230531}}],["566566e8-6d1b-47ee-b20f-19dfae9cbc4b",{"pageContent":"/**\n   * Clear error state\n   */\n  const clearError = useCallback(() => {\n    setError(null);\n  }, []);\n\n  /**\n   * Format duration as MM:SS\n   * @param {number} seconds - Duration in seconds\n   * @returns {string} Formatted duration\n   */\n  const formatDuration = useCallback((seconds) => {\n    const minutes = Math.floor(seconds / 60);\n    const remainingSeconds = seconds % 60;\n    return `${minutes.toString().padStart(2, '0')}:${remainingSeconds.toString().padStart(2, '0')}`;\n  }, []);\n\n  return {\n    startRecording,\n    stopRecording,\n    requestPermission,\n    clearError,\n    formatDuration,\n    isRecording,\n    isSupported,\n    hasPermission,\n    duration,\n    error,\n  };\n};","metadata":{"source":"src/hooks/useAudioRecording.js","section":"","chunkIndex":3,"totalChunks":4,"timestamp":1749642230531}}],["ac311a10-26ce-4f16-a113-577d111741b6",{"pageContent":"/**\n * @fileoverview Custom hook for OpenAI integration\n */\n\nimport { useState, useCallback, useMemo } from 'react';\nimport { createOpenAIService } from '../services/openai.service';\n\n/**\n * Custom hook for OpenAI chat and transcription\n * @param {string} apiKey - OpenAI API key\n * @returns {Object} OpenAI utilities and state\n */","metadata":{"source":"src/hooks/useOpenAI.js","section":"","chunkIndex":0,"totalChunks":2,"timestamp":1749642230531}}],["04adb638-f88e-4859-ab3d-d96da348c10c",{"pageContent":"/**\n * @fileoverview OpenAI API service layer\n */\n\nimport { ChatOpenAI } from '@langchain/openai';\nimport { HumanMessage, SystemMessage } from '@langchain/core/messages';\nimport { OPENAI_CONFIG, API_ENDPOINTS, ERROR_MESSAGES } from '../constants';\n\n/**\n * OpenAI service class for handling chat and transcription requests\n */","metadata":{"source":"src/services/openai.service.js","section":"","chunkIndex":0,"totalChunks":4,"timestamp":1749642230531}}],["82789b1d-68a7-48fd-9625-c6cb9b8d9d03",{"pageContent":"/**\n * @fileoverview Utility functions for validation\n */\n\nimport { PDF_CONFIG } from '../constants';\n\n/**\n * Validate PDF file\n * @param {File} file - File to validate\n * @returns {{isValid: boolean, error: string|null}} Validation result\n * \n * @example\n * const result = validatePDFFile(file);\n * if (!result.isValid) console.error(result.error);\n */\nexport function validatePDFFile(file) {\n  if (!file) {\n    return { isValid: false, error: 'No file provided' };\n  }\n\n  if (file.size > PDF_CONFIG.MAX_FILE_SIZE) {\n    return { \n      isValid: false, \n      error: `File too large. Maximum size: ${formatFileSize(PDF_CONFIG.MAX_FILE_SIZE)}` \n    };\n  }\n\n  if (!PDF_CONFIG.ACCEPTED_TYPES.includes(file.type)) {\n    return { \n      isValid: false, \n      error: 'Invalid file type. Only PDF files are accepted.' \n    };\n  }\n\n  return { isValid: true, error: null };\n}\n\n// Helper function to format file size\nfunction formatFileSize(bytes) {\n  const sizes = ['Bytes', 'KB', 'MB', 'GB'];\n  if (bytes === 0) return '0 Bytes';\n  const i = Math.floor(Math.log(bytes) / Math.log(1024));\n  return Math.round(bytes / Math.pow(1024, i) * 100) / 100 + ' ' + sizes[i];\n}","metadata":{"source":"src/utils/validation.js","section":"","chunkIndex":0,"totalChunks":1,"timestamp":1749642230531}}],["3e8c83bf-b719-4f42-a0f8-2690e056d889",{"pageContent":"### Customização através do ThemeProvider\n```javascript\nimport { ThemeProvider } from \"@material-tailwind/react\";\n\nconst customTheme = {\n  button: {\n    defaultProps: {\n      variant: \"filled\",\n      size: \"md\",\n      color: \"blue\",\n    },\n    styles: {\n      base: {\n        initial: {\n          verticalAlign: \"align-middle\",\n          fontFamily: \"font-sans\",\n          fontWeight: \"font-bold\",\n          textAlign: \"text-center\",\n          textTransform: \"uppercase\",\n          transition: \"transition-all\",\n          userSelect: \"select-none\",\n        },\n      },\n      variants: {\n        filled: {\n          blue: {\n            backgroud: \"bg-blue-500\",\n            color: \"text-white\",\n            shadow: \"shadow-md shadow-blue-500/10\",\n          },\n        },\n      },\n    },\n  },\n};\n\nexport default function App() {\n  return (\n    <ThemeProvider value={customTheme}>\n      {/* Your app components */}\n    </ThemeProvider>\n  );\n}\n```\n\n### Implementação de Dark Mode\n```javascript\n// tailwind.config.js\nmodule.exports = withMT({\n  darkMode: 'class', // ou 'media' para preferência automática do sistema\n  theme: {\n    extend: {\n      colors: {\n        // Definir cores para dark mode\n      },\n    },\n  },\n});\n```\n\n```javascript\n// Componente DarkModeToggle\nimport { useState, useEffect } from 'react';\nimport { Button } from \"@material-tailwind/react\";\n\nexport default function DarkModeToggle() {\n  const [darkMode, setDarkMode] = useState(false);\n\n  useEffect(() => {\n    if (darkMode) {\n      document.documentElement.classList.add('dark');\n    } else {\n      document.documentElement.classList.remove('dark');\n    }\n  }, [darkMode]);\n\n  return (\n    <div className=\"bg-white dark:bg-gray-800 min-h-screen p-8\">\n      <Button \n        onClick={() => setDarkMode(!darkMode)}\n        className=\"dark:bg-blue-600 dark:text-white\"\n      >\n        Toggle Dark Mode\n      </Button>\n    </div>\n  );\n}\n```\n\n## 6. Melhores práticas de uso\n\n### Otimização de performance","metadata":{"source":"docs/Material-Tailwind-Guia-Completo.md","section":"","chunkIndex":6,"totalChunks":15,"timestamp":1749642230531}}],["3bee9576-c2f5-4301-8dcb-37df4ba8a9ca",{"pageContent":"// Carregar índice\n    this.db = await load(data.index);\n    \n    // Restaurar cache de embeddings\n    if (data.embeddingCache) {\n      this.embeddingCache = new Map(data.embeddingCache);\n    }\n\n    this.initialized = true;\n\n    return data.metadata;\n  }\n\n  // Análise detalhada do documento\n  async analyzeDocument() {\n    if (!this.db) return null;\n\n    const allDocs = await search(this.db, {\n      term: '',\n      limit: 10000\n    });\n\n    const stats = {\n      totalChunks: allDocs.hits.length,\n      totalTokens: 0,\n      averageChunkSize: 0,\n      pagesProcessed: new Set(),\n      tokenDistribution: [],\n      importanceDistribution: [],\n      uniqueHashes: new Set()\n    };\n\n    allDocs.hits.forEach(hit => {\n      const metadata = hit.document.metadata;\n      stats.totalTokens += metadata.totalTokens;\n      stats.pagesProcessed.add(metadata.pageNumber);\n      stats.tokenDistribution.push(metadata.totalTokens);\n      stats.importanceDistribution.push(metadata.importance);\n      stats.uniqueHashes.add(metadata.hash);\n    });\n\n    stats.averageChunkSize = Math.round(stats.totalTokens / stats.totalChunks);\n    stats.pagesProcessed = stats.pagesProcessed.size;\n    stats.duplicateChunks = stats.totalChunks - stats.uniqueHashes.size;\n\n    // Calcular percentis\n    stats.tokenPercentiles = this.calculatePercentiles(stats.tokenDistribution);\n    stats.importancePercentiles = this.calculatePercentiles(stats.importanceDistribution);\n\n    return stats;\n  }\n\n  // Utilitários\n  estimateTokens(text) {\n    // Aproximação: ~3 caracteres por token em português\n    return Math.ceil(text.length / 3);\n  }\n\n  generateHash(text) {\n    // Hash simples para cache\n    let hash = 0;\n    for (let i = 0; i < text.length; i++) {\n      const char = text.charCodeAt(i);\n      hash = ((hash << 5) - hash) + char;\n      hash = hash & hash;\n    }\n    return hash.toString(36);\n  }","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":14,"totalChunks":43,"timestamp":1749642230531}}],["a216eb8a-2cb4-4717-bee2-cfbc439b112c",{"pageContent":"/**\n * @fileoverview Custom hook for audio recording\n */\n\nimport { useState, useCallback, useRef, useEffect } from 'react';\nimport { createAudioService } from '../services/audio.service';\n\n/**\n * Custom hook for audio recording functionality\n * @returns {Object} Audio recording utilities and state\n */","metadata":{"source":"src/hooks/useAudioRecording.js","section":"","chunkIndex":0,"totalChunks":4,"timestamp":1749642230531}}],["77cee858-e8e5-478f-a499-d8e18d9013a7",{"pageContent":"### Formulário com validação\n```jsx\nimport { Input, Button, Typography, Card } from \"@material-tailwind/react\";\n\nexport function FormExample() {\n  return (\n    <Card color=\"transparent\" shadow={false}>\n      <Typography variant=\"h4\" color=\"blue-gray\">\n        Sign Up\n      </Typography>\n      <form className=\"mt-8 mb-2 w-80 max-w-screen-lg sm:w-96\">\n        <div className=\"mb-1 flex flex-col gap-6\">\n          <Typography variant=\"h6\" color=\"blue-gray\" className=\"-mb-3\">\n            Your Name\n          </Typography>\n          <Input\n            size=\"lg\"\n            placeholder=\"name@mail.com\"\n            className=\" !border-t-blue-gray-200 focus:!border-t-gray-900\"\n            labelProps={{\n              className: \"before:content-none after:content-none\",\n            }}\n          />\n        </div>\n        <Button className=\"mt-6\" fullWidth>\n          sign up\n        </Button>\n      </form>\n    </Card>\n  );\n}\n```\n\n## 4. Configuração específica para Vite e React\n\n### Criação de projeto Vite com React\n```bash\nnpm create vite@latest my-project -- --template react\ncd my-project\nnpm install\n```\n\n### Configuração do Vite (vite.config.js)\n```javascript\nimport { defineConfig } from 'vite'\nimport react from '@vitejs/plugin-react'\n\nexport default defineConfig({\n  plugins: [react()],\n  css: {\n    postcss: {\n      plugins: [\n        require('tailwindcss'),\n        require('autoprefixer'),\n      ],\n    }\n  }\n})\n```\n\n### Configuração Tailwind específica para Vite\n```javascript\n// tailwind.config.js\nconst withMT = require(\"@material-tailwind/react/utils/withMT\");\n\nmodule.exports = withMT({\n  content: [\n    \"./index.html\",\n    \"./src/**/*.{vue,js,ts,jsx,tsx}\"\n  ],\n  theme: {\n    extend: {},\n  },\n  plugins: [],\n});\n```\n\n### Configuração para monorepo\n```javascript\nconst withMT = require(\"@material-tailwind/react/utils/withMT\");","metadata":{"source":"docs/Material-Tailwind-Guia-Completo.md","section":"","chunkIndex":4,"totalChunks":15,"timestamp":1749642230531}}],["f854dab3-cb79-4b41-9d41-2a5c75ba14fb",{"pageContent":"export class ConfigService {\n  static API_KEY_STORAGE = 'openai_api_key';\n  static INDEX_METADATA_STORAGE = 'rag_index_metadata';\n  \n  // API Key Management\n  static saveApiKey(apiKey) {\n    sessionStorage.setItem(this.API_KEY_STORAGE, apiKey);\n  }\n  \n  static getApiKey() {\n    return sessionStorage.getItem(this.API_KEY_STORAGE);\n  }\n  \n  static hasApiKey() {\n    return !!this.getApiKey();\n  }\n  \n  static clearApiKey() {\n    sessionStorage.removeItem(this.API_KEY_STORAGE);\n  }\n  \n  static validateApiKey(apiKey) {\n    return apiKey && apiKey.startsWith('sk-') && apiKey.length > 20;\n  }\n  \n  // Index Metadata Management\n  static saveIndexMetadata(metadata) {\n    localStorage.setItem(this.INDEX_METADATA_STORAGE, JSON.stringify(metadata));\n  }\n  \n  static getIndexMetadata() {\n    const data = localStorage.getItem(this.INDEX_METADATA_STORAGE);\n    return data ? JSON.parse(data) : null;\n  }\n  \n  static clearIndexMetadata() {\n    localStorage.removeItem(this.INDEX_METADATA_STORAGE);\n  }\n  \n  // Available Indexes\n  static getAvailableIndexes() {\n    const keys = Object.keys(localStorage).filter(key => key.startsWith('rag_index_'));\n    return keys.map(key => {\n      const data = localStorage.getItem(key);\n      try {\n        const parsed = JSON.parse(data);\n        return parsed.metadata;\n      } catch {\n        return null;\n      }\n    }).filter(Boolean);\n  }\n}","metadata":{"source":"src/services/config.service.js","section":"","chunkIndex":0,"totalChunks":1,"timestamp":1749642230531}}],["a47cf580-2dd5-463d-add5-903c0d26b30a",{"pageContent":"// Gerar embedding com retry automático\n  async generateEmbeddingWithRetry(text, retries = 0) {\n    try {\n      const response = await this.openai.embeddings.create({\n        model: this.config.embeddingModel,\n        input: text,\n        dimensions: this.config.embeddingDimensions\n      });\n      \n      return response.data[0].embedding;\n    } catch (error) {\n      if (retries < this.config.maxRetries) {\n        await new Promise(resolve => setTimeout(resolve, this.config.retryDelay * (retries + 1)));\n        return this.generateEmbeddingWithRetry(text, retries + 1);\n      }\n      throw error;\n    }\n  }\n\n  // Busca semântica otimizada\n  async searchSemantic(query, options = {}) {\n    if (!this.initialized || !this.db) {\n      throw new Error('Sistema não inicializado');\n    }\n\n    const {\n      limit = this.config.topK,\n      threshold = this.config.similarityThreshold,\n      useReranking = true,\n      includeContext = true\n    } = options;\n\n    // Gerar embedding da query com cache\n    const queryHash = this.generateHash(query);\n    let queryEmbedding;\n    \n    if (this.embeddingCache.has(queryHash)) {\n      queryEmbedding = this.embeddingCache.get(queryHash);\n    } else {\n      queryEmbedding = await this.generateEmbeddingWithRetry(query);\n      this.embeddingCache.set(queryHash, queryEmbedding);\n    }\n\n    // Busca vetorial\n    const results = await search(this.db, {\n      mode: 'vector',\n      vector: {\n        value: queryEmbedding,\n        property: 'embedding'\n      },\n      limit: limit * 2,\n      threshold: threshold,\n      includeVectors: false\n    });\n\n    let relevantDocs = results.hits.map(hit => ({\n      text: hit.document.text,\n      score: hit.score,\n      metadata: hit.document.metadata\n    }));\n\n    // Reranking com GPT\n    if (useReranking && relevantDocs.length > 0) {\n      relevantDocs = await this.rerankDocuments(query, relevantDocs, limit);\n    }","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":9,"totalChunks":43,"timestamp":1749642230531}}],["0e78ffd7-eb47-44e0-9b62-205868044383",{"pageContent":"// Construir contexto otimizado com metadados\n  buildOptimizedContext(documents, maxTokens) {\n    let context = '';\n    let currentTokens = 0;\n\n    // Ordenar por score * importance\n    const sorted = documents.sort((a, b) => \n      (b.score * b.metadata.importance) - (a.score * a.metadata.importance)\n    );\n\n    for (const doc of sorted) {\n      const docTokens = doc.metadata.totalTokens;\n      \n      if (currentTokens + docTokens > maxTokens) {\n        break;\n      }\n\n      const pageInfo = ` [Página ${doc.metadata.pageNumber}]`;\n      const relevanceInfo = ` [Relevância: ${(doc.score * 100).toFixed(1)}%]`;\n      \n      context += `${doc.text}${pageInfo}${relevanceInfo}\\n\\n---\\n\\n`;\n      currentTokens += docTokens;\n    }\n\n    return context.trim();\n  }\n\n  // Exportar índice completo com metadados\n  async exportIndex() {\n    const indexData = await save(this.db);\n    const stats = await this.analyzeDocument();\n    \n    const exportData = {\n      version: '2.0',\n      metadata: {\n        model: this.config.embeddingModel,\n        dimensions: this.config.embeddingDimensions,\n        created: new Date().toISOString(),\n        stats: stats,\n        config: this.config\n      },\n      index: indexData,\n      embeddingCache: Array.from(this.embeddingCache.entries()).slice(0, 100) // Limitar tamanho\n    };\n\n    const blob = new Blob([JSON.stringify(exportData)], { type: 'application/json' });\n    return blob;\n  }\n\n  // Importar índice com validação\n  async importIndex(file) {\n    const text = await file.text();\n    const data = JSON.parse(text);\n\n    // Validações\n    if (!data.version || data.version !== '2.0') {\n      throw new Error('Versão de índice incompatível');\n    }\n\n    if (data.metadata?.dimensions !== this.config.embeddingDimensions) {\n      throw new Error(`Índice usa ${data.metadata.dimensions} dimensões, mas o sistema está configurado para ${this.config.embeddingDimensions}`);\n    }","metadata":{"source":"src/services/highQualityRAG.service.js","section":"","chunkIndex":13,"totalChunks":17,"timestamp":1749642230531}}],["f9dbb4dc-041e-418b-9fbd-a3bd46283a4d",{"pageContent":"// Construir contexto otimizado com metadados\n  buildOptimizedContext(documents, maxTokens) {\n    let context = '';\n    let currentTokens = 0;\n\n    // Ordenar por score * importance\n    const sorted = documents.sort((a, b) => \n      (b.score * b.metadata.importance) - (a.score * a.metadata.importance)\n    );\n\n    for (const doc of sorted) {\n      const docTokens = doc.metadata.totalTokens;\n      \n      if (currentTokens + docTokens > maxTokens) {\n        break;\n      }\n\n      const pageInfo = ` [Página ${doc.metadata.pageNumber}]`;\n      const relevanceInfo = ` [Relevância: ${(doc.score * 100).toFixed(1)}%]`;\n      \n      context += `${doc.text}${pageInfo}${relevanceInfo}\\n\\n---\\n\\n`;\n      currentTokens += docTokens;\n    }\n\n    return context.trim();\n  }\n\n  // Exportar índice completo com metadados\n  async exportIndex() {\n    const indexData = await save(this.db);\n    const stats = await this.analyzeDocument();\n    \n    const exportData = {\n      version: '2.0',\n      metadata: {\n        model: this.config.embeddingModel,\n        dimensions: this.config.embeddingDimensions,\n        created: new Date().toISOString(),\n        stats: stats,\n        config: this.config\n      },\n      index: indexData,\n      embeddingCache: Array.from(this.embeddingCache.entries()).slice(0, 100) // Limitar tamanho\n    };\n\n    const blob = new Blob([JSON.stringify(exportData)], { type: 'application/json' });\n    return blob;\n  }\n\n  // Importar índice com validação\n  async importIndex(file) {\n    const text = await file.text();\n    const data = JSON.parse(text);\n\n    // Validações\n    if (!data.version || data.version !== '2.0') {\n      throw new Error('Versão de índice incompatível');\n    }\n\n    if (data.metadata?.dimensions !== this.config.embeddingDimensions) {\n      throw new Error(`Índice usa ${data.metadata.dimensions} dimensões, mas o sistema está configurado para ${this.config.embeddingDimensions}`);\n    }","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":13,"totalChunks":43,"timestamp":1749642230531}}],["25c296c0-8ba1-4cae-b13c-373fd935ce28",{"pageContent":"// Carregar índice\n    this.db = await load(data.index);\n    \n    // Restaurar cache de embeddings\n    if (data.embeddingCache) {\n      this.embeddingCache = new Map(data.embeddingCache);\n    }\n\n    this.initialized = true;\n\n    return data.metadata;\n  }\n\n  // Análise detalhada do documento\n  async analyzeDocument() {\n    if (!this.db) return null;\n\n    try {\n      const allDocs = await search(this.db, {\n        term: '*',\n        limit: 10000\n      });\n\n      const stats = {\n        totalChunks: allDocs.hits.length,\n        totalTokens: 0,\n        averageChunkSize: 0,\n        pagesProcessed: new Set(),\n        tokenDistribution: [],\n        importanceDistribution: [],\n        uniqueHashes: new Set()\n      };\n\n      allDocs.hits.forEach(hit => {\n        const doc = hit.document;\n        stats.totalTokens += doc.totalTokens || 0;\n        stats.pagesProcessed.add(doc.pageNumber);\n        stats.tokenDistribution.push(doc.totalTokens || 0);\n        stats.importanceDistribution.push(doc.importance || 1);\n        stats.uniqueHashes.add(doc.hash);\n      });\n\n      stats.averageChunkSize = stats.totalChunks > 0 ? Math.round(stats.totalTokens / stats.totalChunks) : 0;\n      stats.pagesProcessed = stats.pagesProcessed.size;\n      stats.duplicateChunks = stats.totalChunks - stats.uniqueHashes.size;\n\n      // Calcular percentis\n      stats.tokenPercentiles = this.calculatePercentiles(stats.tokenDistribution);\n      stats.importancePercentiles = this.calculatePercentiles(stats.importanceDistribution);\n\n      return stats;\n    } catch (error) {\n      console.error('Error analyzing document:', error);\n      return null;\n    }\n  }\n\n  // Utilitários\n  estimateTokens(text) {\n    // Aproximação: ~3 caracteres por token em português\n    return Math.ceil(text.length / 3);\n  }","metadata":{"source":"src/services/highQualityRAG.service.js","section":"","chunkIndex":14,"totalChunks":17,"timestamp":1749642230531}}],["46020870-bfb3-472e-9332-f0538fb04779",{"pageContent":"// UI do histórico\n  const HistoryDialog = () => (\n    <Dialog open={showSavedIndexes} handler={() => setShowSavedIndexes(false)} size=\"lg\">\n      <DialogHeader>\n        <div className=\"flex items-center gap-2\">\n          <ClockIcon className=\"h-6 w-6\" />\n          Histórico de Consultas\n        </div>\n      </DialogHeader>\n      <DialogBody className=\"overflow-y-auto max-h-[60vh]\">\n        {queryHistory.length > 0 ? (\n          <List>\n            {queryHistory.map((item, idx) => (\n              <ListItem \n                key={idx} \n                className=\"p-3 hover:bg-gray-50 cursor-pointer\"\n                onClick={() => {\n                  loadFromHistory(item);\n                  setShowSavedIndexes(false);\n                }}\n              >\n                <div className=\"w-full\">\n                  <div className=\"flex justify-between items-start mb-1\">\n                    <Typography variant=\"small\" className=\"font-medium\">\n                      {item.query}\n                    </Typography>\n                    <Chip\n                      value={`${item.sources} fontes`}\n                      size=\"sm\"\n                      color=\"blue\"\n                    />\n                  </div>\n                  <Typography variant=\"small\" color=\"gray\">\n                    {item.answer}\n                  </Typography>\n                  <Typography variant=\"small\" color=\"blue-gray\" className=\"mt-1\">\n                    {new Date(item.timestamp).toLocaleString()}\n                  </Typography>\n                </div>\n              </ListItem>\n            ))}\n          </List>\n        ) : (\n          <Typography color=\"gray\" className=\"text-center py-8\">\n            Nenhuma consulta realizada ainda\n          </Typography>\n        )}\n      </DialogBody>\n      <DialogFooter>\n        <Button\n          variant=\"text\"\n          color=\"red\"\n          onClick={() => {\n            if (confirm('Deseja limpar todo o histórico?')) {\n              setQueryHistory([]);","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":31,"totalChunks":43,"timestamp":1749642230531}}],["7970e356-bfe3-4f12-9d99-797a89f784c8",{"pageContent":"export const createPDFService = () => {\n  return new PDFService();\n};","metadata":{"source":"src/services/pdf.service.js","section":"","chunkIndex":3,"totalChunks":4,"timestamp":1749642230531}}],["600b8604-bd98-41aa-9b38-f58c8369c5b0",{"pageContent":"### Estrutura de Arquivos Necessária\n```\nsrc/\n├── services/\n│   ├── config.service.js         # Gerenciamento de API key\n│   └── highQualityRAG.service.js # Lógica principal do RAG\n├── components/\n│   ├── ApiKeySetup.jsx          # Tela de configuração inicial\n│   └── HighQualityRAG.jsx       # Interface principal do sistema\n├── workers/\n│   └── pdf.worker.js            # Web Worker para processamento\n└── App.jsx                      # Componente raiz\n```\n\n### Dependências Necessárias\n```json\n{\n  \"dependencies\": {\n    \"openai\": \"^4.0.0\",\n    \"@orama/orama\": \"^2.0.0\",\n    \"langchain\": \"^0.1.0\",\n    \"pdfjs-dist\": \"^3.0.0\",\n    \"@material-tailwind/react\": \"^2.0.0\",\n    \"@heroicons/react\": \"^2.0.0\"\n  }\n}\n```\n\n### Instruções de Implementação\n1. Instale as dependências: `npm install openai @orama/orama langchain pdfjs-dist`\n2. Copie os arquivos de serviço e componentes para as pastas correspondentes\n3. Configure o Web Worker para processamento assíncrono\n4. Ajuste as configurações de chunking e embedding conforme necessário\n5. Teste com PDFs pequenos antes de processar arquivos grandes\n\n---\n\n## 1. Serviço de Configuração e Gerenciamento de API Key","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":1,"totalChunks":43,"timestamp":1749642230531}}],["167b28cd-2801-4117-9c03-b0996c6442ba",{"pageContent":"# CLAUDE.md\n\nThis file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.\n\n## Project Overview\n\n**Project**: Podcast POC  \n**Description**: Web application for educational podcast generation from PDFs using OpenAI APIs. Features include PDF text extraction, AI-powered chat interface, audio recording/transcription, and vector search capabilities.  \n**Stack**: React 18.3.1 + Vite 6.0.5 + Material Tailwind + OpenAI APIs + LangChain  \n\n## Essential Commands\n\n```bash\n# Development\nnpm install                  # Install all dependencies\nnpm run dev                  # Start dev server (http://localhost:5173)\nnpm run build                # Production build\nnpm run preview              # Preview production build\nnpm run lint                 # Run ESLint\n\n# Environment Setup - Create .env.local file:\nVITE_OPENAI_API_KEY=your_openai_api_key_here\n\n# Git Workflow\ngit checkout development     # Active development branch\ngit checkout -b feature/name # Create feature branch\ngit commit -m \"type: description\" # Commit format (feat/fix/docs/refactor)\n```\n\n## High-Level Architecture\n\n### Application Flow\n```\n1. PDF Upload → Text Extraction → Context Storage\n2. User Query → OpenAI API → Streaming Response\n3. Audio Recording → Whisper API → Transcribed Text\n```\n\n### Key Architectural Patterns\n\n1. **Service Layer Pattern**: Business logic isolated in service classes\n   - `openai.service.js` - OpenAI API integration with LangChain\n   - `pdf.service.js` - PDF text extraction\n   - `audio.service.js` - Audio recording management\n\n2. **Custom Hooks**: Stateful logic encapsulation\n   - `useOpenAI` - Chat and transcription with loading states\n   - `usePDF` - PDF processing with progress tracking\n   - `useAudioRecording` - Audio capture and blob generation\n\n3. **Component Organization**:\n   - `components/features/` - Feature-specific components\n   - `components/ui/` - Reusable UI components\n   - Each component manages its own state","metadata":{"source":"CLAUDE.md","section":"","chunkIndex":0,"totalChunks":2,"timestamp":1749642230531}}],["f53f5465-e82f-4d38-9692-bb9bccbe57de",{"pageContent":"// Configurar worker do PDF.js - use absolute URLs for better compatibility\npdfjsLib.GlobalWorkerOptions.workerSrc = 'https://cdn.jsdelivr.net/npm/pdfjs-dist@5.3.31/build/pdf.worker.min.mjs';\n\nself.onmessage = async function(event) {\n  const { type, data } = event.data;\n  \n  if (type === 'process-pdf') {\n    try {\n      const { arrayBuffer, chunkSize } = data;\n      const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise;\n      const totalPages = pdf.numPages;\n      const chunks = [];\n      \n      // Processar em batches de páginas\n      const PAGES_PER_BATCH = 5;\n      \n      for (let startPage = 1; startPage <= totalPages; startPage += PAGES_PER_BATCH) {\n        const endPage = Math.min(startPage + PAGES_PER_BATCH - 1, totalPages);\n        const batchChunks = [];\n        \n        for (let pageNum = startPage; pageNum <= endPage; pageNum++) {\n          const page = await pdf.getPage(pageNum);\n          const textContent = await page.getTextContent();\n          \n          // Reconstruir texto preservando estrutura\n          const pageText = reconstructPageText(textContent);\n          \n          batchChunks.push({\n            pageNumber: pageNum,\n            text: pageText,\n            estimatedTokens: Math.ceil(pageText.length / 3)\n          });\n          \n          page.cleanup();\n        }\n        \n        // Enviar batch processado\n        self.postMessage({\n          type: 'batch-complete',\n          data: {\n            chunks: batchChunks,\n            progress: {\n              current: endPage,\n              total: totalPages,\n              percentage: (endPage / totalPages) * 100\n            }\n          }\n        });\n        \n        // Pequena pausa para não sobrecarregar\n        await new Promise(resolve => setTimeout(resolve, 10));\n      }\n      \n      self.postMessage({ type: 'processing-complete' });\n      \n    } catch (error) {\n      self.postMessage({\n        type: 'error',\n        error: error.message\n      });\n    }\n  }\n};","metadata":{"source":"src/workers/pdf.worker.js","section":"","chunkIndex":1,"totalChunks":3,"timestamp":1749642230531}}],["623ec582-0c99-4046-b286-f77fc3b70597",{"pageContent":"onProgress?.({\n            phase: 'extraction',\n            current: data.progress.current,\n            total: data.progress.total,\n            percentage: data.progress.percentage * 0.4, // 40% para extração\n            message: `Extraindo texto: ${data.progress.current}/${data.progress.total} páginas`\n          });\n        } \n        else if (type === 'processing-complete') {\n          // Iniciar fase de embeddings\n          this.pdfWorker.removeEventListener('message', handleWorkerMessage);\n          \n          try {\n            await this.generateAndStoreEmbeddings(allChunks, file.name, onProgress);\n            \n            const processingTime = Date.now() - startTime;\n            const result = {\n              success: true,\n              documentName: file.name,\n              totalPages: processedPages,\n              totalChunks: allChunks.length,\n              processingTime: processingTime,\n              estimatedCost: this.estimateCost(allChunks.length)\n            };\n            \n            resolve(result);\n          } catch (err) {\n            reject(err);\n          }\n        }\n        else if (type === 'error') {\n          this.pdfWorker.removeEventListener('message', handleWorkerMessage);\n          reject(new Error(error));\n        }\n      };\n\n      this.pdfWorker.addEventListener('message', handleWorkerMessage);\n      \n      // Iniciar processamento\n      this.pdfWorker.postMessage({\n        type: 'process-pdf',\n        data: { arrayBuffer, chunkSize: this.config.chunkSize }\n      });\n    });\n  }","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":7,"totalChunks":43,"timestamp":1749642230531}}],["58f00300-4a6f-4583-b120-134e5fe70383",{"pageContent":"// Limpar recursos\n  cleanup() {\n    if (this.pdfWorker) {\n      this.pdfWorker.terminate();\n      this.pdfWorker = null;\n    }\n    this.embeddingCache.clear();\n    this.responseCache.clear();\n  }\n}","metadata":{"source":"src/services/highQualityRAG.service.js","section":"","chunkIndex":16,"totalChunks":17,"timestamp":1749642230531}}],["28b75fc1-d6ff-4658-add1-f7d46c60c5fe",{"pageContent":"onProgress?.({\n              phase: 'extraction',\n              current: data.progress.current,\n              total: data.progress.total,\n              percentage: data.progress.percentage * 0.4, // 40% para extração\n              message: `Extraindo texto: ${data.progress.current}/${data.progress.total} páginas`\n            });\n          } \n          else if (type === 'processing-complete') {\n            // Iniciar fase de embeddings\n            this.pdfWorker.removeEventListener('message', handleWorkerMessage);\n            \n            try {\n              await this.generateAndStoreEmbeddings(allChunks, file.name, onProgress);\n              \n              const processingTime = Date.now() - startTime;\n              const result = {\n                success: true,\n                documentName: file.name,\n                totalPages: processedPages,\n                totalChunks: allChunks.length,\n                processingTime: processingTime,\n                estimatedCost: this.estimateCost(allChunks.length)\n              };\n              \n              resolve(result);\n            } catch (err) {\n              reject(err);\n            }\n          }\n          else if (type === 'error') {\n            this.pdfWorker.removeEventListener('message', handleWorkerMessage);\n            reject(new Error(error));\n          }\n        };\n\n        this.pdfWorker.addEventListener('message', handleWorkerMessage);\n        \n        // Iniciar processamento\n        this.pdfWorker.postMessage({\n          type: 'process-pdf',\n          data: { arrayBuffer, chunkSize: this.config.chunkSize }\n        });\n      }).catch(reject);\n    });\n  }","metadata":{"source":"src/services/highQualityRAG.service.js","section":"","chunkIndex":4,"totalChunks":17,"timestamp":1749642230531}}],["2c8a548b-1e3c-4349-bede-c671c20271a4",{"pageContent":"this.audioChunks = [];\n      this.onDataAvailable = onDataAvailable;\n      this.onStop = onStop;\n\n      this.mediaRecorder.ondataavailable = (event) => {\n        if (event.data.size > 0) {\n          this.audioChunks.push(event.data);\n          if (this.onDataAvailable) {\n            this.onDataAvailable(event.data);\n          }\n        }\n      };\n\n      this.mediaRecorder.onstop = () => {\n        const audioBlob = new Blob(this.audioChunks, { type: AUDIO_CONFIG.AUDIO_TYPE });\n        if (this.onStop) {\n          this.onStop(audioBlob);\n        }\n        this.cleanup();\n      };\n\n      this.mediaRecorder.onerror = (event) => {\n        console.error('MediaRecorder error:', event.error);\n        if (onError) {\n          onError(event.error);\n        } else {\n          throw new Error(ERROR_MESSAGES.MICROPHONE_ACCESS);\n        }\n      };\n\n      this.mediaRecorder.start();\n\n      // Auto-stop after max recording time\n      setTimeout(() => {\n        if (this.isRecording()) {\n          this.stopRecording();\n        }\n      }, AUDIO_CONFIG.MAX_RECORDING_TIME);\n\n    } catch (error) {\n      console.error('Failed to start recording:', error);\n      this.cleanup();\n      throw new Error(ERROR_MESSAGES.MICROPHONE_ACCESS);\n    }\n  }\n\n  /**\n   * Stop audio recording\n   * @returns {void}\n   */\n  stopRecording() {\n    if (this.mediaRecorder && this.mediaRecorder.state !== 'inactive') {\n      this.mediaRecorder.stop();\n    }\n  }\n\n  /**\n   * Check if currently recording\n   * @returns {boolean} Whether recording is active\n   */\n  isRecording() {\n    return this.mediaRecorder && this.mediaRecorder.state === 'recording';\n  }\n\n  /**\n   * Clean up resources\n   * @private\n   */\n  cleanup() {\n    if (this.stream) {\n      this.stream.getTracks().forEach(track => track.stop());\n      this.stream = null;\n    }\n    this.mediaRecorder = null;\n    this.audioChunks = [];\n  }","metadata":{"source":"src/services/audio.service.js","section":"","chunkIndex":2,"totalChunks":5,"timestamp":1749642230531}}],["8e0b704f-0628-47d3-9c31-383392f79396",{"pageContent":"{/* Upload e Gerenciamento */}\n      <Card>\n        <CardBody>\n          <div className=\"flex items-center justify-between mb-4\">\n            <Typography variant=\"h5\">Gerenciamento de Documentos</Typography>\n            {uploadedFile && (\n              <Chip \n                value={uploadedFile.name} \n                color=\"green\" \n                icon={<DocumentIcon className=\"h-4 w-4\" />}\n                onClose={() => {\n                  if (confirm('Deseja remover este documento?')) {\n                    handleReset();\n                  }\n                }}\n              />\n            )}\n          </div>\n          \n          <div className=\"grid grid-cols-1 md:grid-cols-4 gap-3\">\n            {/* Upload PDF */}\n            <input\n              ref={fileInputRef}\n              type=\"file\"\n              accept=\".pdf\"\n              onChange={handleFileUpload}\n              disabled={isProcessing}\n              className=\"hidden\"\n            />\n            <Button\n              onClick={() => fileInputRef.current?.click()}\n              disabled={isProcessing}\n              color=\"blue\"\n              className=\"flex items-center justify-center gap-2\"\n            >\n              <DocumentIcon className=\"h-5 w-5\" />\n              Novo PDF\n            </Button>\n\n            {/* Importar Índice */}\n            <input\n              ref={indexInputRef}\n              type=\"file\"\n              accept=\".json\"\n              onChange={handleImport}\n              disabled={isProcessing}\n              className=\"hidden\"\n            />\n            <Button\n              onClick={() => indexInputRef.current?.click()}\n              variant=\"outlined\"\n              disabled={isProcessing}\n              className=\"flex items-center justify-center gap-2\"\n            >\n              <ArrowUpTrayIcon className=\"h-5 w-5\" />\n              Importar\n            </Button>","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":34,"totalChunks":43,"timestamp":1749642230531}}],["e00ac4fa-8e83-4db5-90b0-92f0d29b14f6",{"pageContent":"hash: hash\n                }\n              });\n            });\n          }\n          \n          page.cleanup();\n        }\n        \n        onProgress?.({\n          phase: 'extraction',\n          current: endPage,\n          total: totalPages,\n          percentage: (endPage / totalPages) * 40,\n          message: `Extraindo texto: ${endPage}/${totalPages} páginas`\n        });\n        \n        // Yield to main thread\n        await new Promise(resolve => setTimeout(resolve, 0));\n      }\n      \n      // Process embeddings\n      await this.generateAndStoreEmbeddings(allChunks, file.name, onProgress);\n      \n      const processingTime = Date.now() - startTime;\n      return {\n        success: true,\n        documentName: file.name,\n        totalPages: totalPages,\n        totalChunks: allChunks.length,\n        processingTime: processingTime,\n        estimatedCost: this.estimateCost(allChunks.length)\n      };\n    } catch (error) {\n      throw new Error(`Erro no processamento do PDF: ${error.message}`);\n    }\n  }","metadata":{"source":"src/services/highQualityRAG.service.js","section":"","chunkIndex":6,"totalChunks":17,"timestamp":1749642230531}}],["22dd03b7-e020-46af-aa88-e85bb41b6695",{"pageContent":"setUploadedFile(file);\n    setIsProcessing(true);\n    setError(null);\n    setProgress(null);\n    setResponse(null);\n\n    try {\n      const result = await ragService.processPDF(file, (prog) => {\n        setProgress(prog);\n      });\n\n      // Obter estatísticas\n      const docStats = await ragService.analyzeDocument();\n      setStats(docStats);\n\n      // Salvar metadados\n      const metadata = {\n        fileName: file.name,\n        processedAt: new Date().toISOString(),\n        stats: docStats,\n        result: result\n      };\n      \n      ConfigService.saveIndexMetadata(metadata);\n\n      setProgress(null);\n      \n      // Notificação de sucesso\n      const notification = `✅ PDF processado com sucesso!\\n\\n` +\n        `📄 ${result.totalPages} páginas\\n` +\n        `📦 ${result.totalChunks} chunks\\n` +\n        `⏱️ ${(result.processingTime / 1000).toFixed(1)}s\\n` +\n        `💰 Custo estimado: $${result.estimatedCost.total.toFixed(4)}`;\n      \n      alert(notification);\n      \n    } catch (err) {\n      setError(err.message);\n    } finally {\n      setIsProcessing(false);\n    }\n  }, [ragService]);\n\n  // Fazer pergunta\n  const handleQuery = useCallback(async () => {\n    if (!query.trim()) return;\n\n    setIsProcessing(true);\n    setError(null);\n    setResponse(null);\n    setIsStreaming(true);\n\n    try {\n      const startTime = Date.now();\n      const result = await ragService.generateResponse(query, {\n        streamResponse: true\n      });\n\n      // Processar stream\n      let fullResponse = '';\n      setResponse({ \n        answer: '', \n        sources: result.sources, \n        isStreaming: true,\n        startTime: startTime \n      });\n\n      for await (const chunk of result.stream) {\n        const content = chunk.choices[0]?.delta?.content || '';\n        fullResponse += content;\n        \n        setResponse(prev => ({\n          ...prev,\n          answer: fullResponse\n        }));\n      }","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":22,"totalChunks":43,"timestamp":1749642230531}}],["f73215d9-dfcc-43ac-a23a-0f76d98d3cac",{"pageContent":"/**\n * @fileoverview PDF processing service\n */\n\nimport * as pdfjsLib from 'pdfjs-dist';\nimport { PDF_CONFIG, ERROR_MESSAGES } from '../constants';\n\n// Configure PDF.js worker\npdfjsLib.GlobalWorkerOptions.workerSrc = PDF_CONFIG.WORKER_SRC;\n\n/**\n * PDF processing service class\n */","metadata":{"source":"src/services/pdf.service.js","section":"","chunkIndex":0,"totalChunks":4,"timestamp":1749642230531}}],["882fb91a-22b4-47a9-88c5-3498e79afef7",{"pageContent":"// Verificar se tem acesso aos modelos necessários\n      const models = await response.json();\n      const hasEmbedding = models.data.some(m => m.id.includes('embedding'));\n      const hasGPT4 = models.data.some(m => m.id.includes('gpt-4'));\n\n      if (!hasEmbedding || !hasGPT4) {\n        throw new Error('Sua API key precisa ter acesso aos modelos de embedding e GPT-4');\n      }\n\n      // Salvar e continuar\n      ConfigService.saveApiKey(apiKey);\n      onComplete();\n    } catch (err) {\n      setError(err.message);\n    } finally {\n      setIsValidating(false);\n    }\n  };\n\n  const loadExistingIndex = () => {\n    // Permitir uso sem API key se há índices salvos\n    ConfigService.saveApiKey('sk-dummy-for-search-only');\n    onComplete();\n  };\n\n  return (\n    <div className=\"min-h-screen flex items-center justify-center bg-gray-50 p-4\">\n      <div className=\"w-full max-w-lg space-y-4\">\n        {/* Card Principal */}\n        <Card>\n          <CardBody className=\"space-y-6\">\n            <div className=\"text-center\">\n              <KeyIcon className=\"h-12 w-12 mx-auto text-blue-500 mb-4\" />\n              <Typography variant=\"h4\" color=\"blue-gray\">\n                Sistema RAG com OpenAI\n              </Typography>\n              <Typography color=\"gray\" className=\"mt-2\">\n                Para processar novos documentos, você precisa fornecer sua API key da OpenAI\n              </Typography>\n            </div>","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":17,"totalChunks":43,"timestamp":1749642230531}}],["303aa47f-615e-474b-ae99-e76a5f962c4b",{"pageContent":"// Utilitários\n  estimateTokens(text) {\n    // Aproximação: ~3 caracteres por token em português\n    return Math.ceil(text.length / 3);\n  }\n\n  generateHash(text) {\n    // Hash simples para cache\n    let hash = 0;\n    for (let i = 0; i < text.length; i++) {\n      const char = text.charCodeAt(i);\n      hash = ((hash << 5) - hash) + char;\n      hash = hash & hash;\n    }\n    return hash.toString(36);\n  }\n\n  calculateImportance(text, pageNum, totalPages) {\n    let score = 1.0;\n    \n    // Primeiras páginas (resumo, introdução)\n    if (pageNum <= 3) score *= 1.3;\n    \n    // Últimas páginas (conclusão)\n    if (pageNum >= totalPages - 2) score *= 1.2;\n    \n    // Títulos e subtítulos (heurística)\n    if (text.match(/^[A-Z\\s\\d\\.]{3,50}$/m)) score *= 1.4;\n    \n    // Parágrafos com números e dados\n    const numbers = text.match(/\\d+\\.?\\d*/g) || [];\n    if (numbers.length > 5) score *= 1.2;\n    \n    // Listas e enumerações\n    if (text.match(/^\\s*[\\d\\-\\*•]\\s+/m)) score *= 1.1;\n    \n    // Chunks mais longos (mais contexto)\n    if (text.length > 600) score *= 1.1;\n    \n    return Math.min(score, 2.0);\n  }\n\n  calculatePercentiles(values) {\n    if (!values.length) return {};\n    \n    const sorted = values.sort((a, b) => a - b);\n    const percentiles = {};\n    \n    [25, 50, 75, 90, 95].forEach(p => {\n      const index = Math.floor((p / 100) * sorted.length);\n      percentiles[`p${p}`] = sorted[index];\n    });\n    \n    return percentiles;\n  }\n\n  estimateCost(totalChunks) {\n    const tokensPerChunk = this.config.chunkSize;\n    const totalTokens = totalChunks * tokensPerChunk;\n    \n    return {\n      embedding: {\n        model: this.config.embeddingModel,\n        tokens: totalTokens,\n        cost: (totalTokens / 1000) * 0.00013 // $0.00013 per 1K tokens\n      },\n      total: (totalTokens / 1000) * 0.00013\n    };\n  }","metadata":{"source":"src/services/highQualityRAG.service.js","section":"","chunkIndex":15,"totalChunks":17,"timestamp":1749642230531}}],["a878b28c-d90a-4607-a2f0-b2c4a2af3eaf",{"pageContent":"function reconstructPageText(textContent) {\n  const lines = {};\n  \n  // Handle both array and object formats\n  const items = textContent.items || textContent;\n  if (!items || !Array.isArray(items)) {\n    return '';\n  }\n  \n  items.forEach(item => {\n    // Ensure item has required properties\n    if (!item.transform || !item.str) return;\n    \n    const y = Math.round(item.transform[5]);\n    if (!lines[y]) lines[y] = [];\n    lines[y].push(item);\n  });\n  \n  return Object.keys(lines)\n    .sort((a, b) => b - a)\n    .map(y => {\n      return lines[y]\n        .sort((a, b) => a.transform[4] - b.transform[4])\n        .map(item => item.str || '')\n        .join(' ')\n        .trim();\n    })\n    .filter(line => line.length > 0)\n    .join('\\n');\n}","metadata":{"source":"src/workers/pdf.worker.js","section":"","chunkIndex":2,"totalChunks":3,"timestamp":1749642230531}}],["0b2a0f01-2b62-4f68-be4f-378ad19a4d1d",{"pageContent":"/**\n * @fileoverview Custom hook for PDF processing\n */\n\nimport { useState, useCallback, useMemo } from 'react';\nimport { createPDFService } from '../services/pdf.service';\n\n/**\n * Custom hook for PDF processing\n * @returns {Object} PDF utilities and state\n */","metadata":{"source":"src/hooks/usePDF.js","section":"","chunkIndex":0,"totalChunks":3,"timestamp":1749642230531}}],["cbbdbe14-b75c-4438-9526-0e000d8bfc5b",{"pageContent":"/**\n   * Transcribe audio using OpenAI Whisper\n   * @param {Blob} audioBlob - Audio data to transcribe\n   * @param {string} language - Language code (default: 'pt')\n   * @returns {Promise<string>} Transcribed text\n   * @throws {Error} When transcription fails\n   */\n  async transcribeAudio(audioBlob, language = 'pt') {\n    try {\n      const formData = new FormData();\n      formData.append('file', audioBlob, 'audio.webm');\n      formData.append('model', OPENAI_CONFIG.WHISPER_MODEL);\n      formData.append('language', language);\n\n      const response = await fetch(API_ENDPOINTS.OPENAI_TRANSCRIPTIONS, {\n        method: 'POST',\n        headers: {\n          'Authorization': `Bearer ${this.apiKey}`,\n        },\n        body: formData\n      });\n\n      if (!response.ok) {\n        throw new Error(`HTTP ${response.status}: ${response.statusText}`);\n      }\n\n      const data = await response.json();\n      return data.text || '';\n    } catch (error) {\n      console.error('Transcription failed:', error);\n      throw new Error(ERROR_MESSAGES.TRANSCRIPTION_FAILED);\n    }\n  }\n}\n\n/**\n * Create OpenAI service instance\n * @param {string} apiKey - OpenAI API key\n * @returns {OpenAIService} Service instance\n */","metadata":{"source":"src/services/openai.service.js","section":"","chunkIndex":2,"totalChunks":4,"timestamp":1749642230531}}],["8cc6af7a-ff1c-4c8b-b88a-f2cce129ce37",{"pageContent":"// Configurar worker do PDF.js\npdfjsLib.GlobalWorkerOptions.workerSrc = `//cdnjs.cloudflare.com/ajax/libs/pdf.js/${pdfjsLib.version}/pdf.worker.min.js`;\n\nself.onmessage = async function(event) {\n  const { type, data } = event.data;\n  \n  if (type === 'process-pdf') {\n    try {\n      const { arrayBuffer, chunkSize } = data;\n      const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise;\n      const totalPages = pdf.numPages;\n      const chunks = [];\n      \n      // Processar em batches de páginas\n      const PAGES_PER_BATCH = 5;\n      \n      for (let startPage = 1; startPage <= totalPages; startPage += PAGES_PER_BATCH) {\n        const endPage = Math.min(startPage + PAGES_PER_BATCH - 1, totalPages);\n        const batchChunks = [];\n        \n        for (let pageNum = startPage; pageNum <= endPage; pageNum++) {\n          const page = await pdf.getPage(pageNum);\n          const textContent = await page.getTextContent();\n          \n          // Reconstruir texto preservando estrutura\n          const pageText = reconstructPageText(textContent);\n          \n          batchChunks.push({\n            pageNumber: pageNum,\n            text: pageText,\n            estimatedTokens: Math.ceil(pageText.length / 3)\n          });\n          \n          page.cleanup();\n        }\n        \n        // Enviar batch processado\n        self.postMessage({\n          type: 'batch-complete',\n          data: {\n            chunks: batchChunks,\n            progress: {\n              current: endPage,\n              total: totalPages,\n              percentage: (endPage / totalPages) * 100\n            }\n          }\n        });\n        \n        // Pequena pausa para não sobrecarregar\n        await new Promise(resolve => setTimeout(resolve, 10));\n      }\n      \n      self.postMessage({ type: 'processing-complete' });\n      \n    } catch (error) {\n      self.postMessage({\n        type: 'error',\n        error: error.message\n      });\n    }\n  }\n};","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":3,"totalChunks":43,"timestamp":1749642230531}}],["723eaf9f-f3ed-4897-a103-e3190cd143b2",{"pageContent":"export class AudioService {\n  constructor() {\n    this.mediaRecorder = null;\n    this.stream = null;\n    this.audioChunks = [];\n    this.onDataAvailable = null;\n    this.onStop = null;\n  }\n\n  /**\n   * Check if audio recording is supported\n   * @returns {boolean} Whether audio recording is supported\n   */\n  isSupported() {\n    return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia && window.MediaRecorder);\n  }\n\n  /**\n   * Request microphone permission\n   * @returns {Promise<boolean>} Whether permission was granted\n   */\n  async requestPermission() {\n    if (!this.isSupported()) {\n      throw new Error('Audio recording is not supported in this browser');\n    }\n\n    try {\n      const stream = await navigator.mediaDevices.getUserMedia(AUDIO_CONFIG.CONSTRAINTS);\n      // Stop the stream immediately after getting permission\n      stream.getTracks().forEach(track => track.stop());\n      return true;\n    } catch (error) {\n      console.error('Microphone permission denied:', error);\n      return false;\n    }\n  }\n\n  /**\n   * Start audio recording\n   * @param {Object} options - Recording options\n   * @param {function} options.onDataAvailable - Callback for data chunks\n   * @param {function} options.onStop - Callback when recording stops\n   * @param {function} options.onError - Callback for errors\n   * @returns {Promise<void>}\n   * @throws {Error} When recording fails to start\n   */\n  async startRecording({ onDataAvailable, onStop, onError } = {}) {\n    if (!this.isSupported()) {\n      throw new Error('Audio recording is not supported');\n    }\n\n    try {\n      this.stream = await navigator.mediaDevices.getUserMedia(AUDIO_CONFIG.CONSTRAINTS);\n      this.mediaRecorder = new MediaRecorder(this.stream, {\n        mimeType: AUDIO_CONFIG.AUDIO_TYPE\n      });\n\n      this.audioChunks = [];\n      this.onDataAvailable = onDataAvailable;\n      this.onStop = onStop;","metadata":{"source":"src/services/audio.service.js","section":"","chunkIndex":1,"totalChunks":5,"timestamp":1749642230531}}],["3a4d728b-be24-4d61-a310-628a0802922f",{"pageContent":"if (type === 'batch-complete') {\n            processedPages += data.chunks.length;\n            \n            // Processar chunks do batch\n            for (const pageData of data.chunks) {\n              const chunks = await this.splitter.splitText(pageData.text);\n              \n              chunks.forEach((chunk, index) => {\n                const hash = this.generateHash(chunk);\n                \n                allChunks.push({\n                  text: chunk,\n                  metadata: {\n                    pageNumber: pageData.pageNumber,\n                    chunkIndex: index,\n                    source: file.name,\n                    totalTokens: this.estimateTokens(chunk),\n                    importance: this.calculateImportance(chunk, pageData.pageNumber, 100), // Assumindo 100 páginas max\n                    hash: hash\n                  }\n                });\n              });\n            }","metadata":{"source":"src/services/highQualityRAG.service.js","section":"","chunkIndex":3,"totalChunks":17,"timestamp":1749642230531}}],["5d212808-8318-4374-b290-0ce0126b6eea",{"pageContent":"export class HighQualityRAGService {\n  constructor() {\n    this.openai = null;\n    this.db = null;\n    this.initialized = false;\n    this.pdfWorker = null;\n    \n    // Configurações otimizadas para qualidade máxima\n    this.config = {\n      embeddingModel: 'text-embedding-3-large',\n      embeddingDimensions: 3072,\n      chatModel: 'gpt-4o-mini', // Updated to current available model\n      chunkSize: 800,\n      chunkOverlap: 200,\n      temperature: 0.2,\n      maxTokens: 4000,\n      topK: 10,\n      similarityThreshold: 0.7,\n      batchSize: 5,\n      maxRetries: 3,\n      retryDelay: 1000\n    };\n\n    this.splitter = new SimpleTextSplitter({\n      chunkSize: this.config.chunkSize,\n      chunkOverlap: this.config.chunkOverlap,\n      separators: [\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \"; \", \": \", \" \"]\n    });\n    \n    // Cache de embeddings para evitar reprocessamento\n    this.embeddingCache = new Map();\n  }\n\n  async initialize() {\n    try {\n      const apiKey = ConfigService.getApiKey();\n      if (!apiKey) {\n        throw new Error('API key não configurada');\n      }\n\n      // Test API key before proceeding\n      this.openai = new OpenAI({\n        apiKey: apiKey,\n        dangerouslyAllowBrowser: true\n      });\n\n      // Test OpenAI connection\n      try {\n        await this.openai.models.list();\n      } catch (apiError) {\n        throw new Error(`Erro na API OpenAI: ${apiError.message}`);\n      }\n\n      // Criar banco vetorial otimizado\n      this.db = await create({\n        schema: {\n          id: 'string',\n          text: 'string',\n          embedding: `vector[${this.config.embeddingDimensions}]`,\n          pageNumber: 'number',\n          source: 'string', \n          chunkIndex: 'number',\n          totalTokens: 'number',\n          importance: 'number',\n          hash: 'string'\n        }\n      });","metadata":{"source":"src/services/highQualityRAG.service.js","section":"","chunkIndex":1,"totalChunks":17,"timestamp":1749642230531}}],["d67b8f07-cdc2-45e1-8a27-2baac8cb83e9",{"pageContent":"### Layout de Landing Page\n```jsx\nexport function LandingPageLayout() {\n  return (\n    <>\n      {/* Hero Section */}\n      <div className=\"relative flex h-screen content-center items-center justify-center pt-16 pb-32\">\n        <div className=\"absolute top-0 h-full w-full bg-[url('/img/background-1.jpg')] bg-cover bg-center\" />\n        <div className=\"absolute top-0 h-full w-full bg-black/75 bg-cover bg-center\" />\n        <div className=\"max-w-8xl container relative mx-auto\">\n          <div className=\"flex flex-wrap items-center\">\n            <div className=\"ml-auto mr-auto w-full px-4 text-center lg:w-8/12\">\n              <Typography variant=\"h1\" color=\"white\" className=\"mb-6 font-black\">\n                Your story starts with us.\n              </Typography>\n              <Typography variant=\"lead\" color=\"white\" className=\"opacity-80\">\n                This is a simple example of a Landing Page you can build using\n                Material Tailwind. It features multiple CSS components\n              </Typography>\n            </div>\n          </div>\n        </div>\n      </div>\n\n      {/* Features Section */}\n      <section className=\"-mt-32 bg-white px-4 pb-20 pt-4\">\n        <div className=\"container mx-auto\">\n          <div className=\"grid grid-cols-1 gap-6 md:grid-cols-2 lg:grid-cols-3\">\n            {/* Feature cards */}\n          </div>\n        </div>\n      </section>\n    </>\n  );\n}\n```\n\n## 10. Troubleshooting comum e soluções\n\n### Problema 1: Erros de configuração TypeScript\n\n**Solução para conflito de versão @types/react**\n```bash\n# Deletar node_modules e package-lock.json\nrm -rf node_modules package-lock.json\n\n# Downgrade da versão @types/react no package.json\n\"@types/react\": \"18.2.42\"  # Nota: Sem o símbolo ^\n\nnpm install\n```\n\n**Resolução de módulo em tsconfig.json**\n```json\n{\n  \"compilerOptions\": {\n    \"moduleResolution\": \"node\"\n  }\n}\n```\n\n### Problema 2: Conflitos com Tailwind CSS","metadata":{"source":"docs/Material-Tailwind-Guia-Completo.md","section":"","chunkIndex":12,"totalChunks":15,"timestamp":1749642230531}}],["91723c7c-07f1-49ad-a75c-e05351a97a30",{"pageContent":"async initialize() {\n    const apiKey = ConfigService.getApiKey();\n    if (!apiKey) {\n      throw new Error('API key não configurada');\n    }\n\n    this.openai = new OpenAI({\n      apiKey: apiKey,\n      dangerouslyAllowBrowser: true\n    });\n\n    // Criar banco vetorial otimizado\n    this.db = await create({\n      schema: {\n        id: 'string',\n        text: 'string',\n        embedding: `vector[${this.config.embeddingDimensions}]`,\n        metadata: {\n          pageNumber: 'number',\n          source: 'string',\n          chunkIndex: 'number',\n          totalTokens: 'number',\n          importance: 'number',\n          hash: 'string' // Para cache\n        }\n      },\n      components: {\n        tokenizer: {\n          language: 'portuguese' // Otimizado para português\n        }\n      }\n    });\n\n    // Inicializar Web Worker\n    this.pdfWorker = new Worker(new URL('../workers/pdf.worker.js', import.meta.url), {\n      type: 'module'\n    });\n\n    this.initialized = true;\n  }\n\n  // Processar PDF com Web Worker\n  async processPDF(file, onProgress) {\n    if (!this.initialized) {\n      await this.initialize();\n    }\n\n    return new Promise(async (resolve, reject) => {\n      const startTime = Date.now();\n      const arrayBuffer = await file.arrayBuffer();\n      const allChunks = [];\n      let processedPages = 0;\n\n      // Listener para mensagens do worker\n      const handleWorkerMessage = async (event) => {\n        const { type, data, error } = event.data;","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":5,"totalChunks":43,"timestamp":1749642230531}}],["fb3f4b9c-993d-44aa-abe7-1b4642ab500d",{"pageContent":"export const createOpenAIService = (apiKey) => {\n  if (!apiKey) {\n    throw new Error('OpenAI API key is required');\n  }\n  return new OpenAIService(apiKey);\n};","metadata":{"source":"src/services/openai.service.js","section":"","chunkIndex":3,"totalChunks":4,"timestamp":1749642230531}}],["80c649e9-0bea-4014-b38c-89f67a2d6bc0",{"pageContent":"// Gerar e armazenar embeddings com retry e cache\n  async generateAndStoreEmbeddings(chunks, sourceName, onProgress) {\n    const totalChunks = chunks.length;\n    let processedChunks = 0;\n    \n    // Processar em batches\n    for (let i = 0; i < totalChunks; i += this.config.batchSize) {\n      const batch = chunks.slice(i, i + this.config.batchSize);\n      \n      // Verificar cache primeiro\n      const embeddings = await Promise.all(\n        batch.map(async (chunk) => {\n          if (this.embeddingCache.has(chunk.metadata.hash)) {\n            return this.embeddingCache.get(chunk.metadata.hash);\n          }\n          \n          // Gerar com retry\n          const embedding = await this.generateEmbeddingWithRetry(chunk.text);\n          this.embeddingCache.set(chunk.metadata.hash, embedding);\n          return embedding;\n        })\n      );\n      \n      // Inserir no banco vetorial\n      for (let j = 0; j < batch.length; j++) {\n        const chunk = batch[j];\n        const embedding = embeddings[j];\n        \n        await insert(this.db, {\n          id: `${sourceName}_p${chunk.metadata.pageNumber}_c${chunk.metadata.chunkIndex}`,\n          text: chunk.text,\n          embedding: embedding,\n          pageNumber: chunk.metadata.pageNumber,\n          source: chunk.metadata.source,\n          chunkIndex: chunk.metadata.chunkIndex,\n          totalTokens: chunk.metadata.totalTokens,\n          importance: chunk.metadata.importance,\n          hash: chunk.metadata.hash\n        });\n      }\n      \n      processedChunks += batch.length;\n      \n      onProgress?.({\n        phase: 'embedding',\n        current: processedChunks,\n        total: totalChunks,\n        percentage: 40 + (processedChunks / totalChunks) * 60, // 40-100%\n        message: `Gerando embeddings: ${processedChunks}/${totalChunks} chunks`\n      });\n      \n      // Rate limiting\n      if (i + this.config.batchSize < totalChunks) {\n        await new Promise(resolve => setTimeout(resolve, 200));\n      }\n    }\n  }","metadata":{"source":"src/services/highQualityRAG.service.js","section":"","chunkIndex":7,"totalChunks":17,"timestamp":1749642230531}}],["b43d6702-86ea-4767-85a1-28886086fa97",{"pageContent":"/**\n * @fileoverview Utility functions for formatting data\n */\n\n/**\n * Format file size in human-readable format\n * @param {number} bytes - File size in bytes\n * @param {number} [decimals=2] - Number of decimal places\n * @returns {string} Formatted file size\n * \n * @example\n * formatFileSize(1024) // \"1.00 KB\"\n * formatFileSize(1048576) // \"1.00 MB\"\n */\nexport function formatFileSize(bytes, decimals = 2) {\n  if (bytes === 0) return '0 Bytes';\n\n  const k = 1024;\n  const dm = decimals < 0 ? 0 : decimals;\n  const sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB'];\n\n  const i = Math.floor(Math.log(bytes) / Math.log(k));\n\n  return parseFloat((bytes / Math.pow(k, i)).toFixed(dm)) + ' ' + sizes[i];\n}\n\n/**\n * Format duration in MM:SS format\n * @param {number} seconds - Duration in seconds\n * @returns {string} Formatted duration\n * \n * @example\n * formatDuration(65) // \"01:05\"\n * formatDuration(3661) // \"61:01\"\n */\nexport function formatDuration(seconds) {\n  const minutes = Math.floor(seconds / 60);\n  const remainingSeconds = seconds % 60;\n  return `${minutes.toString().padStart(2, '0')}:${remainingSeconds.toString().padStart(2, '0')}`;\n}","metadata":{"source":"src/utils/format.js","section":"","chunkIndex":0,"totalChunks":1,"timestamp":1749642230531}}],["4ab37d2b-0997-4ab9-9715-e9c69ae26623",{"pageContent":"{/* Distribuição de tokens */}\n            {stats.tokenPercentiles && (\n              <Card>\n                <CardBody>\n                  <Typography variant=\"h6\" className=\"mb-3\">\n                    Distribuição de Tokens por Chunk\n                  </Typography>\n                  <div className=\"space-y-2\">\n                    <div className=\"flex justify-between\">\n                      <Typography variant=\"small\">Percentil 25:</Typography>\n                      <Typography variant=\"small\" className=\"font-medium\">\n                        {stats.tokenPercentiles.p25} tokens\n                      </Typography>\n                    </div>\n                    <div className=\"flex justify-between\">\n                      <Typography variant=\"small\">Mediana (P50):</Typography>\n                      <Typography variant=\"small\" className=\"font-medium\">\n                        {stats.tokenPercentiles.p50} tokens\n                      </Typography>\n                    </div>\n                    <div className=\"flex justify-between\">\n                      <Typography variant=\"small\">Percentil 75:</Typography>\n                      <Typography variant=\"small\" className=\"font-medium\">\n                        {stats.tokenPercentiles.p75} tokens\n                      </Typography>\n                    </div>\n                    <div className=\"flex justify-between\">\n                      <Typography variant=\"small\">Percentil 95:</Typography>\n                      <Typography variant=\"small\" className=\"font-medium\">\n                        {stats.tokenPercentiles.p95} tokens\n                      </Typography>\n                    </div>\n                  </div>\n                </CardBody>\n              </Card>\n            )}","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":27,"totalChunks":43,"timestamp":1749642230531}}],["3b245104-6b73-46ca-838b-8f64cde06755",{"pageContent":"// Gerar e armazenar embeddings com retry e cache\n  async generateAndStoreEmbeddings(chunks, sourceName, onProgress) {\n    const totalChunks = chunks.length;\n    let processedChunks = 0;\n    \n    // Processar em batches\n    for (let i = 0; i < totalChunks; i += this.config.batchSize) {\n      const batch = chunks.slice(i, i + this.config.batchSize);\n      \n      // Verificar cache primeiro\n      const embeddings = await Promise.all(\n        batch.map(async (chunk) => {\n          if (this.embeddingCache.has(chunk.metadata.hash)) {\n            return this.embeddingCache.get(chunk.metadata.hash);\n          }\n          \n          // Gerar com retry\n          const embedding = await this.generateEmbeddingWithRetry(chunk.text);\n          this.embeddingCache.set(chunk.metadata.hash, embedding);\n          return embedding;\n        })\n      );\n      \n      // Inserir no banco vetorial\n      for (let j = 0; j < batch.length; j++) {\n        const chunk = batch[j];\n        const embedding = embeddings[j];\n        \n        await insert(this.db, {\n          id: `${sourceName}_p${chunk.metadata.pageNumber}_c${chunk.metadata.chunkIndex}`,\n          text: chunk.text,\n          embedding: embedding,\n          metadata: chunk.metadata\n        });\n      }\n      \n      processedChunks += batch.length;\n      \n      onProgress?.({\n        phase: 'embedding',\n        current: processedChunks,\n        total: totalChunks,\n        percentage: 40 + (processedChunks / totalChunks) * 60, // 40-100%\n        message: `Gerando embeddings: ${processedChunks}/${totalChunks} chunks`\n      });\n      \n      // Rate limiting\n      if (i + this.config.batchSize < totalChunks) {\n        await new Promise(resolve => setTimeout(resolve, 200));\n      }\n    }\n  }","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":8,"totalChunks":43,"timestamp":1749642230531}}],["b1a00ccb-c913-4915-b271-f3bcc96c7fd5",{"pageContent":"<div className=\"space-y-4\">\n              <div>\n                <Input\n                  type=\"password\"\n                  label=\"API Key da OpenAI\"\n                  value={apiKey}\n                  onChange={(e) => setApiKey(e.target.value)}\n                  placeholder=\"sk-...\"\n                  error={!!error}\n                  icon={<KeyIcon className=\"h-5 w-5\" />}\n                />\n                {error && (\n                  <Typography variant=\"small\" color=\"red\" className=\"mt-1 flex items-center gap-1\">\n                    <ExclamationTriangleIcon className=\"h-4 w-4\" />\n                    {error}\n                  </Typography>\n                )}\n              </div>\n\n              <Button\n                onClick={validateAndSaveKey}\n                disabled={!apiKey || isValidating}\n                className=\"w-full\"\n                color=\"blue\"\n              >\n                {isValidating ? 'Validando...' : 'Continuar com API Key'}\n              </Button>\n\n              <div className=\"text-center space-y-2\">\n                <Typography variant=\"small\" color=\"gray\">\n                  Sua API key será armazenada apenas nesta sessão\n                </Typography>\n                <Typography variant=\"small\">\n                  <a \n                    href=\"https://platform.openai.com/api-keys\" \n                    target=\"_blank\" \n                    rel=\"noopener noreferrer\"\n                    className=\"text-blue-500 hover:underline\"\n                  >\n                    Obter API key →\n                  </a>\n                </Typography>\n              </div>\n            </div>\n          </CardBody>\n        </Card>","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":18,"totalChunks":43,"timestamp":1749642230531}}],["f48be6aa-eb4c-44d6-8917-33d481035075",{"pageContent":"# Material Tailwind: Pesquisa Extensiva e Guia Completo\n\nMaterial Tailwind é uma biblioteca de componentes que une o poder do Tailwind CSS com os princípios do Material Design, oferecendo **mais de 460 componentes** prontos para uso com mais de **3.1 milhões de instalações** no NPM e **53.000+ projetos ativos**. A biblioteca está disponível para React e HTML, mantendo total compatibilidade com Tailwind CSS v3 e oferecendo versões gratuita e Pro.\n\n## 1. Guia completo de instalação e configuração em projetos React\n\n### Pré-requisitos essenciais\nPara instalar Material Tailwind com sucesso, você precisa de Node.js v16.14.0 ou superior e um projeto React configurado. A biblioteca requer Tailwind CSS como dependência peer.\n\n### Processo de instalação passo a passo\n\n**Etapa 1: Instalar Tailwind CSS**\n```bash\n# Para Create React App ou projetos React existentes\nnpm install -D tailwindcss postcss autoprefixer\nnpx tailwindcss init -p\n```\n\n**Etapa 2: Instalar Material Tailwind React**\n```bash\nnpm install @material-tailwind/react\n# ou usando Yarn\nyarn add @material-tailwind/react\n```\n\n**Etapa 3: Configurar Tailwind com Material Tailwind**\n```javascript\n// tailwind.config.js\nconst withMT = require(\"@material-tailwind/react/utils/withMT\");\n\nmodule.exports = withMT({\n  content: [\"./src/**/*.{js,jsx,ts,tsx}\"],\n  theme: {\n    extend: {},\n  },\n  plugins: [],\n});\n```\n\n**Etapa 4: Adicionar diretivas Tailwind ao CSS**\n```css\n/* src/index.css */\n@tailwind base;\n@tailwind components;\n@tailwind utilities;\n```\n\n**Etapa 5: Configurar ThemeProvider**\n```javascript\n// src/index.js ou src/main.jsx\nimport React from \"react\";\nimport ReactDOM from \"react-dom/client\";\nimport App from \"./App\";\nimport \"./index.css\";\nimport { ThemeProvider } from \"@material-tailwind/react\";\n\nconst root = ReactDOM.createRoot(document.getElementById(\"root\"));\nroot.render(\n  <React.StrictMode>\n    <ThemeProvider>\n      <App />\n    </ThemeProvider>\n  </React.StrictMode>\n);\n```","metadata":{"source":"docs/Material-Tailwind-Guia-Completo.md","section":"","chunkIndex":0,"totalChunks":15,"timestamp":1749642230531}}],["68017e40-8145-43c6-9de5-b2d60a000e61",{"pageContent":"// Gerar embedding com retry automático\n  async generateEmbeddingWithRetry(text, retries = 0) {\n    try {\n      const response = await this.openai.embeddings.create({\n        model: this.config.embeddingModel,\n        input: text,\n        dimensions: this.config.embeddingDimensions\n      });\n      \n      return response.data[0].embedding;\n    } catch (error) {\n      if (retries < this.config.maxRetries) {\n        await new Promise(resolve => setTimeout(resolve, this.config.retryDelay * (retries + 1)));\n        return this.generateEmbeddingWithRetry(text, retries + 1);\n      }\n      throw error;\n    }\n  }\n\n  // Busca semântica otimizada\n  async searchSemantic(query, options = {}) {\n    try {\n      if (!this.initialized || !this.db) {\n        throw new Error('Sistema não inicializado');\n      }\n\n      if (!query || query.trim().length === 0) {\n        return [];\n      }\n\n      const {\n        limit = this.config.topK,\n        threshold = this.config.similarityThreshold,\n        useReranking = true,\n        includeContext = true\n      } = options;\n\n      // Gerar embedding da query com cache\n      const queryHash = this.generateHash(query);\n      let queryEmbedding;\n      \n      try {\n        if (this.embeddingCache.has(queryHash)) {\n          queryEmbedding = this.embeddingCache.get(queryHash);\n        } else {\n          queryEmbedding = await this.generateEmbeddingWithRetry(query);\n          this.embeddingCache.set(queryHash, queryEmbedding);\n        }\n      } catch (embedError) {\n        throw new Error(`Erro ao gerar embedding: ${embedError.message}`);\n      }","metadata":{"source":"src/services/highQualityRAG.service.js","section":"","chunkIndex":8,"totalChunks":17,"timestamp":1749642230531}}],["690c3c6e-d4e3-4fd6-a6ae-a54e96e81ede",{"pageContent":"// UI de estatísticas\n  const StatsDialog = () => (\n    <Dialog open={showStats} handler={() => setShowStats(false)} size=\"xl\">\n      <DialogHeader>\n        <div className=\"flex items-center gap-2\">\n          <ChartBarIcon className=\"h-6 w-6\" />\n          Estatísticas do Documento\n        </div>\n      </DialogHeader>\n      <DialogBody className=\"overflow-y-auto max-h-[70vh]\">\n        {stats && (\n          <div className=\"space-y-6\">\n            {/* Cards de estatísticas principais */}\n            <div className=\"grid grid-cols-2 md:grid-cols-4 gap-4\">\n              <Card className=\"bg-blue-50\">\n                <CardBody className=\"text-center\">\n                  <Typography variant=\"h6\" color=\"blue\">Total de Chunks</Typography>\n                  <Typography variant=\"h3\" color=\"blue-gray\">\n                    {stats.totalChunks}\n                  </Typography>\n                </CardBody>\n              </Card>\n              \n              <Card className=\"bg-green-50\">\n                <CardBody className=\"text-center\">\n                  <Typography variant=\"h6\" color=\"green\">Total de Tokens</Typography>\n                  <Typography variant=\"h3\" color=\"blue-gray\">\n                    {(stats.totalTokens / 1000).toFixed(1)}k\n                  </Typography>\n                </CardBody>\n              </Card>\n              \n              <Card className=\"bg-orange-50\">\n                <CardBody className=\"text-center\">\n                  <Typography variant=\"h6\" color=\"orange\">Páginas</Typography>\n                  <Typography variant=\"h3\" color=\"blue-gray\">\n                    {stats.pagesProcessed}\n                  </Typography>\n                </CardBody>\n              </Card>\n              \n              <Card className=\"bg-purple-50\">\n                <CardBody className=\"text-center\">\n                  <Typography variant=\"h6\" color=\"purple\">Média/Chunk</Typography>\n                  <Typography variant=\"h3\" color=\"blue-gray\">","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":25,"totalChunks":43,"timestamp":1749642230531}}],["9ca70f47-c1d1-41fc-bf81-a105aa998a58",{"pageContent":"import * as pdfjsLib from 'pdfjs-dist';\n\n// Configurar worker do PDF.js - use absolute URLs for better compatibility\npdfjsLib.GlobalWorkerOptions.workerSrc = 'https://cdn.jsdelivr.net/npm/pdfjs-dist@5.3.31/build/pdf.worker.min.mjs';","metadata":{"source":"src/workers/pdf.worker.js","section":"","chunkIndex":0,"totalChunks":3,"timestamp":1749642230531}}],["d65e8a82-82fd-46ae-b759-3c39ba74fd44",{"pageContent":"export class SimpleTextSplitter {\n  constructor({ chunkSize = 800, chunkOverlap = 200, separators = [\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \"; \", \": \", \" \"] }) {\n    this.chunkSize = chunkSize;\n    this.chunkOverlap = chunkOverlap;\n    this.separators = separators;\n  }\n\n  async splitText(text) {\n    if (!text || typeof text !== 'string') {\n      return [];\n    }\n\n    // Normalize text\n    text = text.trim();\n    if (text.length <= this.chunkSize) {\n      return [text];\n    }\n\n    const chunks = [];\n    let currentChunk = '';\n    const sentences = this.splitBySeparators(text);\n\n    for (const sentence of sentences) {\n      // If adding this sentence would exceed chunk size\n      if (currentChunk && (currentChunk.length + sentence.length + 1) > this.chunkSize) {\n        // Add current chunk if it has content\n        if (currentChunk.trim()) {\n          chunks.push(currentChunk.trim());\n        }\n\n        // Start new chunk with overlap from previous chunk\n        if (chunks.length > 0 && this.chunkOverlap > 0) {\n          const prevChunk = chunks[chunks.length - 1];\n          const overlapText = this.getOverlap(prevChunk, this.chunkOverlap);\n          currentChunk = overlapText ? overlapText + ' ' + sentence : sentence;\n        } else {\n          currentChunk = sentence;\n        }\n      } else {\n        // Add sentence to current chunk\n        currentChunk = currentChunk ? currentChunk + ' ' + sentence : sentence;\n      }\n    }\n\n    // Add the last chunk if it has content\n    if (currentChunk.trim()) {\n      chunks.push(currentChunk.trim());\n    }\n\n    return chunks.filter(chunk => chunk.length > 0);\n  }","metadata":{"source":"src/utils/textSplitter.js","section":"","chunkIndex":0,"totalChunks":2,"timestamp":1749642230531}}],["7800e762-a9a4-4b58-8976-c0978e3fdbfb",{"pageContent":"export class PDFService {\n  /**\n   * Validate PDF file before processing\n   * @param {File} file - PDF file to validate\n   * @throws {Error} When file is invalid\n   */\n  validateFile(file) {\n    if (!file) {\n      throw new Error('No file provided');\n    }\n\n    if (file.size > PDF_CONFIG.MAX_FILE_SIZE) {\n      throw new Error(ERROR_MESSAGES.FILE_TOO_LARGE);\n    }\n\n    if (!PDF_CONFIG.ACCEPTED_TYPES.includes(file.type)) {\n      throw new Error(ERROR_MESSAGES.INVALID_FILE_TYPE);\n    }\n  }\n\n  /**\n   * Extract text from PDF file\n   * @param {File} file - PDF file to process\n   * @param {function} onProgress - Progress callback (optional)\n   * @returns {Promise<{content: string, pageCount: number, extractedAt: Date}>}\n   * @throws {Error} When extraction fails\n   */\n  async extractText(file, onProgress) {\n    this.validateFile(file);\n\n    try {\n      // Convert file to ArrayBuffer\n      const arrayBuffer = await file.arrayBuffer();\n      \n      // Load PDF document\n      const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise;\n      let fullText = '';\n\n      // Extract text from each page\n      for (let i = 1; i <= pdf.numPages; i++) {\n        const page = await pdf.getPage(i);\n        const textContent = await page.getTextContent();\n        \n        // Group items by line based on Y position\n        const lines = {};\n        textContent.items.forEach(item => {\n          const y = Math.round(item.transform[5]);\n          if (!lines[y]) lines[y] = [];\n          lines[y].push(item);\n        });\n        \n        // Sort lines and concatenate text\n        const sortedLines = Object.keys(lines).sort((a, b) => b - a);\n        const pageText = sortedLines.map(y => {\n          return lines[y]\n            .sort((a, b) => a.transform[4] - b.transform[4])\n            .map(item => item.str)\n            .join('')\n            .trim();\n        }).filter(line => line).join('\\n');\n        \n        fullText += pageText + '\\n\\n';","metadata":{"source":"src/services/pdf.service.js","section":"","chunkIndex":1,"totalChunks":4,"timestamp":1749642230531}}],["1f177142-60ee-4496-aefe-8cc6af3fb73a",{"pageContent":"// Listener para mensagens do worker\n      const handleWorkerMessage = async (event) => {\n        const { type, data, error } = event.data;\n\n        if (type === 'batch-complete') {\n          processedPages += data.chunks.length;\n          \n          // Processar chunks do batch\n          for (const pageData of data.chunks) {\n            const chunks = await this.splitter.splitText(pageData.text);\n            \n            chunks.forEach((chunk, index) => {\n              const hash = this.generateHash(chunk);\n              \n              allChunks.push({\n                text: chunk,\n                metadata: {\n                  pageNumber: pageData.pageNumber,\n                  chunkIndex: index,\n                  source: file.name,\n                  totalTokens: this.estimateTokens(chunk),\n                  importance: this.calculateImportance(chunk, pageData.pageNumber, 100), // Assumindo 100 páginas max\n                  hash: hash\n                }\n              });\n            });\n          }","metadata":{"source":"docs/rag-openai-high-quality.md","section":"","chunkIndex":6,"totalChunks":43,"timestamp":1749642230531}}],["72d9280e-8c07-472c-8f9d-de95238ca464",{"pageContent":"// Inicializar Web Worker with error handling\n      try {\n        this.pdfWorker = new Worker(new URL('../workers/pdf.worker.js', import.meta.url), {\n          type: 'module'\n        });\n        \n        // Add error handler for worker\n        this.pdfWorker.onerror = (error) => {\n          console.error('PDF Worker error:', error);\n        };\n      } catch (workerError) {\n        console.warn('Web Worker initialization failed, falling back to main thread processing');\n        this.pdfWorker = null;\n      }\n\n      this.initialized = true;\n    } catch (error) {\n      this.initialized = false;\n      throw new Error(`Falha na inicialização: ${error.message}`);\n    }\n  }\n\n  // Processar PDF com Web Worker ou fallback\n  async processPDF(file, onProgress) {\n    if (!this.initialized) {\n      await this.initialize();\n    }\n\n    // Use Web Worker if available, otherwise fallback to main thread\n    if (this.pdfWorker) {\n      return this.processPDFWithWorker(file, onProgress);\n    } else {\n      return this.processPDFMainThread(file, onProgress);\n    }\n  }\n\n  // Processar PDF com Web Worker\n  async processPDFWithWorker(file, onProgress) {\n    return new Promise((resolve, reject) => {\n      const startTime = Date.now();\n      const allChunks = [];\n      let processedPages = 0;\n\n      // Get array buffer and start processing\n      file.arrayBuffer().then(arrayBuffer => {\n        // Listener para mensagens do worker\n        const handleWorkerMessage = async (event) => {\n          const { type, data, error } = event.data;","metadata":{"source":"src/services/highQualityRAG.service.js","section":"","chunkIndex":2,"totalChunks":17,"timestamp":1749642230531}}],["a29ff152-34d1-4e9f-9514-93877cd2b2e3",{"pageContent":"// Add the last chunk if it has content\n    if (currentChunk.trim()) {\n      chunks.push(currentChunk.trim());\n    }\n\n    return chunks.filter(chunk => chunk.length > 0);\n  }\n\n  splitBySeparators(text) {\n    let parts = [text];\n    \n    for (const separator of this.separators) {\n      const newParts = [];\n      for (const part of parts) {\n        if (part.includes(separator)) {\n          const split = part.split(separator);\n          for (let i = 0; i < split.length; i++) {\n            if (split[i].trim()) {\n              newParts.push(split[i].trim());\n            }\n          }\n        } else {\n          newParts.push(part);\n        }\n      }\n      parts = newParts;\n    }\n    \n    return parts;\n  }\n\n  getOverlap(text, overlapSize) {\n    if (!text || overlapSize <= 0) return '';\n    \n    // Get last words that fit within overlap size\n    const words = text.split(' ');\n    let overlap = '';\n    let currentSize = 0;\n    \n    for (let i = words.length - 1; i >= 0; i--) {\n      const word = words[i];\n      if (currentSize + word.length + 1 <= overlapSize) {\n        overlap = word + (overlap ? ' ' + overlap : '');\n        currentSize += word.length + 1;\n      } else {\n        break;\n      }\n    }\n    \n    return overlap;\n  }\n}","metadata":{"source":"src/utils/textSplitter.js","section":"","chunkIndex":1,"totalChunks":2,"timestamp":1749642230531}}],["52241560-7831-4c9f-adf8-74f3c553cdff",{"pageContent":"// Fallback para processar PDF na thread principal\n  async processPDFMainThread(file, onProgress) {\n    try {\n      const startTime = Date.now();\n      const arrayBuffer = await file.arrayBuffer();\n      \n      // Dynamic import para evitar erro se pdfjs não estiver disponível\n      const pdfjsLib = await import('pdfjs-dist');\n      pdfjsLib.GlobalWorkerOptions.workerSrc = 'https://cdn.jsdelivr.net/npm/pdfjs-dist@5.3.31/build/pdf.worker.min.mjs';\n      \n      const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise;\n      const totalPages = pdf.numPages;\n      const allChunks = [];\n      \n      // Process pages in batches\n      const PAGES_PER_BATCH = 3; // Menor para evitar travar a UI\n      \n      for (let startPage = 1; startPage <= totalPages; startPage += PAGES_PER_BATCH) {\n        const endPage = Math.min(startPage + PAGES_PER_BATCH - 1, totalPages);\n        \n        for (let pageNum = startPage; pageNum <= endPage; pageNum++) {\n          const page = await pdf.getPage(pageNum);\n          const textContent = await page.getTextContent();\n          \n          // Simple text reconstruction\n          const pageText = textContent.items\n            .map(item => item.str || '')\n            .join(' ')\n            .trim();\n          \n          if (pageText) {\n            const chunks = await this.splitter.splitText(pageText);\n            \n            chunks.forEach((chunk, index) => {\n              const hash = this.generateHash(chunk);\n              \n              allChunks.push({\n                text: chunk,\n                metadata: {\n                  pageNumber: pageNum,\n                  chunkIndex: index,\n                  source: file.name,\n                  totalTokens: this.estimateTokens(chunk),\n                  importance: this.calculateImportance(chunk, pageNum, totalPages),\n                  hash: hash\n                }\n              });\n            });\n          }\n          \n          page.cleanup();\n        }","metadata":{"source":"src/services/highQualityRAG.service.js","section":"","chunkIndex":5,"totalChunks":17,"timestamp":1749642230531}}],["aa312b3e-2541-41f8-8e09-5522388acc88",{"pageContent":"### Problema 6: Ícones Material não exibindo\n\n**Adicionar fonte Material Icons ao HTML**\n```html\n<link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\" />\n```\n\n## Recursos adicionais e links importantes\n\n### Documentação oficial\n- **React Docs**: https://www.material-tailwind.com/docs/react/installation\n- **HTML Docs**: https://www.material-tailwind.com/docs/html/installation\n- **GitHub Repository**: https://github.com/creativetimofficial/material-tailwind\n\n### Exemplos e templates\n- **Material Tailwind Dashboard React**: Template admin gratuito com 40+ componentes\n- **Material Tailwind Kit React**: UI kit com seções pré-construídas\n- **CodeSandbox Playground**: Editor online para Material Tailwind React/HTML\n- **Material Tailwind Blocks**: Coleção premium com 30+ novos blocks\n\nMaterial Tailwind oferece uma solução robusta para desenvolvedores que buscam combinar a estética do Material Design com a abordagem utility-first do Tailwind CSS. A versão gratuita fornece funcionalidade substancial para a maioria dos projetos, enquanto a versão Pro atende a necessidades comerciais avançadas com componentes e templates premium. A compatibilidade total com Tailwind CSS v3.x garante capacidades modernas de desenvolvimento web, embora os desenvolvedores devam monitorar as atualizações de compatibilidade com v4 para preparar seus projetos para o futuro.","metadata":{"source":"docs/Material-Tailwind-Guia-Completo.md","section":"","chunkIndex":14,"totalChunks":15,"timestamp":1749642230531}}],["2bb62789-7428-452b-9d98-1c7bc51b863a",{"pageContent":"// Report progress if callback provided\n        if (onProgress) {\n          onProgress({\n            currentPage: i,\n            totalPages: pdf.numPages,\n            progress: (i / pdf.numPages) * 100\n          });\n        }\n      }\n\n      return {\n        content: fullText.trim(),\n        pageCount: pdf.numPages,\n        extractedAt: new Date()\n      };\n    } catch (error) {\n      console.error('PDF text extraction failed:', error);\n      throw new Error(ERROR_MESSAGES.PDF_PROCESSING);\n    }\n  }\n\n  /**\n   * Get PDF metadata\n   * @param {File} file - PDF file\n   * @returns {Promise<Object>} PDF metadata\n   */\n  async getMetadata(file) {\n    this.validateFile(file);\n\n    try {\n      const arrayBuffer = await file.arrayBuffer();\n      const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise;\n      const metadata = await pdf.getMetadata();\n\n      return {\n        pageCount: pdf.numPages,\n        title: metadata.info?.Title || 'Untitled',\n        author: metadata.info?.Author || 'Unknown',\n        subject: metadata.info?.Subject || '',\n        creator: metadata.info?.Creator || '',\n        producer: metadata.info?.Producer || '',\n        creationDate: metadata.info?.CreationDate || null,\n        modificationDate: metadata.info?.ModDate || null,\n      };\n    } catch (error) {\n      console.error('Failed to get PDF metadata:', error);\n      throw new Error('Failed to extract PDF metadata');\n    }\n  }\n}\n\n/**\n * Create PDF service instance\n * @returns {PDFService} Service instance\n */","metadata":{"source":"src/services/pdf.service.js","section":"","chunkIndex":2,"totalChunks":4,"timestamp":1749642230531}}],["09990bed-12fb-4ced-bbc7-5b192e3a72bc",{"pageContent":"/**\n   * Get recording duration in seconds\n   * @returns {number} Recording duration\n   */\n  getDuration() {\n    if (!this.mediaRecorder) return 0;\n    \n    // Estimate duration based on chunks (approximate)\n    return this.audioChunks.length * 0.1; // Rough estimate\n  }\n}\n\n/**\n * Create audio service instance\n * @returns {AudioService} Service instance\n */","metadata":{"source":"src/services/audio.service.js","section":"","chunkIndex":3,"totalChunks":5,"timestamp":1749642230531}}],["00305f53-342e-4779-8c71-be8756aaccbc",{"pageContent":"# Podcast POC - Guia para CLAUDE CODE\n\n\n## Visão Geral do Projeto\n\n<project-info>\nNome do Projeto: Podcast POC\nRepositório: podcast-poc\nDescrição: Web application para geração de podcasts educacionais a partir de PDFs usando APIs OpenAI. Recursos incluem extração de texto PDF, interface de chat com IA, gravação/transcrição de áudio e capacidades de busca vetorial.\nLinguagens: JavaScript, React\nFrameworks: React 18.3.1 + Vite 6.0.5 + Material Tailwind\nBibliotecas Principais: OpenAI API, PDF.js, MediaRecorder API\nPlataforma: Web (navegador moderno com suporte a Web Workers)\n</project-info>\n\n## Comandos Essenciais\n\n```bash\n# Instalação e setup\nnpm install                  # Instalar todas as dependências\n# Configurar VITE_OPENAI_API_KEY no .env.local\n\n# Build\nnpm run build                # Build para produção\nnpm run preview              # Visualizar build de produção localmente\n\n# Testes\n# Testes ainda não implementados - TODO: configurar Jest/Vitest\n\n# Lint e Verificação de Tipos\nnpm run lint                 # Executar ESLint para verificar código\n# TypeScript não configurado - projeto usa JavaScript\n\n# Execução\nnpm run dev                  # Iniciar servidor de desenvolvimento (http://localhost:5173)\nnpm run preview              # Executar preview da build de produção\n\n\n# Git\ngit checkout development     # Branch de desenvolvimento ativo\ngit checkout -b feature/nome # Criar branch de feature\ngit commit -m \"tipo: desc\"   # Formato: feat/fix/docs/refactor/chore\n```\n\n## Arquitetura do Sistema\n\n<architecture>\n### Arquitetura Funcional e Modular\n\nO Podcast POC é estruturado em uma arquitetura modular com os seguintes módulos principais que trabalham de forma integrada:\n\n\n### Padrões de Design Utilizados","metadata":{"source":".ondokai/onboarding.md","section":"","chunkIndex":0,"totalChunks":7,"timestamp":1749642234867}}],["5285c12a-d86c-4818-8804-2d70e4a83399",{"pageContent":"O Podcast POC é estruturado em uma arquitetura modular com os seguintes módulos principais que trabalham de forma integrada:\n\n\n### Padrões de Design Utilizados\n\n1. **Service Layer Pattern**: Lógica de negócio isolada em serviços\n2. **Custom Hooks Pattern**: Encapsulamento de lógica stateful reutilizável\n3. **Component Composition**: Componentes modulares e compostos\n4. **Error Boundary Pattern**: Tratamento robusto de erros\n5. **Worker Pattern**: Processamento pesado em Web Workers\n\n### Fluxo de Dados Principal\n\n```\n1. Upload PDF → Web Worker → Extração de Texto\n2. Texto → Text Splitter → Chunks\n3. User Query + Context → OpenAI API\n4. Streaming Response → UI Update\n5. Audio Recording → Whisper → Query Text\n```\n\n### Comunicação Entre Módulos\n\n- **Event-driven**: Callbacks e promises para operações assíncronas\n- **State Management**: React hooks para estado local\n- **Service Calls**: Funções puras nos serviços para processamento\n- **Streaming**: Server-sent events para respostas em tempo real\n\n### Integrações Externas\n\n1. **OpenAI API**: Chat completions, Whisper transcription\n2. **PDF.js**: Renderização e extração de PDF\n3. **Material Tailwind**: Componentes UI\n4. **Web APIs**: MediaRecorder, Web Workers, Blob API\n\n### Considerações de Escalabilidade\n\n- Processamento assíncrono com Workers previne bloqueio da UI\n- Streaming de respostas reduz latência percebida\n- Modularização permite evolução independente de componentes\n- Fallbacks implementados para maior resiliência\n</architecture>\n\n## Estrutura do Repositório","metadata":{"source":".ondokai/onboarding.md","section":"","chunkIndex":1,"totalChunks":7,"timestamp":1749642234867}}],["392859ee-f00f-4619-b3a4-8da466d2a864",{"pageContent":"```\npodcast-poc/\n├── src/                     # Código fonte da aplicação\n│   ├── components/          # Componentes React organizados por tipo\n│   │   ├── features/        # Componentes de funcionalidades específicas\n│   │   │   ├── ChatInterface.jsx      # Interface de chat com IA\n│   │   │   ├── ExtractedTextDisplay.jsx # Exibição de texto extraído\n│   │   │   └── PDFUploader.jsx        # Upload e processamento de PDF\n│   │   └── ui/              # Componentes de UI reutilizáveis\n│   │       └── ErrorBoundary.jsx      # Tratamento global de erros\n│   ├── hooks/               # Custom hooks React\n│   │   ├── useOpenAI.js     # Hook para integração OpenAI\n│   │   ├── usePDF.js        # Hook para processamento PDF\n│   │   └── useAudioRecording.js # Hook para gravação de áudio\n│   ├── services/            # Camada de serviços (lógica de negócio)\n│   │   ├── openai.service.js    # Integração com APIs OpenAI\n│   │   ├── pdf.service.js       # Extração de texto PDF\n│   │   ├── audio.service.js     # Gravação e processamento de áudio\n│   │   ├── config.service.js    # Gerenciamento de configurações\n│   │   └── highQualityRAG.service.js # Serviço de RAG (não utilizado)\n│   ├── workers/             # Web Workers para processamento pesado\n│   │   └── pdf.worker.js    # Worker para extração de PDF\n│   ├── utils/               # Funções utilitárias\n│   │   ├── format.js        # Formatadores de dados\n│   │   ├── textSplitter.js  # Divisão de texto em chunks\n│   │   └── validation.js    # Validações gerais\n│   ├── constants/           # Constantes da aplicação\n│   │   └── index.js         # Configurações e limites\n│   ├── App.jsx              # Componente principal\n│   └── main.jsx             # Ponto de entrada React\n├── public/                  # Arquivos públicos estáticos\n│   └── pdf.worker.min.mjs   # Worker PDF.js (OBRIGATÓRIO)\n├── docs/                    # Documentação do projeto\n├── package.json             # Dependências e scripts","metadata":{"source":".ondokai/onboarding.md","section":"","chunkIndex":2,"totalChunks":7,"timestamp":1749642234867}}],["4f5160be-ae96-4c48-b207-17ae86265676",{"pageContent":"│   └── pdf.worker.min.mjs   # Worker PDF.js (OBRIGATÓRIO)\n├── docs/                    # Documentação do projeto\n├── package.json             # Dependências e scripts\n├── vite.config.js           # Configuração do Vite\n├── tailwind.config.js       # Configuração do Tailwind CSS\n├── eslint.config.js         # Configuração do ESLint\n└── .env.local               # Variáveis de ambiente (não versionado)\n```","metadata":{"source":".ondokai/onboarding.md","section":"","chunkIndex":3,"totalChunks":7,"timestamp":1749642234867}}],["2e070cee-204e-46b7-a4ad-d6c64cff77a7",{"pageContent":"## Convenções de Código\n\n<code-conventions>\n### Estilo de Código\n- Indentação: 2 espaços (configurado no ESLint)\n- Comprimento máximo de linha: 100 caracteres (recomendado)\n- Quotes: Aspas simples para strings\n- Ponto-e-vírgula: Obrigatório no final de statements\n- Chaves: Mesma linha (estilo JavaScript moderno)\n\n### Nomenclatura\n- Variáveis: camelCase (ex: extractedText, isLoading)\n- Funções: camelCase (ex: handleSubmit, processAudio)\n- Classes: PascalCase (ex: OpenAIService, PDFProcessor)\n- Constantes: UPPER_SNAKE_CASE (ex: MAX_FILE_SIZE, API_TIMEOUT)\n- Arquivos: \n  - Componentes: PascalCase.jsx (ex: ChatInterface.jsx)\n  - Hooks: camelCase com prefixo 'use' (ex: useOpenAI.js)\n  - Serviços: camelCase.service.js (ex: openai.service.js)\n  - Utilitários: camelCase.js (ex: textSplitter.js)\n\n### Documentação\n- Estilo de comentários: JSDoc para funções públicas\n- Requisitos para funções públicas: @fileoverview, @param, @returns\n- Formato de TODOs: // TODO: [descrição] - [autor] [data]\n- Evitar comentários desnecessários - código deve ser autoexplicativo\n\n### Padrões de Projeto\n- Service Layer Pattern: Toda lógica de negócio em arquivos .service.js\n- Custom Hooks: Lógica stateful encapsulada em hooks use*\n- Error Boundaries: Tratamento de erros em componentes wrapper\n- Composition over Inheritance: Preferir composição de componentes\n- Single Responsibility: Cada módulo/componente com uma única responsabilidade\n</code-conventions>\n\n## Fluxo de Trabalho Git\n\n<git-workflow>\n### Branches\n- Branch principal: main\n- Branch de desenvolvimento: development\n- Branches de feature: feature/nome-da-feature\n- Branches de fix: fix/nome-do-bug\n\n### Commits\n- Formato de mensagem: tipo: descrição\n- Tipos aceitos: feat/fix/docs/refactor/chore\n</git-workflow>\n\n\n\n\n\n\n## Configuração do Ambiente de Desenvolvimento","metadata":{"source":".ondokai/onboarding.md","section":"","chunkIndex":4,"totalChunks":7,"timestamp":1749642234867}}],["c33c0936-3d93-4e8e-83a4-89dfc2de753f",{"pageContent":"### Commits\n- Formato de mensagem: tipo: descrição\n- Tipos aceitos: feat/fix/docs/refactor/chore\n</git-workflow>\n\n\n\n\n\n\n## Configuração do Ambiente de Desenvolvimento\n\n<dev-environment>\n### Requisitos\n- Node.js: v18.0.0 ou superior (recomendado v20+)\n- npm: v9.0.0 ou superior\n- Git: v2.0.0 ou superior\n- Editor: VSCode recomendado com extensões ESLint e Tailwind CSS IntelliSense\n- Navegador moderno com suporte a Web Workers e MediaRecorder API\n\n### Configuração Passo a Passo\n1. Clonar o repositório:\n   ```bash\n   git clone [url-do-repositorio]\n   cd podcast-poc\n   git checkout development\n   ```\n\n2. Instalar dependências:\n   ```bash\n   npm install\n   ```\n\n3. Configurar variáveis de ambiente:\n   ```bash\n   # Criar arquivo .env.local\n   echo \"VITE_OPENAI_API_KEY=sua_chave_aqui\" > .env.local\n   ```\n\n4. Verificar arquivo do worker PDF:\n   ```bash\n   # Garantir que existe em public/\n   ls public/pdf.worker.min.mjs\n   ```\n\n5. Iniciar servidor de desenvolvimento:\n   ```bash\n   npm run dev\n   # Acessar http://localhost:5173\n   ```\n\n### Configurações Específicas\n- VSCode: Instalar extensões ESLint, Tailwind CSS IntelliSense, ES7+ React snippets\n- Git: Configurar email e nome para commits\n- Chrome DevTools: Habilitar source maps para debugging\n- OpenAI API: Obter chave em https://platform.openai.com/api-keys\n\n### Containers e Virtualização\n- Docker não configurado atualmente\n- Para desenvolvimento, usar ambiente Node.js local\n- Possível containerização futura para deployment\n</dev-environment>\n\n\n\n## Instruções para Mode de Pensamento Estendido\n\n<thinking-mode>\nUse as seguintes técnicas para ativar o modo de pensamento estendido do Claude CODE:\n\n- \"think\" - Ativa 4.000 tokens de pensamento\n- \"think hard\" ou \"think a lot\" ou \"think deeply\" - Ativa 10.000 tokens de pensamento \n- \"think harder\" ou \"think very hard\" - Ativa 31.999 tokens de pensamento\n- \"ultrathink\" ou \"megathink\" - Ativa o nível máximo de pensamento (31.999 tokens)","metadata":{"source":".ondokai/onboarding.md","section":"","chunkIndex":5,"totalChunks":7,"timestamp":1749642234867}}],["e091772f-78a7-48e6-85d9-159ba12149e2",{"pageContent":"Use essas técnicas para análises complexas de arquitetura, planejamento de features ou debugging de problemas difíceis.\n</thinking-mode>\n\n\n\n\n\n\n---\n\n**Notas Adicionais para o CLAUDE CODE:**\n\nEste template deve ser adaptado conforme as necessidades específicas do seu projeto. Seções podem ser removidas ou adicionadas de acordo com a complexidade e requisitos. Mantenha este arquivo atualizado conforme o projeto evolui para garantir que o CLAUDE CODE sempre tenha informações precisas sobre o contexto técnico.\n\nPara referências a diretórios ou arquivos específicos, use caminhos relativos à raiz do projeto para facilitar a navegação do CLAUDE CODE.\n\nUse o comando \"think hard\" quando precisar de análises mais profundas sobre arquitetura ou refatoração, e \"ultrathink\" para problemas particularmente complexos ou decisões críticas.","metadata":{"source":".ondokai/onboarding.md","section":"","chunkIndex":6,"totalChunks":7,"timestamp":1749642234867}}]],{"0":"ec98efa2-add3-474b-8ef8-294529f406a7","1":"03aca64d-3c5f-4c3f-8dde-e1f70e03f585","2":"1ddc96d9-5992-41de-8795-4b5105b3efff","3":"445d6b54-5d7b-435c-8c0c-3e0d80805d51","4":"758483d2-0baa-4101-8014-7ddc6f643644","5":"548fa954-bb9c-4bb4-a250-c882952b8276","6":"68058528-3efb-43a4-87d0-4fcd1b81d9f0","7":"5bfefeb9-274c-467f-8a82-dbf1115d404f","8":"136c873d-9a74-4254-ab58-ca53f8bd8d3d","9":"74859e58-c497-48dc-a09b-69c095640b80","10":"6a8e313e-9c3e-42ee-8423-c8a0d5d33eff","11":"d638c7f4-1616-4322-8df3-d25e4849a2f9","12":"f23fb33b-8426-49fa-b0de-ad3716970cfd","13":"ecd1d5f0-408a-44c2-906f-8a989300da16","14":"d772aed8-9127-499f-9230-8cf15bfbe9db","15":"469af271-9223-4b43-870c-4503595efc05","16":"40237ae6-e1b5-496d-a1de-07a521668129","17":"e241573a-e2ca-4f66-a943-303144f7a351","18":"b23cadb0-7136-4a6a-acea-4f9ed36e3f2f","19":"30e8cfa7-4c9f-4da9-9482-dcaa65975e16","20":"bc82d40c-92d3-4689-b37c-cc8f9be02415","21":"5f225529-5bf1-4069-81c6-7211b4019ded","22":"7ea566b7-e49c-48fc-bc3e-4b54bfc325ed","23":"f0bf5977-e4fc-4820-a8ff-815e3e98fca9","24":"46281bb3-c620-43bf-ba2e-6f77e9e6700f","25":"5eb18e84-c5c2-44c7-b5e7-a6a3cd2a9d59","26":"e7bb3eb9-42f7-49ef-add3-36b67641ccbf","27":"4aa1691d-76e7-4afc-a471-0bf7f4c90bfd","28":"e305fbfd-3e30-42c9-9877-619a6c3b5115","29":"5fadf2b2-201b-46e2-9e13-f94af618d7fd","30":"5088fc3c-2cc7-4884-856c-fdcb8b244fa6","31":"e8528a19-f391-4a73-939e-f118555d9b7c","32":"a3c7ce2f-9126-4e5e-9c7d-29b01ba1585f","33":"d199d339-50ee-4553-b13b-8ebad3d934d1","34":"34e50e4b-8c89-4bc4-92b4-3191f08fc012","35":"ded20539-ebad-4c9b-832a-fcc0c7672ddc","36":"7ed72a65-bf9c-4caf-9885-57b99e9c21c2","37":"11461a2f-c714-4126-8a7a-f56b18ed2700","38":"1e901cdc-f5eb-43f5-84f5-6ea6ada5244b","39":"365d470d-82ee-492a-b05d-3140306d2454","40":"f36ae44c-ad3b-4ae0-a580-d3981c049c13","41":"de6873dd-7acb-46f9-8a37-f41905e6553b","42":"e97779d3-a669-4186-bb04-f7c77a1a1a4a","43":"1b84ef0f-0724-4cb2-8e66-48fb13ec7849","44":"bcfde8c6-6110-4207-b63c-15d3761472b7","45":"821064f2-4e31-49af-86d5-21a71bf8186e","46":"19e0bf5a-4b8d-4c2d-936a-baff62463b30","47":"405a51d9-30f3-41f2-b135-f0db3516c55a","48":"9bdbc880-3e2b-4542-81e8-45bceb9ffeaf","49":"f93faad6-e83a-4259-b1ef-42b5cbdda4a6","50":"b437a186-bfee-4ceb-96c3-171ab6dceb74","51":"fe7c9885-b579-4920-ad8c-d7ce830a763c","52":"1fd3996c-7ad6-4882-8967-69c4302457b6","53":"88d52e74-b556-49c1-9342-f2e602c4661e","54":"566566e8-6d1b-47ee-b20f-19dfae9cbc4b","55":"ac311a10-26ce-4f16-a113-577d111741b6","56":"04adb638-f88e-4859-ab3d-d96da348c10c","57":"82789b1d-68a7-48fd-9625-c6cb9b8d9d03","58":"3e8c83bf-b719-4f42-a0f8-2690e056d889","59":"3bee9576-c2f5-4301-8dcb-37df4ba8a9ca","60":"a216eb8a-2cb4-4717-bee2-cfbc439b112c","61":"77cee858-e8e5-478f-a499-d8e18d9013a7","62":"f854dab3-cb79-4b41-9d41-2a5c75ba14fb","63":"a47cf580-2dd5-463d-add5-903c0d26b30a","64":"0e78ffd7-eb47-44e0-9b62-205868044383","65":"f9dbb4dc-041e-418b-9fbd-a3bd46283a4d","66":"25c296c0-8ba1-4cae-b13c-373fd935ce28","67":"46020870-bfb3-472e-9332-f0538fb04779","68":"7970e356-bfe3-4f12-9d99-797a89f784c8","69":"600b8604-bd98-41aa-9b38-f58c8369c5b0","70":"167b28cd-2801-4117-9c03-b0996c6442ba","71":"f53f5465-e82f-4d38-9692-bb9bccbe57de","72":"623ec582-0c99-4046-b286-f77fc3b70597","73":"58f00300-4a6f-4583-b120-134e5fe70383","74":"28b75fc1-d6ff-4658-add1-f7d46c60c5fe","75":"2c8a548b-1e3c-4349-bede-c671c20271a4","76":"8e0b704f-0628-47d3-9c31-383392f79396","77":"e00ac4fa-8e83-4db5-90b0-92f0d29b14f6","78":"22dd03b7-e020-46af-aa88-e85bb41b6695","79":"f73215d9-dfcc-43ac-a23a-0f76d98d3cac","80":"882fb91a-22b4-47a9-88c5-3498e79afef7","81":"303aa47f-615e-474b-ae99-e76a5f962c4b","82":"a878b28c-d90a-4607-a2f0-b2c4a2af3eaf","83":"0b2a0f01-2b62-4f68-be4f-378ad19a4d1d","84":"cbbdbe14-b75c-4438-9526-0e000d8bfc5b","85":"8cc6af7a-ff1c-4c8b-b88a-f2cce129ce37","86":"723eaf9f-f3ed-4897-a103-e3190cd143b2","87":"3a4d728b-be24-4d61-a310-628a0802922f","88":"5d212808-8318-4374-b290-0ce0126b6eea","89":"d67b8f07-cdc2-45e1-8a27-2baac8cb83e9","90":"91723c7c-07f1-49ad-a75c-e05351a97a30","91":"fb3f4b9c-993d-44aa-abe7-1b4642ab500d","92":"80c649e9-0bea-4014-b38c-89f67a2d6bc0","93":"b43d6702-86ea-4767-85a1-28886086fa97","94":"4ab37d2b-0997-4ab9-9715-e9c69ae26623","95":"3b245104-6b73-46ca-838b-8f64cde06755","96":"b1a00ccb-c913-4915-b271-f3bcc96c7fd5","97":"f48be6aa-eb4c-44d6-8917-33d481035075","98":"68017e40-8145-43c6-9de5-b2d60a000e61","99":"690c3c6e-d4e3-4fd6-a6ae-a54e96e81ede","100":"9ca70f47-c1d1-41fc-bf81-a105aa998a58","101":"d65e8a82-82fd-46ae-b759-3c39ba74fd44","102":"7800e762-a9a4-4b58-8976-c0978e3fdbfb","103":"1f177142-60ee-4496-aefe-8cc6af3fb73a","104":"72d9280e-8c07-472c-8f9d-de95238ca464","105":"a29ff152-34d1-4e9f-9514-93877cd2b2e3","106":"52241560-7831-4c9f-adf8-74f3c553cdff","107":"aa312b3e-2541-41f8-8e09-5522388acc88","108":"2bb62789-7428-452b-9d98-1c7bc51b863a","109":"09990bed-12fb-4ced-bbc7-5b192e3a72bc","110":"00305f53-342e-4779-8c71-be8756aaccbc","111":"5285c12a-d86c-4818-8804-2d70e4a83399","112":"392859ee-f00f-4619-b3a4-8da466d2a864","113":"4f5160be-ae96-4c48-b207-17ae86265676","114":"2e070cee-204e-46b7-a4ad-d6c64cff77a7","115":"c33c0936-3d93-4e8e-83a4-89dfc2de753f","116":"e091772f-78a7-48e6-85d9-159ba12149e2"}]